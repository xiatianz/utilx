<!doctype html><html lang=zh-cn dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>æ‰€æœ‰æ–‡ç«  | æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·</title><meta name=keywords content="æŠ€æœ¯æ–‡ç« ,åšå®¢æ–‡ç« ,å¼€å‘æ•™ç¨‹,å·¥å…·ä½¿ç”¨"><meta name=description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><meta name=author content="util.cn Team"><link rel=canonical href=/blog/posts/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.7e8505b7cdf8bb22ab2305e53c2700bb06c7e64faeb72cd3468823a9a3bd3d6e.css integrity="sha256-foUFt834uyKrIwXlPCcAuwbH5k+utyzTRogjqaO9PW4=" rel="preload stylesheet" as=style><link rel=icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=apple-touch-icon href=/blog/apple-touch-icon.png><link rel=mask-icon href=/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=/blog/posts/feed.xml title=rss><link rel=alternate hreflang=zh-cn href=/blog/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script src=/js/external-link-config.js></script><script src=/js/external-link-interceptor.js></script><link rel=stylesheet href=/blog/css/custom.css media=screen><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«","url":"https://www.util.cn/blog/","description":"æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚æä¾›JSONæ ¼å¼åŒ–ã€SQLä¼˜åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰åœ¨çº¿å·¥å…·çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…æå‡å·¥ä½œæ•ˆç‡ã€‚","publisher":{"@type":"Organization","name":"æœ‰æ¡å·¥å…·","url":"https://www.util.cn","logo":{"@type":"ImageObject","url":"https://www.util.cn/blog/logo/logo-256.png","width":256,"height":256}},"potentialAction":[{"@type":"SearchAction","target":"https://www.util.cn/blog/search?q={search_term_string}","query-input":"required name=search_term_string"}]}</script><meta property="og:type" content="website"><meta property="og:title" content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«"><meta property="og:description" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚æä¾›JSONæ ¼å¼åŒ–ã€SQLä¼˜åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰åœ¨çº¿å·¥å…·çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…æå‡å·¥ä½œæ•ˆç‡ã€‚"><meta property="og:url" content="https://www.util.cn/blog/"><meta property="og:site_name" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢"><meta property="og:image" content="https://www.util.cn/blog/logo/logo-256.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«"><meta name=twitter:description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚"><meta name=twitter:image content="https://www.util.cn/blog/logo/logo-256.png"><meta name=baidu-site-verification content><meta name=category content="æŠ€æœ¯åšå®¢,å¼€å‘è€…å·¥å…·,ç¼–ç¨‹æ•™ç¨‹"><meta name=coverage content="Worldwide"><meta name=distribution content="Global"><meta name=rating content="General"><script id=51la_code async crossorigin=anonymous src="https://sdk.51.la/js-sdk-pro.min.js?id=3OM52V0xJAPv6ozF&hash=pro"></script><script>window.addEventListener("load",function(){setTimeout(function(){typeof la!="undefined"?console.log("51laç»Ÿè®¡å·²åŠ è½½"):(console.warn("51laç»Ÿè®¡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ"),function(){var e=document.createElement("script");e.src="https://sdk.51.la/js-sdk-pro.min.js?id=3OM52V0xJAPv6ozF&hash=backup",e.async=!0,document.head.appendChild(e)}())},3e3)})</script><meta property="og:url" content="/blog/posts/"><meta property="og:site_name" content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·"><meta property="og:title" content="æ‰€æœ‰æ–‡ç« "><meta property="og:description" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="æ‰€æœ‰æ–‡ç« "><meta name=twitter:description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"æ‰€æœ‰æ–‡ç« ","item":"/blog/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=/blog/ accesskey=h title="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· (Alt + H)">æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/blog/posts/ title="æ‰€æœ‰æ–‡ç« åˆ—è¡¨ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŸ¥çœ‹æ‰€æœ‰æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹"><span class=active>æ–‡ç« </span></a></li><li><a href=https://www.util.cn title="æœ‰æ¡å·¥å…· - å¼€å‘è€…çš„å¸¸ç”¨å·¥å…·é›†åˆï¼šæ— å¹¿å‘Š Â· æœ¬åœ°è®¡ç®— Â· å³å¼€å³ç”¨çš„åœ¨çº¿å·¥å…·å¹³å°ï¼Œæä¾›JSONæ ¼å¼åŒ–ã€SQLæ ¼å¼åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰å®ç”¨å·¥å…·"><span>æœ‰æ¡å·¥å…·</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=/blog/categories/ title="æ–‡ç« åˆ†ç±» - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŒ‰æŠ€æœ¯é¢†åŸŸåˆ†ç±»çš„ä¼˜è´¨æ–‡ç« ï¼ŒåŒ…æ‹¬å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰"><span>åˆ†ç±»</span></a></li><li><a href=/blog/tags/ title="æ ‡ç­¾äº‘ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šé€šè¿‡æ ‡ç­¾å¿«é€Ÿæ‰¾åˆ°æ„Ÿå…´è¶£çš„æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹"><span>æ ‡ç­¾</span></a></li><li><a href=/blog/archives/ title="æ–‡ç« å½’æ¡£ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŒ‰æ—¶é—´æŸ¥çœ‹å†å²æ–‡ç« "><span>å½’æ¡£</span></a></li><li><a href=/blog/search/ title="æœç´¢æ–‡ç«  - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šé€šè¿‡å…³é”®è¯æœç´¢æ‰¾åˆ°æ„Ÿå…´è¶£çš„æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹ï¼Œæ”¯æŒæ ‡é¢˜ã€å†…å®¹ã€åˆ†ç±»å’Œæ ‡ç­¾æœç´¢"><span>æœç´¢</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>æ‰€æœ‰æ–‡ç« </h1><div class=post-description>æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹</div></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Edge AIæ¶æ„è®¾è®¡ï¼šåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²æ™ºèƒ½åº”ç”¨</h2></header><div class=entry-content><p>å¼•è¨€ éšç€AIèŠ¯ç‰‡çš„æ™®åŠå’Œæ¨¡å‹ä¼˜åŒ–æŠ€æœ¯çš„è¿›æ­¥ï¼Œ2025å¹´Edge AIè¿æ¥äº†çˆ†å‘å¼å¢é•¿ã€‚ä»æ™ºèƒ½æ‰‹æœºåˆ°å·¥ä¸šè®¾å¤‡ï¼Œæ™ºèƒ½æ­£åœ¨ä»äº‘ç«¯ä¸‹æ²‰åˆ°è¾¹ç¼˜ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨Edge AIçš„æ¶æ„è®¾è®¡ï¼Œå¸®åŠ©å¼€å‘è€…åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²é«˜æ€§èƒ½AIåº”ç”¨ã€‚
ä¸€ã€Edge AIæŠ€æœ¯æ ˆ 1.1 æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 # æ¨¡å‹å‹ç¼©ä¸ä¼˜åŒ– import tensorflow as tf import tensorflow_model_optimization as tfmot from tensorflow.lite.python import converter import numpy as np class ModelOptimizer: """è¾¹ç¼˜AIæ¨¡å‹ä¼˜åŒ–å™¨""" def __init__(self, model): self.original_model = model self.optimized_model = None def quantize_model(self, model, representative_data=None): """ æ¨¡å‹é‡åŒ–ï¼šå°†32ä½æµ®ç‚¹æ•°è½¬æ¢ä¸º8ä½æ•´æ•° - æ¨¡å‹å¤§å°å‡å°‘75% - æ¨ç†é€Ÿåº¦æå‡2-4å€ - ç²¾åº¦æŸå¤±é€šå¸¸&lt;1% """ if representative_data is None: # è®­ç»ƒåé‡åŒ–ï¼ˆæ— éœ€æ ¡å‡†æ•°æ®ï¼‰ converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] else: # é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆéœ€è¦æ ¡å‡†æ•°æ®ï¼‰ def representative_dataset(): for data in representative_data: yield [data] converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_dataset converter.target_spec.supported_types = [tf.float16] # å¯é€‰ï¼šfloat16 tflite_model = converter.convert() return tflite_model def prune_model(self, model, pruning_params=None): """ æ¨¡å‹å‰ªæï¼šç§»é™¤ä¸é‡è¦çš„è¿æ¥ - å‡å°‘æ¨¡å‹å¤æ‚åº¦ - åŠ é€Ÿæ¨ç† - é˜²æ­¢è¿‡æ‹Ÿåˆ """ if pruning_params is None: pruning_params = { 'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay( initial_sparsity=0.0, final_sparsity=0.5, # å‰ªæ50% begin_step=0, end_step=1000 ), 'block_size': (1, 1), # ç»“æ„åŒ–å‰ªæ } # åº”ç”¨å‰ªæ pruning_model = tfmot.sparsity.keras.prune_low_magnitude( model, **pruning_params ) # å¾®è°ƒå‰ªæåçš„æ¨¡å‹ pruning_model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # pruning_model.fit(x_train, y_train, epochs=3) return pruning_model def distill_model(self, teacher_model, student_model, data): """ çŸ¥è¯†è’¸é¦ï¼šç”¨å¤§æ¨¡å‹è®­ç»ƒå°æ¨¡å‹ - ä¿ç•™å¤§æ¨¡å‹çš„çŸ¥è¯† - å¤§å¹…å‡å°æ¨¡å‹å¤§å° """ # æ¸©åº¦å‚æ•°ï¼šæ§åˆ¶è¾“å‡ºåˆ†å¸ƒçš„å¹³æ»‘åº¦ temperature = 3 # æ•™å¸ˆæ¨¡å‹çš„è½¯æ ‡ç­¾ teacher_logits = teacher_model.predict(data, verbose=0) # å­¦ç”Ÿæ¨¡å‹å­¦ä¹ è½¯æ ‡ç­¾å’Œç¡¬æ ‡ç­¾ def distillation_loss(y_true, y_pred): # è½¯æ ‡ç­¾æŸå¤± soft_loss = tf.keras.losses.KLDivergence()( tf.nn.softmax(teacher_logits / temperature), tf.nn.softmax(y_pred / temperature) ) # ç¡¬æ ‡ç­¾æŸå¤± hard_loss = tf.keras.losses.sparse_categorical_crossentropy( y_true, y_pred ) # åŠ æƒç»„åˆ return 0.7 * soft_loss * temperature ** 2 + 0.3 * hard_loss student_model.compile( optimizer='adam', loss=distillation_loss, metrics=['accuracy'] ) return student_model def optimize_for_hardware(self, tflite_model, target_hardware): """ é’ˆå¯¹ç‰¹å®šç¡¬ä»¶ä¼˜åŒ– """ # Edge TPUä¼˜åŒ– if target_hardware == 'edge_tpu': # Edge TPUåªæ”¯æŒ8ä½æ•´æ•°é‡åŒ– converter = tf.lite.TFLiteConverter.from_keras_model(self.original_model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_input_type = tf.uint8 converter.inference_output_type = tf.uint8 # GPUä¼˜åŒ– elif target_hardware == 'gpu': converter = tf.lite.TFLiteConverter.from_keras_model(self.original_model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.supported_types = [tf.float16] # é€šç”¨CPUä¼˜åŒ– else: converter = tf.lite.TFLiteConverter.from_keras_model(self.original_model) converter.optimizations = [tf.lite.Optimize.DEFAULT] return converter.convert() # å®é™…ä½¿ç”¨ç¤ºä¾‹ optimizer = ModelOptimizer(original_model) # 1. é‡åŒ–æ¨¡å‹ quantized_model = optimizer.quantize_model( original_model, representative_data=calibration_data ) # 2. ä¿å­˜æ¨¡å‹ with open('model_quant.tflite', 'wb') as f: f.write(quantized_model) # 3. æŸ¥çœ‹æ¨¡å‹å¤§å° import os original_size = os.path.getsize('model.h5') / (1024 * 1024) # MB quantized_size = os.path.getsize('model_quant.tflite') / (1024 * 1024) print(f"åŸå§‹æ¨¡å‹: {original_size:.2f} MB") print(f"é‡åŒ–æ¨¡å‹: {quantized_size:.2f} MB") print(f"å‹ç¼©ç‡: {(1 - quantized_size / original_size) * 100:.1f}%") 1.2 è¾¹ç¼˜æ¨ç†æ¡†æ¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 # TensorFlow Liteéƒ¨ç½² class TFLiteInferenceEngine: """TensorFlow Liteæ¨ç†å¼•æ“""" def __init__(self, model_path, num_threads=4, use_gpu=False): import tflite_runtime.interpreter as tflite # åŠ è½½æ¨¡å‹ self.interpreter = tflite.Interpreter( model_path=model_model_path, num_threads=num_threads ) # åˆ†é…å¼ é‡ self.interpreter.allocate_tensors() # è·å–è¾“å…¥è¾“å‡ºè¯¦æƒ… self.input_details = self.interpreter.get_input_details() self.output_details = self.interpreter.get_output_details() # æ£€æŸ¥ç¡¬ä»¶åŠ é€Ÿ if use_gpu: self._enable_gpu_delegation() def _enable_gpu_delegation(self): """å¯ç”¨GPUåŠ é€Ÿ""" import tflite_runtime.interpreter as tflite # GPUå§”æ‰˜ options = tflite.InterpreterOptions() options.add_delegate("TfLiteGpuDelegateV2") self.interpreter = tflite.Interpreter( model_path=self.model_path, interpreter_options=options ) def predict(self, input_data): """æ‰§è¡Œæ¨ç†""" # è®¾ç½®è¾“å…¥ input_index = self.input_details[0]['index'] self.interpreter.set_tensor(input_index, input_data) # æ‰§è¡Œæ¨ç† self.interpreter.invoke() # è·å–è¾“å‡º output_index = self.output_details[0]['index'] output_data = self.interpreter.get_tensor(output_index) return output_data def predict_batch(self, input_batch): """æ‰¹é‡æ¨ç†""" results = [] for input_data in input_batch: result = self.predict(input_data) results.append(result) return np.array(results) # ONNX Runtimeéƒ¨ç½² class ONNXInferenceEngine: """ONNX Runtimeæ¨ç†å¼•æ“""" def __init__(self, model_path, providers=None): import onnxruntime as ort if providers is None: # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ‰§è¡Œæä¾›è€… providers = ort.get_available_providers() self.session = ort.InferenceSession( model_path, providers=providers ) # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯ self.input_name = self.session.get_inputs()[0].name self.output_name = self.session.get_outputs()[0].name def predict(self, input_data): """æ‰§è¡Œæ¨ç†""" result = self.session.run( [self.output_name], {self.input_name: input_data} ) return result[0] def get_model_info(self): """è·å–æ¨¡å‹ä¿¡æ¯""" return { 'inputs': [{ 'name': input.name, 'shape': input.shape, 'type': input.type } for input in self.session.get_inputs() ], 'outputs': [{ 'name': output.name, 'shape': output.shape, 'type': output.type } for output in self.session.get_outputs() ], 'providers': self.session.get_providers() } # PyTorch Mobileéƒ¨ç½² class PyTorchMobileEngine: """PyTorch Mobileæ¨ç†å¼•æ“""" def __init__(self, model_path): import torch import torch.jit as jit # åŠ è½½TorchScriptæ¨¡å‹ self.model = jit.load(model_path) self.model.eval() # ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰ if torch.cuda.is_available(): self.model = self.model.cuda() def predict(self, input_data): import torch # è½¬æ¢ä¸ºtensor if not isinstance(input_data, torch.Tensor): input_tensor = torch.tensor(input_data) else: input_tensor = input_data # ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœæ¨¡å‹åœ¨GPUï¼‰ if torch.cuda.is_available() and next(self.model.parameters()).is_cuda: input_tensor = input_tensor.cuda() # æ¨ç† with torch.no_grad(): output = self.model(input_tensor) # ç§»å›CPUå¹¶è½¬æ¢ä¸ºnumpy return output.cpu().numpy() äºŒã€ç«¯äº‘ååŒæ¶æ„ 2.1 ååŒæ¨ç†æ¨¡å¼ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 # ç«¯äº‘ååŒæ¨ç† class EdgeCloudCollaborativeInference: """ç«¯äº‘ååŒæ¨ç†""" def __init__(self, edge_model, cloud_api): self.edge_model = edge_model # è½»é‡çº§è¾¹ç¼˜æ¨¡å‹ self.cloud_api = cloud_api # äº‘ç«¯API # é˜ˆå€¼é…ç½® self.confidence_threshold = 0.8 self.latency_threshold = 100 # ms self.bandwidth_threshold = 100 # KB/s async def predict(self, input_data): """æ™ºèƒ½æ¨ç†å†³ç­–""" # å°è¯•è¾¹ç¼˜æ¨ç† edge_result = await self._edge_inference(input_data) # è¯„ä¼°è¾¹ç¼˜ç»“æœ if self._should_use_edge_result(edge_result): return edge_result else: # å›é€€åˆ°äº‘ç«¯ return await self._cloud_inference(input_data) async def _edge_inference(self, input_data): """è¾¹ç¼˜æ¨ç†""" start_time = time.time() # æœ¬åœ°æ¨ç† result = self.edge_model.predict(input_data) latency = (time.time() - start_time) * 1000 # ms return { 'result': result, 'confidence': result.get('confidence', 0.5), 'latency': latency, 'source': 'edge' } async def _cloud_inference(self, input_data): """äº‘ç«¯æ¨ç†""" start_time = time.time() # è°ƒç”¨äº‘ç«¯API cloud_result = await self.cloud_api.predict(input_data) latency = (time.time() - start_time) * 1000 # ms return { 'result': cloud_result, 'confidence': cloud_result.get('confidence', 0.9), 'latency': latency, 'source': 'cloud' } def _should_use_edge_result(self, edge_result): """åˆ¤æ–­æ˜¯å¦ä½¿ç”¨è¾¹ç¼˜ç»“æœ""" # é«˜ç½®ä¿¡åº¦ï¼šä½¿ç”¨è¾¹ç¼˜ç»“æœ if edge_result['confidence'] >= self.confidence_threshold: return True # ä½å»¶è¿Ÿè¦æ±‚ï¼šä½¿ç”¨è¾¹ç¼˜ç»“æœ if edge_result['latency'] &lt;= self.latency_threshold: return True # ä½å¸¦å®½ç¯å¢ƒï¼šä½¿ç”¨è¾¹ç¼˜ç»“æœ if self._get_bandwidth() &lt; self.bandwidth_threshold: return True return False def _get_bandwidth(self): """è·å–å½“å‰å¸¦å®½""" # ç®€åŒ–å®ç° return 1000 # KB/s # 2. åˆ†å±‚æ¨ç†æ¨¡å‹ class HierarchicalInference: """åˆ†å±‚æ¨ç†ï¼šè¾¹ç¼˜é¢„ç­›é€‰+äº‘ç«¯ç²¾ç»†å¤„ç†""" def __init__(self, edge_filter, cloud_processor): self.edge_filter = edge_filter # è½»é‡çº§è¿‡æ»¤å™¨ self.cloud_processor = cloud_processor # é‡é‡çº§å¤„ç†å™¨ async def process(self, input_data): """åˆ†å±‚å¤„ç†""" # ç¬¬ä¸€å±‚ï¼šè¾¹ç¼˜å¿«é€Ÿè¿‡æ»¤ filter_result = await self._filter_on_edge(input_data) if filter_result['is_simple']: # ç®€å•æ¡ˆä¾‹ï¼šç›´æ¥è¿”å› return filter_result['result'] else: # å¤æ‚æ¡ˆä¾‹ï¼šäº‘ç«¯æ·±åº¦å¤„ç† return await self._process_on_cloud(input_data, filter_result) async def _filter_on_edge(self, input_data): """è¾¹ç¼˜è¿‡æ»¤""" # å¿«é€Ÿåˆ†ç±» category = self.edge_filter.predict(input_data) return { 'is_simple': category == 'simple', 'result': category, 'confidence': 0.9 } async def _process_on_cloud(self, input_data, filter_result): """äº‘ç«¯æ·±åº¦å¤„ç†""" # å°†è¾¹ç¼˜è¿‡æ»¤ç»“æœä¼ é€’ç»™äº‘ç«¯ cloud_result = await self.cloud_processor.process( input_data, context=filter_result ) return cloud_result # 3. å¢é‡å­¦ä¹ æ¶æ„ class IncrementalLearningEdge: """è¾¹ç¼˜å¢é‡å­¦ä¹ """ def __init__(self, base_model): self.base_model = base_model self.local_adaptations = {} async def predict_with_adaptation(self, input_data, user_id): """å¸¦æœ¬åœ°é€‚é…çš„é¢„æµ‹""" # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ç‰¹å®šé€‚é… if user_id in self.local_adaptations: adapted_model = self.local_adaptations[user_id] result = adapted_model.predict(input_data) else: result = self.base_model.predict(input_data) return result async def update_local_model(self, user_id, new_data): """æ›´æ–°æœ¬åœ°æ¨¡å‹""" # åŸºäºæ–°æ•°æ®å¾®è°ƒæ¨¡å‹ adapted_model = self._fine_tune_model( self.base_model, new_data ) self.local_adaptations[user_id] = adapted_model # å®šæœŸåŒæ­¥åˆ°äº‘ç«¯ await self._sync_to_cloud(user_id, adapted_model) def _fine_tune_model(self, base_model, data): """å¾®è°ƒæ¨¡å‹""" # ç®€åŒ–å®ç°ï¼šè¿ç§»å­¦ä¹  # å®é™…åº”ä½¿ç”¨æ›´å¤æ‚çš„å¾®è°ƒç­–ç•¥ return base_model # è¿”å›é€‚é…åçš„æ¨¡å‹ 2.2 ç¦»çº¿æ¨ç†æ¶æ„ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 # ç¦»çº¿AIæ¨ç† class OfflineInferenceEngine: """ç¦»çº¿æ¨ç†å¼•æ“""" def __init__(self, model_path, cache_size=100): self.model = self._load_model(model_path) self.cache = LRUCache(cache_size) self.offline_models = {} def _load_model(self, model_path): """åŠ è½½æ¨¡å‹""" # TFLiteåŠ è½½ import tflite_runtime.interpreter as tflite return tflite.Interpreter(model_path=model_path) async def predict(self, input_data, model_version='default'): """ç¦»çº¿é¢„æµ‹""" # æ£€æŸ¥ç¼“å­˜ cache_key = self._generate_cache_key(input_data) cached_result = self.cache.get(cache_key) if cached_result: return cached_result # æ‰§è¡Œæ¨ç† result = self._do_inference(input_data, model_version) # ç¼“å­˜ç»“æœ self.cache.put(cache_key, result) return result def _do_inference(self, input_data, model_version): """æ‰§è¡Œæ¨ç†""" # ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬æ¨¡å‹ if model_version != 'default': model = self.offline_models.get(model_version) if model: return model.predict(input_data) # ä½¿ç”¨é»˜è®¤æ¨¡å‹ return self._predict_with_model(self.model, input_data) def download_model(self, model_url, version): """ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°""" # ä¸‹è½½æ¨¡å‹æ–‡ä»¶ model_data = self._download_from_url(model_url) # ä¿å­˜åˆ°æœ¬åœ° model_path = f"/models/{version}.tflite" with open(model_path, 'wb') as f: f.write(model_data) # åŠ è½½æ¨¡å‹ import tflite_runtime.interpreter as tflite model = tflite.Interpreter(model_path=model_path) self.offline_models[version] = model return model def update_model(self, new_version): """æ›´æ–°æ¨¡å‹""" # æ£€æŸ¥ç½‘ç»œè¿æ¥ if not self._is_online(): raise Exception("Offline: Cannot update model") # ä¸‹è½½æ–°ç‰ˆæœ¬ model_url = f"https://api.example.com/models/{new_version}.tflite" self.download_model(model_url, new_version) # è®¾ç½®ä¸ºé»˜è®¤ç‰ˆæœ¬ self.model = self.offline_models[new_version] def _is_online(self): """æ£€æŸ¥ç½‘ç»œè¿æ¥""" import socket try: socket.create_connection(("8.8.8.8", 53), timeout=3) return True except OSError: return False class LRUCache: """LRUç¼“å­˜""" def __init__(self, size): self.size = size self.cache = {} self.order = [] def get(self, key): if key in self.cache: # æ›´æ–°è®¿é—®é¡ºåº self.order.remove(key) self.order.append(key) return self.cache[key] return None def put(self, key, value): if key in self.cache: self.order.remove(key) elif len(self.cache) >= self.size: # ç§»é™¤æœ€æ—§çš„é¡¹ oldest = self.order.pop(0) del self.cache[oldest] self.cache[key] = value self.order.append(key) ä¸‰ã€å®æ—¶æ€§ä¸èƒ½æ•ˆä¼˜åŒ– 3.1 å®æ—¶æ€§ä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 # å®æ—¶AIæ¨ç†ä¼˜åŒ– class RealtimeInferenceOptimizer: """å®æ—¶æ¨ç†ä¼˜åŒ–å™¨""" def __init__(self, model): self.model = model self.input_queue = queue.Queue(maxsize=10) self.output_queue = queue.Queue(maxsize=10) async def start_inference_thread(self): """å¯åŠ¨æ¨ç†çº¿ç¨‹""" import threading thread = threading.Thread(target=self._inference_loop) thread.daemon = True thread.start() def _inference_loop(self): """æ¨ç†å¾ªç¯""" while True: try: # ä»é˜Ÿåˆ—è·å–è¾“å…¥ input_data = self.input_queue.get(timeout=1.0) # æ‰§è¡Œæ¨ç† result = self.model.predict(input_data) # æ”¾å…¥è¾“å‡ºé˜Ÿåˆ— self.output_queue.put(result) except queue.Empty: continue async def predict_async(self, input_data): """å¼‚æ­¥æ¨ç†""" # éé˜»å¡æäº¤ try: self.input_queue.put_nowait(input_data) except queue.Full: raise Exception("Inference queue full") # ç­‰å¾…ç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰ try: result = self.output_queue.get(timeout=0.1) return result except queue.Empty: raise Exception("Inference timeout") # 2. æ¨¡å‹åˆ†ç‰‡ class ModelSharding: """æ¨¡å‹åˆ†ç‰‡ï¼šå°†å¤§æ¨¡å‹æ‹†åˆ†ä¸ºå°æ¨¡å—""" def __init__(self, model_config): self.shards = {} self._create_shards(model_config) def _create_shards(self, config): """åˆ›å»ºæ¨¡å‹åˆ†ç‰‡""" for shard_name, shard_config in config['shards'].items(): self.shards[shard_name] = self._load_shard(shard_config) def _load_shard(self, config): """åŠ è½½æ¨¡å‹åˆ†ç‰‡""" # åŠ è½½è½»é‡çº§åˆ†ç‰‡æ¨¡å‹ return load_model(config['path']) def predict_sharded(self, input_data, shard_order): """åˆ†ç‰‡æ¨ç†""" current_data = input_data for shard_name in shard_order: shard = self.shards[shard_name] current_data = shard.predict(current_data) return current_data # 3. æ—©æœŸé€€å‡º class EarlyExitInference: """æ—©æœŸé€€å‡ºæ¨ç†""" def __init__(self, model): self.model = model self.exit_thresholds = [0.95, 0.8, 0.6] def predict_with_early_exit(self, input_data): """å¸¦æ—©æœŸé€€å‡ºçš„é¢„æµ‹""" # ç¬¬ä¸€å±‚ï¼šå¿«é€Ÿåˆ†ç±» result = self.model.predict_layer1(input_data) confidence = result['confidence'] if confidence > self.exit_thresholds[0]: return result # ç¬¬äºŒå±‚ï¼šç²¾ç»†åˆ†ç±» result = self.model.predict_layer2(input_data) confidence = result['confidence'] if confidence > self.exit_thresholds[1]: return result # ç¬¬ä¸‰å±‚ï¼šå®Œæ•´æ¨ç† result = self.model.predict_full(input_data) return result 3.2 èƒ½æ•ˆä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 # èƒ½æ•ˆä¼˜åŒ–ç­–ç•¥ class PowerOptimizedInference: """åŠŸè€—ä¼˜åŒ–æ¨ç†""" def __init__(self, model): self.model = model self.power_modes = ['high_performance', 'balanced', 'power_saver'] self.current_mode = 'balanced' def set_power_mode(self, mode): """è®¾ç½®åŠŸè€—æ¨¡å¼""" if mode not in self.power_modes: raise ValueError(f"Invalid power mode: {mode}") self.current_mode = mode # è°ƒæ•´æ¨ç†å‚æ•° if mode == 'high_performance': self.threads = 4 self.precision = 'float32' elif mode == 'balanced': self.threads = 2 self.precision = 'float16' else: # power_saver self.threads = 1 self.precision = 'int8' def predict(self, input_data): """æ ¹æ®åŠŸè€—æ¨¡å¼æ¨ç†""" if self.current_mode == 'power_saver': # é™ä½é¢‘ç‡ self._throttle_inference() result = self._do_inference(input_data) self._restore_inference() else: result = self._do_inference(input_data) return result def _throttle_inference(self): """é™åˆ¶æ¨ç†æ€§èƒ½""" # é™ä½CPUé¢‘ç‡ç­‰ pass def _restore_inference(self): """æ¢å¤æ¨ç†æ€§èƒ½""" pass # 2. æ‰¹å¤„ç†ä¼˜åŒ– class BatchOptimizer: """æ‰¹å¤„ç†ä¼˜åŒ–""" def __init__(self, model, max_batch_size=8, max_wait_time=50): self.model = model self.max_batch_size = max_batch_size self.max_wait_time = max_wait_time # ms self.pending_requests = [] self.last_batch_time = time.time() async def predict(self, input_data): """æ‰¹å¤„ç†æ¨ç†""" # æ·»åŠ åˆ°å¾…å¤„ç†é˜Ÿåˆ— future = asyncio.Future() self.pending_requests.append({ 'input': input_data, 'future': future }) # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œæ‰¹å¤„ç† if self._should_process_batch(): await self._process_batch() return await future def _should_process_batch(self): """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†æ‰¹æ¬¡""" # è¾¾åˆ°æœ€å¤§æ‰¹å¤§å° if len(self.pending_requests) >= self.max_batch_size: return True # è¶…è¿‡æœ€å¤§ç­‰å¾…æ—¶é—´ elapsed = (time.time() - self.last_batch_time) * 1000 if elapsed >= self.max_wait_time: return True return False async def _process_batch(self): """å¤„ç†æ‰¹æ¬¡""" if not self.pending_requests: return # å‡†å¤‡æ‰¹æ¬¡æ•°æ® batch_inputs = [req['input'] for req in self.pending_requests] # æ‰¹é‡æ¨ç† batch_results = await self._batch_predict(batch_inputs) # è¿”å›ç»“æœ for i, req in enumerate(self.pending_requests): req['future'].set_result(batch_results[i]) # æ¸…ç©ºé˜Ÿåˆ— self.pending_requests = [] self.last_batch_time = time.time() async def _batch_predict(self, batch_inputs): """æ‰¹é‡é¢„æµ‹""" # å †å ä¸ºæ‰¹æ¬¡tensor batch_tensor = np.stack(batch_inputs) # æ¨ç† batch_results = self.model.predict(batch_tensor) return batch_results å››ã€å®é™…åº”ç”¨æ¡ˆä¾‹ 4.1 æ™ºèƒ½ç›¸æœºåº”ç”¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 # æ™ºèƒ½ç›¸æœºï¼šè¾¹ç¼˜AIå®æ—¶å›¾åƒå¤„ç† class SmartCameraApp: """æ™ºèƒ½ç›¸æœºåº”ç”¨""" def __init__(self): # åŠ è½½å¤šä¸ªæ¨¡å‹ self.face_detector = self._load_model('face_detector.tflite') self.face_recognizer = self._load_model('face_recognizer.tflite') self.scene_classifier = self._load_model('scene_classifier.tflite') self.image_enhancer = self._load_model('image_enhancer.tflite') async def process_camera_frame(self, frame): """å¤„ç†ç›¸æœºå¸§""" # 1. åœºæ™¯æ£€æµ‹ï¼ˆå¿«é€Ÿï¼‰ scene = self.scene_classifier.predict(frame) # 2. æ ¹æ®åœºæ™¯é€‰æ‹©å¤„ç†æµç¨‹ if scene['class'] == 'portrait': return await self._process_portrait(frame) elif scene['class'] == 'landscape': return await self._process_landscape(frame) elif scene['class'] == 'night': return await self._process_night_scene(frame) else: return await self._process_default(frame) async def _process_portrait(self, frame): """å¤„ç†äººåƒåœºæ™¯""" # æ£€æµ‹äººè„¸ faces = self.face_detector.predict(frame) if faces: # è¯†åˆ«äººè„¸ identities = self.face_recognizer.predict(frame, faces) # ç¾é¢œå¤„ç† enhanced_frame = self.image_enhancer.enance_portrait(frame, faces) return { 'frame': enhanced_frame, 'faces': faces, 'identities': identities, 'effects': ['beautify', 'smooth'] } return {'frame': frame, 'faces': []} async def _process_night_scene(self, frame): """å¤„ç†å¤œæ™¯""" # å¤œæ™¯å¢å¼º enhanced_frame = self.image_enhancer.enforce_night(frame) return { 'frame': enhanced_frame, 'effects': ['night_mode', 'denoise'] } # å®æ—¶æ€§èƒ½ç›‘æ§ class PerformanceMonitor: """æ€§èƒ½ç›‘æ§""" def __init__(self): self.fps_history = [] self.latency_history = [] def measure_inference(self, inference_fn): """æµ‹é‡æ¨ç†æ€§èƒ½""" start_time = time.time() result = inference_fn() end_time = time.time() latency = (end_time - start_time) * 1000 # ms self.latency_history.append(latency) # ä¿æŒæœ€è¿‘100ä¸ªæ ·æœ¬ if len(self.latency_history) > 100: self.latency_history.pop(0) return result def get_stats(self): """è·å–ç»Ÿè®¡ä¿¡æ¯""" if not self.latency_history: return {} import numpy as np return { 'avg_latency': np.mean(self.latency_history), 'p50_latency': np.percentile(self.latency_history, 50), 'p95_latency': np.percentile(self.latency_history, 95), 'p99_latency': np.percentile(self.latency_history, 99), 'max_latency': np.max(self.latency_history), 'fps': 1000 / np.mean(self.latency_history) } æ€»ç»“ Edge AIåœ¨2025å¹´å®ç°äº†ä»æ¦‚å¿µåˆ°å•†ç”¨çš„è·¨è¶Šã€‚2026å¹´ï¼Œéšç€ç¡¬ä»¶èƒ½åŠ›çš„æå‡å’Œä¼˜åŒ–æŠ€æœ¯çš„æˆç†Ÿï¼ŒEdge AIå°†åœ¨æ›´å¤šåœºæ™¯ä¸­æ›¿ä»£äº‘ç«¯AIã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/ai/ class=category-link>AI</a><a href=/blog/categories/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/ class=category-link>è¾¹ç¼˜è®¡ç®—</a></div><span class=post-date>2025-12-31</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to Edge AIæ¶æ„è®¾è®¡ï¼šåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²æ™ºèƒ½åº”ç”¨" href=/blog/articles/edge-ai%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%9C%A8%E8%B5%84%E6%BA%90%E5%8F%97%E9%99%90%E8%AE%BE%E5%A4%87%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>WebAssembly 2025ï¼šä»è¾¹ç¼˜æŠ€æœ¯åˆ°ä¸»æµå¹³å°çš„è·¨è¶Š</h2></header><div class=entry-content><p>å¼•è¨€ 2025å¹´æ˜¯WebAssemblyï¼ˆWASMï¼‰èµ°å‘æˆç†Ÿçš„å…³é”®ä¸€å¹´ã€‚ä»å®éªŒæ€§æŠ€æœ¯åˆ°ä¸»æµå¹³å°ï¼ŒWASMæ­£åœ¨é‡å¡‘Webåº”ç”¨çš„è¾¹ç•Œã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æWASMç”Ÿæ€åœ¨2025å¹´çš„é‡å¤§çªç ´ï¼Œå¹¶å±•æœ›2026å¹´çš„å‘å±•æ–¹å‘ã€‚
ä¸€ã€WASM 2025æŠ€æœ¯çªç ´ 1.1 GCææ¡ˆè½åœ° åƒåœ¾å›æ”¶æ”¯æŒ
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // 2025å¹´WASM GCçš„å®é™…åº”ç”¨ // ä»¥å‰ï¼šæ‰‹åŠ¨ç®¡ç†å†…å­˜ï¼Œç±»ä¼¼Cè¯­è¨€ mod manual_memory { #[no_mangle] pub fn allocate_string(size: usize) -> *mut u8 { let layout = std::alloc::Layout::from_size_align(size, 1).unwrap(); unsafe { let ptr = std::alloc::alloc(layout); ptr as *mut u8 } } #[no_mangle] pub fn free_string(ptr: *mut u8, size: usize) { let layout = std::alloc::Layout::from_size_align(size, 1).unwrap(); unsafe { std::alloc::dealloc(ptr as *mut u8, layout); } } } // ç°åœ¨ï¼šä½¿ç”¨WASM GCï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨Rustçš„Vecã€HashMapç­‰ mod with_gc { use wasm_bindgen::prelude::*; #[wasm_bindgen] pub struct DataProcessor { // å¯ä»¥ç›´æ¥ä½¿ç”¨é›†åˆç±»å‹ items: Vec&lt;DataItem>, cache: HashMap&lt;String, ProcessedData>, } #[wasm_bindgen] impl DataProcessor { #[wasm_bindgen(constructor)] pub fn new() -> Self { Self { items: Vec::new(), cache: HashMap::new(), } } #[wasm_bindgen] pub fn process(&amp;mut self, input: &amp;str) -> String { // ä½¿ç”¨Rustæ ‡å‡†åº“ï¼Œæ— éœ€æ‰‹åŠ¨å†…å­˜ç®¡ç† if let Some(cached) = self.cache.get(input) { return cached.result.clone(); } let result = self.heavy_computation(input); self.cache.insert(input.to_string(), result.clone()); result } fn heavy_computation(&amp;self, input: &amp;str) -> String { // å¤æ‚è®¡ç®—é€»è¾‘ format!("Processed: {}", input) } } } GCå¸¦æ¥çš„å˜é©
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/webassembly/ class=category-link>WebAssembly</a><a href=/blog/categories/%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF/ class=category-link>å‰ç«¯æŠ€æœ¯</a></div><span class=post-date>2025-12-31</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to WebAssembly 2025ï¼šä»è¾¹ç¼˜æŠ€æœ¯åˆ°ä¸»æµå¹³å°çš„è·¨è¶Š" href=/blog/articles/webassembly-2025%E4%BB%8E%E8%BE%B9%E7%BC%98%E6%8A%80%E6%9C%AF%E5%88%B0%E4%B8%BB%E6%B5%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E8%B7%A8%E8%B6%8A/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹2.0ï¼šä»ç¼–ç åˆ°æ¶æ„çš„å…¨é¢å˜é©</h2></header><div class=entry-content><p>å¼•è¨€ 2025å¹´ï¼Œå¤§è¯­è¨€æ¨¡å‹å·²ç»å½»åº•æ”¹å˜äº†è½¯ä»¶å¼€å‘çš„æ–¹å¼ã€‚æˆ‘ä»¬æ­£åœ¨è§è¯ä»"æ‰‹å†™ä»£ç "åˆ°"äººæœºåä½œ"çš„èŒƒå¼è½¬ç§»ã€‚è¿™ä¸æ˜¯ç®€å•çš„å·¥å…·å‡çº§ï¼Œè€Œæ˜¯è½¯ä»¶å·¥ç¨‹æ–¹æ³•è®ºçš„æ ¹æœ¬æ€§å˜é©ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æè¿™ä¸€å˜é©ï¼Œå¸®åŠ©å¼€å‘è€…é€‚åº”æ–°æ—¶ä»£çš„å¼€å‘æ¨¡å¼ã€‚
ä¸€ã€è½¯ä»¶å·¥ç¨‹çš„èŒƒå¼è½¬ç§» 1.1 ä»ç¼–ç åˆ°ç¼–æ’ ä¼ ç»Ÿå¼€å‘æ¨¡å¼
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # è½¯ä»¶å·¥ç¨‹1.0ï¼šå¼€å‘è€…å³ç¼–ç è€… class TraditionalDeveloper: """ è§’è‰²å®šä½ï¼š - 80%æ—¶é—´å†™ä»£ç  - 15%æ—¶é—´è°ƒè¯• - 5%æ—¶é—´è®¾è®¡ æ ¸å¿ƒæŠ€èƒ½ï¼š - è¯­æ³•ç†Ÿç»ƒåº¦ - APIè®°å¿† - æ‰‹åŠ¨è°ƒè¯• - æ–‡æ¡£æŸ¥é˜… """ def create_feature(self, requirement): # 1. æ‰‹å†™æ•°æ®æ¨¡å‹ class User: def __init__(self, id, name, email): self.id = id self.name = name self.email = email # 2. æ‰‹å†™æ•°æ®è®¿é—®å±‚ class UserRepository: def get_by_id(self, id): # æ‰‹å†™SQL pass # 3. æ‰‹å†™APIç«¯ç‚¹ def user_endpoint(request): # æ‰‹å†™è·¯ç”±å¤„ç† pass # 4. æ‰‹å†™æµ‹è¯• def test_user(): # æ‰‹å†™æµ‹è¯•ç”¨ä¾‹ pass # ...æ‰€æœ‰ä»£ç éƒ½éœ€è¦æ‰‹åŠ¨ç¼–å†™ AIè¾…åŠ©å¼€å‘æ¨¡å¼
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/ class=category-link>è½¯ä»¶å·¥ç¨‹</a><a href=/blog/categories/ai%E5%BC%80%E5%8F%91/ class=category-link>AIå¼€å‘</a></div><span class=post-date>2025-12-31</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to LLMé©±åŠ¨çš„è½¯ä»¶å·¥ç¨‹2.0ï¼šä»ç¼–ç åˆ°æ¶æ„çš„å…¨é¢å˜é©" href=/blog/articles/llm%E9%A9%B1%E5%8A%A8%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B2.0%E4%BB%8E%E7%BC%96%E7%A0%81%E5%88%B0%E6%9E%B6%E6%9E%84%E7%9A%84%E5%85%A8%E9%9D%A2%E5%8F%98%E9%9D%A9/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>2025æŠ€æœ¯æµªæ½®å›é¡¾ä¸2026è¶‹åŠ¿å‰ç»ï¼šå¼€å‘è€…å¿…çŸ¥çš„å˜é©æ–¹å‘</h2></header><div class=entry-content><p>å¼•è¨€ 2025å¹´æ˜¯æŠ€æœ¯å˜é©åŠ é€Ÿçš„ä¸€å¹´ã€‚AIç¼–ç¨‹åŠ©æ‰‹ä»å®éªŒæ€§å·¥å…·å˜ä¸ºå¼€å‘æ ‡é…ï¼ŒWebAssemblyç”Ÿæ€èµ°å‘æˆç†Ÿï¼ŒRuståœ¨ç³»ç»Ÿç¼–ç¨‹é¢†åŸŸçš„åœ°ä½ä¸æ–­å·©å›ºã€‚ç«™åœ¨2025å¹´çš„ç»ˆç‚¹ï¼Œè®©æˆ‘ä»¬æ·±åº¦å›é¡¾è¿™ä¸€å¹´çš„æŠ€æœ¯çªç ´ï¼Œå¹¶å±•æœ›2026å¹´çš„å‘å±•æ–¹å‘ã€‚
ä¸€ã€2025å¹´æŠ€æœ¯æ ¼å±€å˜é© 1.1 AIè¾…åŠ©ç¼–ç¨‹æˆä¸ºæ ‡é… ä»è¾…åŠ©åˆ°æ ¸å¿ƒ
2025å¹´ï¼ŒAIç¼–ç¨‹åŠ©æ‰‹å®Œæˆäº†ä»"é”¦ä¸Šæ·»èŠ±"åˆ°"ä¸å¯æˆ–ç¼º"çš„è½¬å˜ã€‚æ ¹æ®Stack Overflowçš„è°ƒæŸ¥ï¼Œè¶…è¿‡70%çš„å¼€å‘è€…æ—¥å¸¸ä½¿ç”¨AIç¼–ç¨‹å·¥å…·ã€‚
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // 2025å¹´çš„å…¸å‹å¼€å‘å·¥ä½œæµ class DeveloperWorkflow { // ä¼ ç»Ÿæ–¹å¼ï¼šæ‰‹åŠ¨ç¼–å†™æ‰€æœ‰ä»£ç  traditionalApproach() { const fetchUser = async (id: string) => { const response = await fetch(`/api/users/${id}`); return response.json(); }; const updateUser = async (id: string, data: any) => { const response = await fetch(`/api/users/${id}`, { method: 'PUT', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(data) }); return response.json(); }; // è¿˜éœ€è¦æ‰‹åŠ¨å†™æµ‹è¯•ã€æ–‡æ¡£ã€é”™è¯¯å¤„ç†... } // 2025å¹´AIè¾…åŠ©æ–¹å¼ï¼šAIç”ŸæˆåŸºç¡€ä»£ç ï¼Œå¼€å‘è€…ä¸“æ³¨ä¸šåŠ¡é€»è¾‘ aiAssistedApproach() { // AIç”Ÿæˆï¼šåŸºç¡€CRUDæ“ä½œã€ç±»å‹å®šä¹‰ã€é”™è¯¯å¤„ç† // å¼€å‘è€…ä¸“æ³¨ï¼šä¸šåŠ¡è§„åˆ™ã€è¾¹ç•Œæ¡ä»¶ã€æ€§èƒ½ä¼˜åŒ– const userService = { // AIç”Ÿæˆçš„åŸºç¡€ç»“æ„ async getUser(id: string): Promise&lt;User> { // AIå·²æ·»åŠ ï¼šé”™è¯¯å¤„ç†ã€ç±»å‹æ£€æŸ¥ã€æ—¥å¿—è®°å½• return await apiClient.get(`/users/${id}`); }, // å¼€å‘è€…æ·»åŠ ï¼šå¤æ‚çš„ä¸šåŠ¡é€»è¾‘ async getUserWithPermissions(id: string): Promise&lt;UserWithPermissions> { const user = await this.getUser(id); const permissions = await permissionService.loadForUser(user); return { ...user, permissions }; }, // å¼€å‘è€…ä¼˜åŒ–ï¼šç¼“å­˜ç­–ç•¥ async getUserCached(id: string): Promise&lt;User> { return cache.remember(`user:${id}`, () => this.getUser(id), 3600); } }; } } AIå·¥å…·çš„è¿›åŒ–
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/ class=category-link>æŠ€æœ¯è¶‹åŠ¿</a><a href=/blog/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/ class=category-link>å¹´åº¦æ€»ç»“</a></div><span class=post-date>2025-12-31</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to 2025æŠ€æœ¯æµªæ½®å›é¡¾ä¸2026è¶‹åŠ¿å‰ç»ï¼šå¼€å‘è€…å¿…çŸ¥çš„å˜é©æ–¹å‘" href=/blog/articles/2025%E6%8A%80%E6%9C%AF%E6%B5%AA%E6%BD%AE%E5%9B%9E%E9%A1%BE%E4%B8%8E2026%E8%B6%8B%E5%8A%BF%E5%89%8D%E7%9E%BB%E5%BC%80%E5%8F%91%E8%80%85%E5%BF%85%E7%9F%A5%E7%9A%84%E5%8F%98%E9%9D%A9%E6%96%B9%E5%90%91/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>å¼€å‘è€…å·¥å…·å®Œå…¨æŒ‡å—ï¼šæå‡ç¼–ç¨‹æ•ˆç‡çš„å®ç”¨å·¥å…·é›†</h2></header><div class=entry-content><p>å¼•è¨€ å·¥æ¬²å–„å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨ã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»å¼€å‘è€…å¿…å¤‡å·¥å…·ï¼Œå¸®åŠ©ä½ æ„å»ºé«˜æ•ˆçš„å¼€å‘ç¯å¢ƒã€‚
ä¸€ã€ä»£ç ç¼–è¾‘å™¨ 1.1 VS Codeé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // settings.json { "editor.formatOnSave": true, "editor.codeActionsOnSave": { "source.fixAll.eslint": true }, "editor.tabSize": 2, "editor.wordWrap": "on", "files.autoSave": "afterDelay", "files.autoSaveDelay": 1000 } // æ¨èæ‰©å±• { "recommendations": [ "dbaeumer.vscode-eslint", "esbenp.prettier-vscode", "ms-python.python", "ms-python.debugpy", "formulahendry.auto-rename-tag", "christian-kohler.path-intellisense", "streetsidesoftware.code-spell-checker" ] } äºŒã€Gitæœ€ä½³å®è·µ 2.1 Gitåˆ«åé…ç½® 1 2 3 4 5 6 7 8 # å¸¸ç”¨åˆ«å git config --global alias.co checkout git config --global alias.br branch git config --global alias.ci commit git config --global alias.st status git config --global alias.unstage 'reset HEAD --' git config --global alias.last 'log -1 HEAD' git config --global alias.visual '!gitk' 2.2 Gitå·¥ä½œæµ 1 2 3 4 5 6 7 8 9 10 11 # åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ git checkout -b feature/new-feature git add . git commit -m "feat: add new feature" git push origin feature/new-feature # åˆ›å»ºPull Request # ä»£ç å®¡æŸ¥é€šè¿‡å git checkout main git merge feature/new-feature git branch -d feature/new-feature ä¸‰ã€è°ƒè¯•å·¥å…· 3.1 Chrome DevTools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // ConsoleæŠ€å·§ console.table(data); console.time('timer'); // ä»£ç ... console.timeEnd('timer'); console.trace('è¿½è¸ªè°ƒç”¨æ ˆ'); // æ–­ç‚¹è°ƒè¯• debugger; // æ€§èƒ½åˆ†æ performance.mark('start'); // ä»£ç ... performance.mark('end'); performance.measure('My Code', 'start', 'end'); å››ã€APIæµ‹è¯•å·¥å…· 4.1 cURLæŠ€å·§ 1 2 3 4 5 6 7 8 # GETè¯·æ±‚ curl -X GET "https://api.example.com/users" \ -H "Authorization: Bearer TOKEN" # POSTè¯·æ±‚ curl -X POST "https://api.example.com/users" \ -H "Content-Type: application/json" \ -d '{"name":"John","email":"john@example.com"}' äº”ã€åœ¨çº¿å¼€å‘å·¥å…· æœ‰æ¡å·¥å…·ï¼ˆutil.cnï¼‰æä¾›ä»¥ä¸‹å®ç”¨å·¥å…·ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/ class=category-link>å¼€å‘å·¥å…·</a><a href=/blog/categories/%E7%94%9F%E4%BA%A7%E5%8A%9B/ class=category-link>ç”Ÿäº§åŠ›</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to å¼€å‘è€…å·¥å…·å®Œå…¨æŒ‡å—ï¼šæå‡ç¼–ç¨‹æ•ˆç‡çš„å®ç”¨å·¥å…·é›†" href=/blog/articles/%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E6%8F%90%E5%8D%87%E7%BC%96%E7%A8%8B%E6%95%88%E7%8E%87%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%E9%9B%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Web3ä¸åŒºå—é“¾å¼€å‘å®Œå…¨æŒ‡å—ï¼šä»æ™ºèƒ½åˆçº¦åˆ°DApp</h2></header><div class=entry-content><p>å¼•è¨€ Web3å’ŒåŒºå—é“¾æŠ€æœ¯æ­£åœ¨é‡å¡‘äº’è”ç½‘çš„å½¢æ€ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨æ™ºèƒ½åˆçº¦å¼€å‘ã€DeFiåè®®ã€NFTç­‰æ ¸å¿ƒä¸»é¢˜ï¼Œå¸®åŠ©å¼€å‘è€…è¿›å…¥Web3ä¸–ç•Œã€‚
ä¸€ã€Solidityæ™ºèƒ½åˆçº¦ 1.1 åŸºç¡€åˆçº¦ç»“æ„ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // SPDX-License-Identifier: MIT pragma solidity ^0.8.20; import "@openzeppelin/contracts/token/ERC20/ERC20.sol"; import "@openzeppelin/contracts/access/Ownable.sol"; contract MyToken is ERC20, Ownable { uint256 public constant MAX_SUPPLY = 1_000_000_000 * 10**18; constructor() ERC20("MyToken", "MTK") { _mint(msg.sender, MAX_SUPPLY); } function mint(address to, uint256 amount) public onlyOwner { _mint(to, amount); } function burn(uint256 amount) public { _burn(msg.sender, amount); } } 1.2 å®‰å…¨æœ€ä½³å®è·µ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // ========== é‡å…¥æ”»å‡»é˜²æŠ¤ ========== contract ReentrancyGuard { bool private locked; modifier noReentrant() { require(!locked, "Reentrant call"); locked = true; _; locked = false; } function withdraw() external noReentrant { // ... } } // ========== è®¿é—®æ§åˆ¶ ========== contract AccessControl { mapping(address => bool) public admins; modifier onlyAdmin() { require(admins[msg.sender], "Not admin"); _; } function addAdmin(address admin) external onlyAdmin { admins[admin] = true; } } // ========== å®‰å…¨æ•°å­¦è¿ç®— ========== library SafeMath { function add(uint256 a, uint256 b) internal pure returns (uint256) { require(a + b >= a, "Overflow"); return a + b; } function sub(uint256 a, uint256 b) internal pure returns (uint256) { require(a >= b, "Underflow"); return a - b; } } äºŒã€DeFiåè®®å¼€å‘ 2.1 AMMäº¤æ¢æ±  1 2 3 4 5 6 7 8 9 10 11 12 contract AMMPool { uint256 public reserve0; uint256 public reserve1; function addLiquidity(uint256 amount0, uint256 amount1) external { // ... } function swap(uint256 amount0In, uint256 amount1In) external { // ... } } ä¸‰ã€NFTå¼€å‘ 1 2 3 4 5 6 7 8 9 10 11 12 import "@openzeppelin/contracts/token/ERC721/extensions/ERC721URIStorage.sol"; contract MyNFT is ERC721URIStorage { uint256 private _tokenIdCounter; function mint(address to, string memory uri) public returns (uint256) { uint256 tokenId = _tokenIdCounter++; _safeMint(to, tokenId); _setTokenURI(tokenId, uri); return tokenId; } } å››ã€å‰ç«¯é›†æˆ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { ethers } from 'ethers'; // è¿æ¥é’±åŒ… async function connectWallet() { const provider = new ethers.BrowserProvider(window.ethereum); await provider.send("eth_requestAccounts", []); const signer = await provider.getSigner(); return signer; } // è°ƒç”¨åˆçº¦ async function mintNFT(signer, contractAddress, uri) { const contract = new ethers.Contract( contractAddress, ['function mint(address to, string memory uri) returns (uint256)'], signer ); const tx = await contract.mint(await signer.getAddress(), uri); await tx.wait(); } æ€»ç»“ Web3å¼€å‘éœ€è¦æŒæ¡æ™ºèƒ½åˆçº¦ã€åŒºå—é“¾åŸç†å’Œå‰ç«¯é›†æˆã€‚æŒç»­å…³æ³¨å®‰å…¨æœ€ä½³å®è·µè‡³å…³é‡è¦ã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/web3/ class=category-link>Web3</a><a href=/blog/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ class=category-link>åŒºå—é“¾</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to Web3ä¸åŒºå—é“¾å¼€å‘å®Œå…¨æŒ‡å—ï¼šä»æ™ºèƒ½åˆçº¦åˆ°DApp" href=/blog/articles/web3%E4%B8%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E4%BB%8E%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%88%B0dapp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>äº‘åŸç”Ÿæ¶æ„å®Œå…¨æŒ‡å—ï¼šKubernetesä¸å¾®æœåŠ¡å®è·µ</h2></header><div class=entry-content><p>å¼•è¨€ äº‘åŸç”Ÿæ¶æ„æ˜¯ç°ä»£åº”ç”¨éƒ¨ç½²çš„æ ‡å‡†æ¨¡å¼ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å¦‚ä½•ä½¿ç”¨Kubernetesã€æœåŠ¡ç½‘æ ¼å’ŒDevOpså®è·µæ„å»ºå¼¹æ€§ã€å¯æ‰©å±•çš„äº‘åŸç”Ÿåº”ç”¨ã€‚
ä¸€ã€Kubernetesæ ¸å¿ƒæ¦‚å¿µ 1.1 Podä¸Deployment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # ========== Podé…ç½® ========== apiVersion: v1 kind: Pod metadata: name: nginx-pod labels: app: nginx spec: containers: - name: nginx image: nginx:1.25 ports: - containerPort: 80 resources: requests: memory: "64Mi" cpu: "250m" limits: memory: "128Mi" cpu: "500m" livenessProbe: httpGet: path: / port: 80 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: / port: 80 initialDelaySeconds: 5 periodSeconds: 5 --- # ========== Deploymenté…ç½® ========== apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 selector: matchLabels: app: nginx strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 0 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.25 ports: - containerPort: 80 env: - name: ENVIRONMENT value: "production" volumeMounts: - name: config-volume mountPath: /etc/nginx/config.d volumes: - name: config-volume configMap: name: nginx-config 1.2 Serviceä¸Ingress 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # ========== Serviceé…ç½® ========== apiVersion: v1 kind: Service metadata: name: nginx-service spec: type: ClusterIP selector: app: nginx ports: - port: 80 targetPort: 80 protocol: TCP --- # ========== Ingressé…ç½® ========== apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx-ingress annotations: kubernetes.io/ingress.class: nginx cert-manager.io/cluster-issuer: letsencrypt-prod nginx.ingress.kubernetes.io/ssl-redirect: "true" spec: tls: - hosts: - app.example.com secretName: app-tls rules: - host: app.example.com http: paths: - path: / pathType: Prefix backend: service: name: nginx-service port: number: 80 äºŒã€æœåŠ¡ç½‘æ ¼ 2.1 Istioé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # ========== Istio VirtualService ========== apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - match: - headers: end-user: exact: jason fault: delay: percentage: value: 100 fixedDelay: 3s route: - destination: host: reviews subset: v2 - route: - destination: host: reviews subset: v1 --- # ========== Istio DestinationRule ========== apiVersion: networking.istio.io/v1beta1 kind: DestinationRule metadata: name: reviews spec: host: reviews trafficPolicy: loadBalancer: simple: LEAST_CONN subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 trafficPolicy: loadBalancer: simple: RANDOM ä¸‰ã€äº‘åŸç”Ÿæœ€ä½³å®è·µ 3.1 å¥åº·æ£€æŸ¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 3 startupProbe: httpGet: path: /health/startup port: 8080 initialDelaySeconds: 0 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 30 3.2 èµ„æºé™åˆ¶ 1 2 3 4 5 6 7 resources: requests: memory: "256Mi" cpu: "250m" limits: memory: "512Mi" cpu: "500m" æ€»ç»“ äº‘åŸç”Ÿæ¶æ„æ˜¯ç°ä»£åº”ç”¨éƒ¨ç½²çš„æœ€ä½³å®è·µã€‚é€šè¿‡Kubernetesã€æœåŠ¡ç½‘æ ¼å’ŒDevOpsçš„ç»“åˆï¼Œå¯ä»¥æ„å»ºå¼¹æ€§ã€å¯æ‰©å±•çš„åº”ç”¨ç³»ç»Ÿã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/ class=category-link>äº‘åŸç”Ÿ</a><a href=/blog/categories/kubernetes/ class=category-link>Kubernetes</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to äº‘åŸç”Ÿæ¶æ„å®Œå…¨æŒ‡å—ï¼šKubernetesä¸å¾®æœåŠ¡å®è·µ" href=/blog/articles/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97kubernetes%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>è·¨å¹³å°ç§»åŠ¨å¼€å‘å®Œå…¨æŒ‡å—ï¼šReact Nativeä¸Flutteræ·±åº¦å®è·µ</h2></header><div class=entry-content><p>å¼•è¨€ è·¨å¹³å°ç§»åŠ¨å¼€å‘æŠ€æœ¯æ—¥è¶‹æˆç†Ÿï¼ŒReact Nativeå’ŒFlutterå·²æˆä¸ºä¸»æµé€‰æ‹©ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æä¸¤å¤§æ¡†æ¶çš„æ¶æ„è®¾è®¡ã€æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºé«˜è´¨é‡çš„ç§»åŠ¨åº”ç”¨ã€‚
ä¸€ã€React Nativeæ·±åº¦å®è·µ 1.1 æ¶æ„è®¾è®¡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 // ========== React Nativeé¡¹ç›®æ¶æ„ ========== /** * æ¨èçš„é¡¹ç›®ç»“æ„ * * src/ * â”œâ”€â”€ api/ # APIæ¥å£ * â”œâ”€â”€ assets/ # é™æ€èµ„æº * â”œâ”€â”€ components/ # é€šç”¨ç»„ä»¶ * â”‚ â”œâ”€â”€ common/ # åŸºç¡€ç»„ä»¶ * â”‚ â””â”€â”€ business/ # ä¸šåŠ¡ç»„ä»¶ * â”œâ”€â”€ navigation/ # å¯¼èˆªé…ç½® * â”œâ”€â”€ screens/ # é¡µé¢ç»„ä»¶ * â”œâ”€â”€ services/ # ä¸šåŠ¡æœåŠ¡ * â”œâ”€â”€ store/ # çŠ¶æ€ç®¡ç† * â”œâ”€â”€ utils/ # å·¥å…·å‡½æ•° * â””â”€â”€ types/ # ç±»å‹å®šä¹‰ */ // ========== çŠ¶æ€ç®¡ç†ï¼šZustand ========== import create from 'zustand'; // å®šä¹‰Storeç±»å‹ interface UserStore { user: User | null; token: string | null; isLoading: boolean; // Actions login: (credentials: Credentials) => Promise&lt;void>; logout: () => void; updateUser: (data: Partial&lt;User>) => void; } // åˆ›å»ºStore const useUserStore = create&lt;UserStore>((set, get) => ({ user: null, token: null, isLoading: false, login: async (credentials) => { set({ isLoading: true }); try { const { user, token } = await api.login(credentials); set({ user, token, isLoading: false }); // æŒä¹…åŒ– await AsyncStorage.setItem('token', token); } catch (error) { set({ isLoading: false }); throw error; } }, logout: () => { set({ user: null, token: null }); AsyncStorage.removeItem('token'); }, updateUser: (data) => { const { user } = get(); if (user) { set({ user: { ...user, ...data } }); } } })); // ========== å¯¼èˆªé…ç½® ========== import { NavigationContainer } from '@react-navigation/native'; import { createBottomTabNavigator } from '@react-navigation/bottom-tabs'; import { createStackNavigator } from '@react-navigation/stack'; // Stack Navigator const Stack = createStackNavigator(); function AppStack() { return ( &lt;Stack.Navigator screenOptions={{ headerShown: false }} > &lt;Stack.Screen name="Home" component={HomeScreen} /> &lt;Stack.Screen name="Profile" component={ProfileScreen} /> &lt;Stack.Screen name="Details" component={DetailsScreen} /> &lt;/Stack.Navigator> ); } // Tab Navigator const Tab = createBottomTabNavigator(); function AppTabs() { return ( &lt;Tab.Navigator screenOptions={({ route }) => ({ tabBarIcon: ({ focused, color, size }) => { return &lt;TabBarIcon focused={focused} name={route.name} />; }, })} > &lt;Tab.Screen name="Home" component={AppStack} /> &lt;Tab.Screen name="Search" component={SearchScreen} /> &lt;Tab.Screen name="Profile" component={ProfileScreen} /> &lt;/Tab.Navigator> ); } // ========== æ€§èƒ½ä¼˜åŒ– ========== import { memo, useMemo, useCallback, useState } from 'react'; // 1. ç»„ä»¶memoåŒ– const ListItem = memo(({ item, onPress }) => { return ( &lt;TouchableOpacity onPress={() => onPress(item)}> &lt;Text>{item.title}&lt;/Text> &lt;/TouchableOpacity> ); }, (prevProps, nextProps) => { return prevProps.item.id === nextProps.item.id; }); // 2. FlatListä¼˜åŒ– function OptimizedList({ data, onEndReached }) { const renderItem = useCallback(({ item }) => ( &lt;ListItem item={item} onPress={handlePress} /> ), []); const keyExtractor = useCallback((item) => item.id, []); return ( &lt;FlatList data={data} renderItem={renderItem} keyExtractor={keyExtractor} onEndReached={onEndReached} onEndReachedThreshold={0.5} maxToRenderPerBatch={10} windowSize={5} initialNumToRender={10} getItemLayout={(data, index) => ({ length: ITEM_HEIGHT, offset: ITEM_HEIGHT * index, index })} removeClippedSubviews={true} /> ); } // 3. å›¾ç‰‡ä¼˜åŒ– import FastImage from 'react-native-fast-image'; const OptimizedImage = memo(({ uri, style }) => { return ( &lt;FastImage style={style} source={{ uri, priority: FastImage.priority.normal, }} resizeMode={FastImage.resizeMode.cover} /> ); }); 1.2 åŸç”Ÿæ¨¡å—å¼€å‘ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 // ========== AndroidåŸç”Ÿæ¨¡å— ========== // UserModule.java package com.myapp; import com.facebook.react.bridge.ReactApplicationContext; import com.facebook.react.bridge.ReactContextBaseJavaModule; import com.facebook.react.bridge.ReactMethod; import com.facebook.react.bridge.Promise; import com.facebook.react.bridge.WritableMap; import com.facebook.react.bridge.Arguments; public class UserModule extends ReactContextBaseJavaModule { private static final String E_USER_NOT_FOUND = "E_USER_NOT_FOUND"; @Override public String getName() { return "UserModule"; } @ReactMethod public void getUserInfo(String userId, Promise promise) { try { // è°ƒç”¨Android API User user = UserManager.getUser(userId); if (user == null) { promise.reject(E_USER_NOT_FOUND, "User not found"); return; } // è½¬æ¢ä¸ºWritableMap WritableMap result = Arguments.createMap(); result.putString("id", user.getId()); result.putString("name", user.getName()); result.putString("email", user.getEmail()); promise.resolve(result); } catch (Exception e) { promise.reject("ERROR", e.getMessage()); } } } // ========== iOSåŸç”Ÿæ¨¡å— ========== // UserModule.m #import &lt;React/RCTBridgeModule.h> #import &lt;React/RCTEventEmitter.h> @interface RCT_EXTERN_MODULE(UserModule, NSObject) RCT_EXTERN_METHOD(getUserInfo:(NSString *)userId resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject) @end // UserModule.swift @objc(UserModule) class UserModule: NSObject { @objc static func requiresMainQueueSetup() -> Bool { return false } @objc(getUserInfo:resolver:rejecter:) func getUserInfo(_ userId: String, resolver: @escaping RCTPromiseResolveBlock, rejecter: @escaping RCTPromiseRejectBlock) { DispatchQueue.global(qos: .background).async { do { // è°ƒç”¨iOS API guard let user = UserManager.shared.getUser(id: userId) else { rejecter("USER_NOT_FOUND", "User not found", nil) return } let result: [String: Any] = [ "id": user.id, "name": user.name, "email": user.email ] resolver(result) } catch { rejecter("ERROR", error.localizedDescription, error) } } } } // ========== TypeScriptç±»å‹å®šä¹‰ ========== // NativeModules.d.ts declare module 'react-native' { interface NativeModulesStatic { UserModule: { getUserInfo(userId: string): Promise&lt;UserInfo>; }; } } interface UserInfo { id: string; name: string; email: string; } // ä½¿ç”¨ import { NativeModules } from 'react-native'; const { UserModule } = NativeModules; async function getUserInfo(userId: string) { try { const userInfo = await UserModule.getUserInfo(userId); console.log(userInfo); } catch (error) { console.error(error); } } äºŒã€Flutteræ·±åº¦å®è·µ 2.1 æ¶æ„è®¾è®¡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 // ========== Flutteré¡¹ç›®ç»“æ„ ========== /** * lib/ * â”œâ”€â”€ core/ # æ ¸å¿ƒåŠŸèƒ½ * â”‚ â”œâ”€â”€ constants/ # å¸¸é‡ * â”‚ â”œâ”€â”€ errors/ # é”™è¯¯å¤„ç† * â”‚ â”œâ”€â”€ network/ # ç½‘ç»œè¯·æ±‚ * â”‚ â””â”€â”€ utils/ # å·¥å…·å‡½æ•° * â”œâ”€â”€ data/ # æ•°æ®å±‚ * â”‚ â”œâ”€â”€ models/ # æ•°æ®æ¨¡å‹ * â”‚ â”œâ”€â”€ repositories/ # ä»“åº“å®ç° * â”‚ â””â”€â”€ datasources/ # æ•°æ®æº * â”œâ”€â”€ domain/ # é¢†åŸŸå±‚ * â”‚ â”œâ”€â”€ entities/ # å®ä½“ * â”‚ â”œâ”€â”€ repositories/ # ä»“åº“æ¥å£ * â”‚ â””â”€â”€ usecases/ # ç”¨ä¾‹ * â”œâ”€â”€ presentation/ # è¡¨ç°å±‚ * â”‚ â”œâ”€â”€ pages/ # é¡µé¢ * â”‚ â”œâ”€â”€ widgets/ # ç»„ä»¶ * â”‚ â””â”€â”€ bloc/ # çŠ¶æ€ç®¡ç† * â””â”€â”€ main.dart */ // ========== BLoCçŠ¶æ€ç®¡ç† ========== // user_event.dart abstract class UserEvent {} class LoginRequested extends UserEvent { final String email; final String password; LoginRequested({required this.email, required this.password}); } class LogoutRequested extends UserEvent {} // user_state.dart abstract class UserState {} class UserInitial extends UserState {} class UserLoading extends UserState {} class UserLoaded extends UserState { final User user; UserLoaded(this.user); } class UserError extends UserState { final String message; UserError(this.message); } // user_bloc.dart class UserBloc extends Bloc&lt;UserEvent, UserState> { final LoginUseCase loginUseCase; final LogoutUseCase logoutUseCase; UserBloc({ required this.loginUseCase, required this.logoutUseCase, }) : super(UserInitial()) { on&lt;LoginRequested>(_onLoginRequested); on&lt;LogoutRequested>(_onLogoutRequested); } Future&lt;void> _onLoginRequested( LoginRequested event, Emitter&lt;UserState> emit, ) async { emit(UserLoading()); final result = await loginUseCase( LoginParams(email: event.email, password: event.password), ); result.fold( (failure) => emit(UserError(failure.message)), (user) => emit(UserLoaded(user)), ); } Future&lt;void> _onLogoutRequested( LogoutRequested event, Emitter&lt;UserState> emit, ) async { await logoutUseCase(); emit(UserInitial()); } } // ========== ä¾èµ–æ³¨å…¥ ========== // service_locator.dart final getIt = GetIt.instance; void initDependencies() { // å¤–éƒ¨ä¾èµ– getIt.registerLazySingleton(() => http.Client()); getIt.registerLazySingleton(() => SharedPreferences.getInstance()); // æ•°æ®æº getIt.registerLazySingleton&lt;UserRemoteDataSource>( () => UserRemoteDataSourceImpl(client: getIt()), ); getIt.registerLazySingleton&lt;UserLocalDataSource>( () => UserLocalDataSourceImpl(sharedPreferences: getIt()), ); // ä»“åº“ getIt.registerLazySingleton&lt;UserRepository>( () => UserRepositoryImpl( remoteDataSource: getIt(), localDataSource: getIt(), ), ); // ç”¨ä¾‹ getIt.registerLazySingleton( () => LoginUseCase(repository: getIt()), ); getIt.registerLazySingleton( () => LogoutUseCase(repository: getIt()), ); // BLoC getIt.registerFactory( () => UserBloc( loginUseCase: getIt(), logoutUseCase: getIt(), ), ); } 2.2 æ€§èƒ½ä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 // ========== æ€§èƒ½ä¼˜åŒ–æŠ€å·§ ========== // 1. ä½¿ç”¨constæ„é€ å‡½æ•° class MyWidget extends StatelessWidget { @override Widget build(BuildContext context) { return const Text('Hello'); // const } } // 2. é¿å…åœ¨buildä¸­åˆ›å»ºå¯¹è±¡ class OptimizedWidget extends StatelessWidget { final String text; const OptimizedWidget({Key? key, required this.text}) : super(key: key); static final _style = TextStyle(fontSize: 16); // é™æ€ @override Widget build(BuildContext context) { return Text(text, style: _style); } } // 3. ListViewä¼˜åŒ– class OptimizedListView extends StatelessWidget { final List&lt;Item> items; const OptimizedListView({Key? key, required this.items}) : super(key: key); @override Widget build(BuildContext context) { return ListView.builder( itemCount: items.length, // æ·»åŠ itemExtentæå‡æ€§èƒ½ itemExtent: 60, itemBuilder: (context, index) { return ListTile( title: Text(items[index].title), ); }, ); } } // 4. å›¾ç‰‡ç¼“å­˜ class CachedImageWidget extends StatelessWidget { final String imageUrl; const CachedImageWidget({Key? key, required this.imageUrl}) : super(key: key); @override Widget build(BuildContext context) { return CachedNetworkImage( imageUrl: imageUrl, placeholder: (context, url) => CircularProgressIndicator(), errorWidget: (context, url, error) => Icon(Icons.error), fadeInDuration: Duration(milliseconds: 300), ); } } // 5. ä½¿ç”¨RepaintBoundary class RepaintBoundaryWidget extends StatelessWidget { @override Widget build(BuildContext context) { return RepaintBoundary( child: AnimatedContainer( duration: Duration(milliseconds: 300), color: Colors.blue, ), ); } } // ========== Isolateä½¿ç”¨ ========== import 'dart:isolate'; // åœ¨æ–°Isolateä¸­æ‰§è¡Œè€—æ—¶æ“ä½œ Future&lt;ProcessedData> processInBackground(RawData data) async { final receivePort = ReceivePort(); await Isolate.spawn( _isolateEntryPoint, _IsolateMessage(data: data, sendPort: receivePort.sendPort), ); final result = await receivePort.first as ProcessedData; return result; } void _isolateEntryPoint(_IsolateMessage message) { final processed = _heavyComputation(message.data); message.sendPort.send(processed); } ProcessedData _heavyComputation(RawData data) { // æ‰§è¡Œè€—æ—¶è®¡ç®— return ProcessedData(/* ... */); } class _IsolateMessage { final RawData data; final SendPort sendPort; _IsolateMessage({required this.data, required this.sendPort}); } ä¸‰ã€è·¨å¹³å°æŠ€æœ¯é€‰å‹ ç‰¹æ€§ React Native Flutter å¼€å‘è¯­è¨€ JavaScript/TypeScript Dart æ€§èƒ½ æ¥è¿‘åŸç”Ÿ æ¥è¿‘åŸç”Ÿ UIæ¸²æŸ“ åŸç”Ÿç»„ä»¶ è‡ªç»˜å¼•æ“ çƒ­é‡è½½ æ”¯æŒ æ”¯æŒ åŒ…ä½“ç§¯ è¾ƒå° è¾ƒå¤§ å­¦ä¹ æ›²çº¿ è¾ƒå¹³ç¼“ ä¸­ç­‰ ç¤¾åŒºç”Ÿæ€ æˆç†Ÿ å¿«é€Ÿå¢é•¿ å¤§å‹åº”ç”¨ Facebookã€Instagram Google Adsã€Alibaba æ€»ç»“ é€‰æ‹©è·¨å¹³å°æ¡†æ¶éœ€è¦è€ƒè™‘å›¢é˜ŸæŠ€æœ¯æ ˆã€é¡¹ç›®éœ€æ±‚å’Œé•¿æœŸç»´æŠ¤ã€‚React Nativeé€‚åˆWebèƒŒæ™¯å›¢é˜Ÿï¼ŒFlutteråˆ™æä¾›æ›´å¥½çš„æ€§èƒ½å’Œä¸€è‡´æ€§ã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/ class=category-link>ç§»åŠ¨å¼€å‘</a><a href=/blog/categories/%E8%B7%A8%E5%B9%B3%E5%8F%B0/ class=category-link>è·¨å¹³å°</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to è·¨å¹³å°ç§»åŠ¨å¼€å‘å®Œå…¨æŒ‡å—ï¼šReact Nativeä¸Flutteræ·±åº¦å®è·µ" href=/blog/articles/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97react-native%E4%B8%8Eflutter%E6%B7%B1%E5%BA%A6%E5%AE%9E%E8%B7%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>æ•°æ®åº“ä¼˜åŒ–ä¸åˆ†å¸ƒå¼å­˜å‚¨ï¼šæ„å»ºé«˜æ€§èƒ½æ•°æ®æ¶æ„</h2></header><div class=entry-content><p>å¼•è¨€ æ•°æ®æ˜¯ç°ä»£åº”ç”¨çš„æ ¸å¿ƒèµ„äº§ã€‚éšç€æ•°æ®é‡çš„çˆ†ç‚¸å¼å¢é•¿ï¼Œæ•°æ®åº“æ€§èƒ½å’Œå¯æ‰©å±•æ€§æˆä¸ºç³»ç»Ÿè®¾è®¡çš„å…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨æ•°æ®åº“ä¼˜åŒ–æŠ€å·§å’Œåˆ†å¸ƒå¼å­˜å‚¨æ¶æ„ï¼Œå¸®åŠ©è¯»è€…æ„å»ºé«˜æ€§èƒ½çš„æ•°æ®æ¶æ„ã€‚
ä¸€ã€æ•°æ®åº“æ€§èƒ½ä¼˜åŒ– 1.1 ç´¢å¼•ä¼˜åŒ–ç­–ç•¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 -- ========== ç´¢å¼•åŸºç¡€ ========== -- 1. B-Treeç´¢å¼•ï¼ˆæœ€å¸¸ç”¨ï¼‰ -- é€‚åˆï¼šç­‰å€¼æŸ¥è¯¢ã€èŒƒå›´æŸ¥è¯¢ã€æ’åº CREATE INDEX idx_user_email ON users(email); CREATE INDEX idx_order_created ON orders(created_at); -- 2. å¤åˆç´¢å¼• -- æ³¨æ„ï¼šæœ€å·¦å‰ç¼€åŸåˆ™ CREATE INDEX idx_user_status_created ON users(status, created_at); -- æœ‰æ•ˆçš„æŸ¥è¯¢ï¼ˆèƒ½ä½¿ç”¨ç´¢å¼•ï¼‰ SELECT * FROM users WHERE status = 1 AND created_at > '2024-01-01'; SELECT * FROM users WHERE status = 1; -- æ— æ•ˆçš„æŸ¥è¯¢ï¼ˆä¸èƒ½ä½¿ç”¨ç´¢å¼•ï¼‰ SELECT * FROM users WHERE created_at > '2024-01-01'; -- 3. è¦†ç›–ç´¢å¼• -- åŒ…å«æŸ¥è¯¢æ‰€éœ€çš„æ‰€æœ‰å­—æ®µï¼Œé¿å…å›è¡¨ CREATE INDEX idx_user_cover ON users(status, created_at, id, name); -- 4. å”¯ä¸€ç´¢å¼• CREATE UNIQUE INDEX idx_user_username ON users(username); -- ========== ç´¢å¼•è®¾è®¡åŸåˆ™ ========== /* 1. é€‰æ‹©æ€§é«˜çš„å­—æ®µé€‚åˆå»ºç´¢å¼• - é«˜é€‰æ‹©æ€§ï¼šå”¯ä¸€å€¼å¤šï¼ˆå¦‚ç”¨æˆ·IDã€é‚®ç®±ï¼‰ - ä½é€‰æ‹©æ€§ï¼šé‡å¤å€¼å¤šï¼ˆå¦‚æ€§åˆ«ã€çŠ¶æ€ï¼‰ 2. WHEREã€JOINã€ORDER BYå­å¥çš„å­—æ®µ 3. å°å­—æ®µä¼˜å…ˆ - æ•´æ•° > æ—¥æœŸ > çŸ­å­—ç¬¦ä¸² > é•¿å­—ç¬¦ä¸² 4. è”åˆç´¢å¼•çš„é¡ºåº - æœ€å¸¸æŸ¥è¯¢çš„å­—æ®µæ”¾å‰é¢ - èŒƒå›´æŸ¥è¯¢å­—æ®µæ”¾åé¢ 5. é¿å…è¿‡å¤šç´¢å¼• - é™ä½å†™å…¥æ€§èƒ½ - å ç”¨å­˜å‚¨ç©ºé—´ */ -- ========== ç´¢å¼•ä¼˜åŒ–æ¡ˆä¾‹ ========== -- é—®é¢˜ï¼šæŸ¥è¯¢æ…¢ -- è€—æ—¶ï¼š2.5ç§’ SELECT * FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.status = 'pending' AND o.created_at > '2024-01-01' ORDER BY o.created_at DESC LIMIT 20; -- ä¼˜åŒ–1ï¼šæ·»åŠ åˆé€‚ç´¢å¼• CREATE INDEX idx_orders_status_created ON orders(status, created_at DESC); CREATE INDEX idx_orders_user_id ON orders(user_id); -- è€—æ—¶ï¼š0.3ç§’ -- ä¼˜åŒ–2ï¼šåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µ SELECT o.id, o.order_no, o.total_amount, u.username FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.status = 'pending' AND o.created_at > '2024-01-01' ORDER BY o.created_at DESC LIMIT 20; -- è€—æ—¶ï¼š0.1ç§’ -- ä¼˜åŒ–3ï¼šä½¿ç”¨è¦†ç›–ç´¢å¼• CREATE INDEX idx_orders_cover ON orders( status, created_at DESC, id, order_no, total_amount, user_id ); -- è€—æ—¶ï¼š0.05ç§’ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 # ========== ç´¢å¼•åˆ†æä¸ç»´æŠ¤ ========== import pymysql from typing import List, Dict, Tuple class IndexAnalyzer: """ç´¢å¼•åˆ†æå™¨""" def __init__(self, connection_config: dict): self.conn = pymysql.connect(**connection_config) def analyze_table_indexes(self, table_name: str) -> List[Dict]: """åˆ†æè¡¨çš„ç´¢å¼•ä½¿ç”¨æƒ…å†µ""" with self.conn.cursor() as cursor: # æŸ¥è¯¢ç´¢å¼•ä¿¡æ¯ sql = """ SHOW INDEX FROM %s """ % table_name cursor.execute(sql) indexes = cursor.fetchall() # æŸ¥è¯¢ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡ sql = """ SELECT table_name, index_name, cardinality, column_name, seq_in_index FROM information_schema.statistics WHERE table_schema = DATABASE() AND table_name = %s ORDER BY index_name, seq_in_index """ cursor.execute(sql, (table_name,)) stats = cursor.fetchall() return { 'indexes': indexes, 'statistics': stats } def find_unused_indexes(self) -> List[Dict]: """æŸ¥æ‰¾æœªä½¿ç”¨çš„ç´¢å¼•""" with self.conn.cursor() as cursor: # MySQL 5.7+ ä½¿ç”¨performance_schema sql = """ SELECT object_schema AS table_schema, object_name AS table_name, index_name FROM performance_schema.table_io_waits_summary_by_index_usage WHERE index_name IS NOT NULL AND count_star = 0 AND index_name != 'PRIMARY' ORDER BY object_schema, object_name """ cursor.execute(sql) return cursor.fetchall() def find_duplicate_indexes(self, table_name: str) -> List[Tuple]: """æŸ¥æ‰¾å†—ä½™ç´¢å¼•""" with self.conn.cursor() as cursor: # æŸ¥è¯¢ç´¢å¼•åŠå…¶åˆ— sql = """ SELECT index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) as columns FROM information_schema.statistics WHERE table_schema = DATABASE() AND table_name = %s GROUP BY index_name HAVING COUNT(*) > 1 """ cursor.execute(sql, (table_name,)) indexes = cursor.fetchall() # æŸ¥æ‰¾å†—ä½™ç´¢å¼• duplicates = [] for i, idx1 in enumerate(indexes): for idx2 in indexes[i+1:]: # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³ç³» if idx2[1].startswith(idx1[1]): duplicates.append((idx1[0], idx2[0])) return duplicates def suggest_indexes(self, table_name: str) -> List[Dict]: """æ¨èç´¢å¼•""" with self.conn.cursor() as cursor: # åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿— sql = """ SELECT sql_text, count(*) as frequency FROM mysql.slow_log WHERE sql_text LIKE %s GROUP BY sql_text ORDER BY frequency DESC LIMIT 10 """ cursor.execute(sql, (f'%{table_name}%',)) slow_queries = cursor.fetchall() suggestions = [] for query, freq in slow_queries: # æå–WHEREæ¡ä»¶å­—æ®µ # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦è§£æSQL # ... suggestions.append({ 'query': query, 'frequency': freq, 'suggested_index': 'å»ºè®®åŸºäºWHEREå­å¥åˆ›å»ºç´¢å¼•' }) return suggestions 1.2 æŸ¥è¯¢ä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 -- ========== SQLæŸ¥è¯¢ä¼˜åŒ– ========== -- 1. é¿å…SELECT * -- ä¸æ¨è SELECT * FROM users WHERE id = 1; -- æ¨è SELECT id, username, email FROM users WHERE id = 1; -- 2. ä½¿ç”¨LIMITé™åˆ¶ç»“æœé›† SELECT * FROM orders WHERE status = 'pending' LIMIT 100; -- 3. ä¼˜åŒ–JOIN -- å°è¡¨é©±åŠ¨å¤§è¡¨ SELECT * FROM small_table s JOIN large_table l ON s.id = l.small_id; -- 4. å­æŸ¥è¯¢ä¼˜åŒ– -- ä¸æ¨è SELECT * FROM users WHERE id IN (SELECT user_id FROM orders WHERE amount > 1000); -- æ¨è SELECT DISTINCT u.* FROM users u INNER JOIN orders o ON u.id = o.user_id WHERE o.amount > 1000; -- 5. EXISTS vs IN -- å°è¡¨ç”¨INï¼Œå¤§è¡¨ç”¨EXISTS -- å°è¡¨ SELECT * FROM users WHERE id IN (1, 2, 3); -- å¤§è¡¨ SELECT * FROM users u WHERE EXISTS ( SELECT 1 FROM orders o WHERE o.user_id = u.id AND o.status = 'pending' ); -- 6. é¿å…åœ¨WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•° -- ä¸æ¨è SELECT * FROM orders WHERE DATE(created_at) = '2024-01-01'; -- æ¨è SELECT * FROM orders WHERE created_at >= '2024-01-01' AND created_at &lt; '2024-01-02'; -- 7. ä½¿ç”¨UNION ALLä»£æ›¿UNION -- ä¸æ¨èï¼ˆå»é‡å¼€é”€å¤§ï¼‰ SELECT user_id FROM orders_2024 UNION SELECT user_id FROM orders_2023; -- æ¨è SELECT user_id FROM orders_2024 UNION ALL SELECT user_id FROM orders_2023; -- 8. æ‰¹é‡æ“ä½œ -- ä¸æ¨èï¼ˆå¤šæ¬¡å•æ¡æ’å…¥ï¼‰ INSERT INTO logs (message) VALUES ('log1'); INSERT INTO logs (message) VALUES ('log2'); INSERT INTO logs (message) VALUES ('log3'); -- æ¨è INSERT INTO logs (message) VALUES ('log1'), ('log2'), ('log3'); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 # ========== æŸ¥è¯¢ä¼˜åŒ–å™¨ ========== import re from typing import List, Dict, Tuple class SQLQueryOptimizer: """SQLæŸ¥è¯¢ä¼˜åŒ–å™¨""" def __init__(self): self.rules = { 'select_star': self._check_select_star, 'missing_where': self._check_missing_where, 'function_in_where': self._check_function_in_where, 'subquery': self._check_subquery, 'nplus1': self._check_nplus1 } def optimize(self, sql: str) -> Dict: """ä¼˜åŒ–SQL""" issues = [] suggestions = [] for rule_name, rule_func in self.rules.items(): result = rule_func(sql) if result: issues.append(result['issue']) suggestions.append(result['suggestion']) return { 'original_sql': sql, 'issues': issues, 'suggestions': suggestions } def _check_select_star(self, sql: str) -> Dict: """æ£€æŸ¥SELECT ***""" if re.search(r'SELECT\s+\*\s+FROM', sql, re.IGNORECASE): return { 'issue': 'ä½¿ç”¨SELECT *', 'suggestion': 'åªæŸ¥è¯¢éœ€è¦çš„åˆ—ï¼Œå‡å°‘æ•°æ®ä¼ è¾“' } return None def _check_missing_where(self, sql: str) -> Dict: """æ£€æŸ¥ç¼ºå°‘WHEREæ¡ä»¶""" if re.search(r'(DELETE|UPDATE)\s+\w+\s+(?!WHERE)', sql, re.IGNORECASE): return { 'issue': 'DELETE/UPDATEç¼ºå°‘WHEREæ¡ä»¶', 'suggestion': 'æ·»åŠ WHEREæ¡ä»¶ï¼Œé¿å…å…¨è¡¨æ“ä½œ' } return None def _check_function_in_where(self, sql: str) -> Dict: """æ£€æŸ¥WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•°""" if re.search( r'WHERE\s+.*(?:DATE|YEAR|MONTH|DAY)\(', sql, re.IGNORECASE ): return { 'issue': 'WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•°', 'suggestion': 'å°†å‡½æ•°ä½œç”¨åˆ°æ¯”è¾ƒå€¼ä¸Šï¼Œè€Œéå­—æ®µ' } return None def _check_subquery(self, sql: str) -> Dict: """æ£€æŸ¥å­æŸ¥è¯¢""" if 'IN (SELECT' in sql.upper(): return { 'issue': 'ä½¿ç”¨INå­æŸ¥è¯¢', 'suggestion': 'è€ƒè™‘æ”¹ç”¨JOINæˆ–EXISTS' } return None def _check_nplus1(self, sql: str) -> Dict: """æ£€æŸ¥N+1æŸ¥è¯¢""" # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦åˆ†ææ‰§è¡Œæ¨¡å¼ return None class QueryExecutionAnalyzer: """æŸ¥è¯¢æ‰§è¡Œåˆ†æå™¨""" def __init__(self, connection): self.conn = connection def explain_query(self, sql: str) -> Dict: """åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’""" with self.conn.cursor() as cursor: # æ‰§è¡ŒEXPLAIN explain_sql = f"EXPLAIN {sql}" cursor.execute(explain_sql) result = cursor.fetchall() analysis = { 'type': [], 'table': [], 'possible_keys': [], 'key': [], 'rows': [], 'filtered': [], 'extra': [] } for row in result: analysis['type'].append(row['type']) analysis['table'].append(row['table']) analysis['possible_keys'].append(row['possible_keys']) analysis['key'].append(row['key']) analysis['rows'].append(row['rows']) analysis['filtered'].append(row['filtered']) analysis['extra'].append(row['Extra']) # åˆ†æç»“æœ suggestions = [] # æ£€æŸ¥æ˜¯å¦å…¨è¡¨æ‰«æ if 'ALL' in analysis['type']: suggestions.append( 'è­¦å‘Šï¼šå­˜åœ¨å…¨è¡¨æ‰«æï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•' ) # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼• if None in analysis['key']: suggestions.append( 'éƒ¨åˆ†æŸ¥è¯¢æ²¡æœ‰ä½¿ç”¨ç´¢å¼•ï¼Œæ£€æŸ¥ç´¢å¼•è®¾è®¡' ) # æ£€æŸ¥æ‰«æè¡Œæ•° if analysis['rows'] and sum(analysis['rows']) > 10000: suggestions.append( 'æ‰«æè¡Œæ•°è¾ƒå¤šï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–ç´¢å¼•' ) return { 'explain_plan': result, 'suggestions': suggestions } def profile_query(self, sql: str) -> Dict: """åˆ†ææŸ¥è¯¢æ€§èƒ½""" with self.conn.cursor() as cursor: # å¼€å¯profiling cursor.execute("SET profiling = 1") # æ‰§è¡ŒæŸ¥è¯¢ cursor.execute(sql) # è·å–profilingç»“æœ cursor.execute("SHOW PROFILE") profile = cursor.fetchall() # è·å–æŸ¥è¯¢ç»Ÿè®¡ cursor.execute("SHOW PROFILE FOR QUERY 1") stats = cursor.fetchall() return { 'profile': profile, 'statistics': stats } äºŒã€åˆ†åº“åˆ†è¡¨ç­–ç•¥ 2.1 æ°´å¹³åˆ†è¡¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 # ========== åˆ†è¡¨ç­–ç•¥ ========== class ShardingStrategy: """åˆ†ç‰‡ç­–ç•¥""" def __init__(self, shard_count: int): self.shard_count = shard_count def hash_sharding(self, key: str) -> int: """å“ˆå¸Œåˆ†ç‰‡""" hash_value = hash(key) return hash_value % self.shard_count def range_sharding(self, key: int) -> int: """èŒƒå›´åˆ†ç‰‡""" # å‡è®¾keyæ˜¯è‡ªå¢ID shard_size = 1000000 # æ¯ä¸ªåˆ†ç‰‡100ä¸‡æ¡ return key // shard_size def modulo_sharding(self, key: int) -> int: """å–æ¨¡åˆ†ç‰‡""" return key % self.shard_count def consistent_hash_sharding(self, key: str) -> int: """ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡""" import hashlib hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16) return hash_value % self.shard_count class ShardingManager: """åˆ†ç‰‡ç®¡ç†å™¨""" def __init__(self, shard_configs: List[dict]): self.shards = {} for config in shard_configs: shard_id = config['id'] self.shards[shard_id] = { 'connection': self._create_connection(config), 'config': config } self.strategy = ShardingStrategy(len(shard_configs)) def _create_connection(self, config: dict): """åˆ›å»ºæ•°æ®åº“è¿æ¥""" import pymysql return pymysql.connect( host=config['host'], port=config['port'], user=config['user'], password=config['password'], database=config['database'] ) def get_shard(self, shard_key: str, sharding_type: str = 'hash'): """è·å–åˆ†ç‰‡è¿æ¥""" if sharding_type == 'hash': shard_id = self.strategy.hash_sharding(shard_key) elif sharding_type == 'consistent': shard_id = self.strategy.consistent_hash_sharding(shard_key) elif sharding_type == 'modulo': shard_id = self.strategy.modulo_sharding(int(shard_key)) else: raise ValueError(f"Unknown sharding type: {sharding_type}") return self.shards[shard_id]['connection'] def execute_on_shard(self, shard_key: str, sql: str, params=None): """åœ¨æŒ‡å®šåˆ†ç‰‡æ‰§è¡ŒSQL""" conn = self.get_shard(shard_key) with conn.cursor() as cursor: cursor.execute(sql, params or ()) return cursor.fetchall() def query_all_shards(self, sql: str, params=None): """æŸ¥è¯¢æ‰€æœ‰åˆ†ç‰‡""" results = [] for shard_id, shard in self.shards.items(): conn = shard['connection'] with conn.cursor() as cursor: cursor.execute(sql, params or ()) shard_results = cursor.fetchall() # æ·»åŠ åˆ†ç‰‡æ ‡è¯† for row in shard_results: if isinstance(row, dict): row['_shard_id'] = shard_id results.extend(shard_results) return results def broadcast_write(self, sql: str, params=None): """å¹¿æ’­å†™å…¥æ‰€æœ‰åˆ†ç‰‡""" results = [] for shard_id, shard in self.shards.items(): conn = shard['connection'] with conn.cursor() as cursor: cursor.execute(sql, params or ()) conn.commit() results.append({ 'shard_id': shard_id, 'affected_rows': cursor.rowcount }) return results # ========== åˆ†è¡¨è·¯ç”± ========== class TableRouter: """è¡¨è·¯ç”±""" def __init__(self, sharding_manager: ShardingManager): self.manager = sharding_manager self.table_rules = {} def add_rule(self, table_name: str, sharding_key: str, sharding_type: str): """æ·»åŠ åˆ†è¡¨è§„åˆ™""" self.table_rules[table_name] = { 'sharding_key': sharding_key, 'sharding_type': sharding_type } def get_table_name(self, original_table: str, shard_key: str) -> str: """è·å–å®é™…è¡¨å""" rule = self.table_rules.get(original_table) if not rule: return original_table # è®¡ç®—åˆ†ç‰‡ID if rule['sharding_type'] == 'hash': shard_id = hash(shard_key) % self.manager.strategy.shard_count elif rule['sharding_type'] == 'modulo': shard_id = int(shard_key) % self.manager.strategy.shard_count else: shard_id = 0 return f"{original_table}_{shard_id:04d}" def execute_query(self, table_name: str, query_template: str, **kwargs): """æ‰§è¡Œåˆ†è¡¨æŸ¥è¯¢""" # è·å–åˆ†ç‰‡é”®å€¼ rule = self.table_rules.get(table_name) if not rule: # ä¸åˆ†è¡¨ï¼Œç›´æ¥æ‰§è¡Œ return self.manager.execute_on_shard('0', query_template, kwargs) shard_key_value = kwargs.get(rule['sharding_key']) if not shard_key_value: raise ValueError(f"Missing sharding key: {rule['sharding_key']}") # è·å–å®é™…è¡¨å actual_table = self.get_table_name(table_name, str(shard_key_value)) # æ›¿æ¢è¡¨å actual_query = query_template.replace(f'FROM {table_name}', f'FROM {actual_table}') return self.manager.execute_on_shard(str(shard_key_value), actual_query, kwargs) # ä½¿ç”¨ç¤ºä¾‹ shard_configs = [ { 'id': 0, 'host': 'db0.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_0' }, { 'id': 1, 'host': 'db1.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_1' }, { 'id': 2, 'host': 'db2.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_2' }, { 'id': 3, 'host': 'db3.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_3' } ] sharding_manager = ShardingManager(shard_configs) table_router = TableRouter(sharding_manager) # é…ç½®ordersè¡¨æŒ‰user_idåˆ†è¡¨ table_router.add_rule('orders', 'user_id', 'modulo') # æ’å…¥è®¢å•ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„åˆ†ç‰‡ï¼‰ table_router.execute_query( 'orders', "INSERT INTO orders (user_id, order_no, total_amount) VALUES (:user_id, :order_no, :total_amount)", user_id=12345, order_no='ORD2024010112345', total_amount=9999.99 ) # æŸ¥è¯¢è®¢å•ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„åˆ†ç‰‡ï¼‰ results = table_router.execute_query( 'orders', "SELECT * FROM orders WHERE user_id = :user_id", user_id=12345 ) 2.2 å‚ç›´åˆ†åº“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 # ========== å‚ç›´åˆ†åº“ç­–ç•¥ ========== class VerticalSharding: """å‚ç›´åˆ†åº“""" def __init__(self): self.databases = { 'user_db': None, # ç”¨æˆ·ç›¸å…³è¡¨ 'order_db': None, # è®¢å•ç›¸å…³è¡¨ 'product_db': None, # å•†å“ç›¸å…³è¡¨ 'log_db': None # æ—¥å¿—ç›¸å…³è¡¨ } def route_by_module(self, table_name: str): """æŒ‰æ¨¡å—è·¯ç”±""" module_mapping = { # ç”¨æˆ·æ¨¡å— 'users': 'user_db', 'user_profiles': 'user_db', 'user_addresses': 'user_db', 'user_preferences': 'user_db', # è®¢å•æ¨¡å— 'orders': 'order_db', 'order_items': 'order_db', 'order_payments': 'order_db', 'order_shippings': 'order_db', # å•†å“æ¨¡å— 'products': 'product_db', 'categories': 'product_db', 'product_skus': 'product_db', 'inventory': 'product_db', # æ—¥å¿—æ¨¡å— 'operation_logs': 'log_db', 'access_logs': 'log_db', 'error_logs': 'log_db' } return self.databases.get(module_mapping.get(table_name)) def cross_database_query(self, queries: List[dict]): """è·¨åº“æŸ¥è¯¢""" results = {} for query_info in queries: db_name = query_info['database'] sql = query_info['sql'] params = query_info.get('params', {}) conn = self.databases[db_name] with conn.cursor() as cursor: cursor.execute(sql, params) results[db_name] = cursor.fetchall() # åœ¨åº”ç”¨å±‚åˆå¹¶ç»“æœ return self._merge_results(results) def _merge_results(self, results: dict) -> List[dict]: """åˆå¹¶è·¨åº“æŸ¥è¯¢ç»“æœ""" # æ ¹æ®ä¸šåŠ¡é€»è¾‘åˆå¹¶ç»“æœ # è¿™é‡Œæ˜¯ç®€åŒ–ç¤ºä¾‹ merged = [] # ä»user_dbè·å–ç”¨æˆ·ä¿¡æ¯ users = results.get('user_db', []) # ä»order_dbè·å–è®¢å•ä¿¡æ¯ orders = results.get('order_db', []) # åˆå¹¶æ•°æ® user_dict = {user['id']: user for user in users} for order in orders: user_id = order['user_id'] if user_id in user_dict: merged.append({ **user_dict[user_id], 'order': order }) return merged # ========== åˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆSagaæ¨¡å¼ï¼‰ ========== class DistributedTransaction: """åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç†å™¨""" def __init__(self): self.participants = [] self.compensations = [] def add_participant(self, database: str, operation: str, compensation: str): """æ·»åŠ äº‹åŠ¡å‚ä¸è€…""" self.participants.append({ 'database': database, 'operation': operation }) self.compensations.append({ 'database': database, 'operation': compensation }) async def execute(self) -> bool: """æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡""" executed = [] try: # é¡ºåºæ‰§è¡Œå„åˆ†åº“æ“ä½œ for participant in self.participants: conn = self.databases[participant['database']] with conn.cursor() as cursor: cursor.execute(participant['operation']) conn.commit() executed.append(participant) return True except Exception as e: # æ‰§è¡Œè¡¥å¿æ“ä½œ for i in range(len(executed) - 1, -1, -1): compensation = self.compensations[i] try: conn = self.databases[compensation['database']] with conn.cursor() as cursor: cursor.execute(compensation['operation']) conn.commit() except Exception as ce: # è¡¥å¿å¤±è´¥ï¼Œè®°å½•æ—¥å¿— print(f"Compensation failed: {ce}") return False ä¸‰ã€åˆ†å¸ƒå¼æ•°æ®åº“ 3.1 NewSQLæ•°æ®åº“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 # ========== TiDBé›†æˆç¤ºä¾‹ ========== import MySQLdb class TiDBClient: """TiDBå®¢æˆ·ç«¯""" def __init__(self, host: str, port: int, user: str, password: str, database: str): self.conn = MySQLdb.connect( host=host, port=port, user=user, password=password, database=database, charset='utf8mb4' ) def insert_batch(self, table: str, records: List[dict]) -> int: """æ‰¹é‡æ’å…¥""" if not records: return 0 # æ„å»ºæ‰¹é‡æ’å…¥SQL columns = list(records[0].keys()) placeholders = ', '.join(['%s'] * len(columns)) sql = f""" INSERT INTO {table} ({', '.join(columns)}) VALUES ({placeholders}) """ values = [ tuple(record[col] for col in columns) for record in records ] with self.conn.cursor() as cursor: cursor.executemany(sql, values) self.conn.commit() return cursor.rowcount def select_with_pagination( self, table: str, where: str = None, order_by: str = None, limit: int = 100, offset: int = 0 ) -> List[dict]: """åˆ†é¡µæŸ¥è¯¢""" sql = f"SELECT * FROM {table}" if where: sql += f" WHERE {where}" if order_by: sql += f" ORDER BY {order_by}" sql += f" LIMIT {limit} OFFSET {offset}" with self.conn.cursor(MySQLdb.cursors.DictCursor) as cursor: cursor.execute(sql) return cursor.fetchall() def get_transaction_info(self) -> dict: """è·å–äº‹åŠ¡ä¿¡æ¯""" with self.conn.cursor() as cursor: # æŸ¥è¯¢å½“å‰äº‹åŠ¡ä¿¡æ¯ cursor.execute("SELECT @@txn_version as version") version = cursor.fetchone() cursor.execute("SELECT @@autocommit as autocommit") autocommit = cursor.fetchone() return { 'version': version[0] if version else None, 'autocommit': autocommit[0] if autocommit else None } # ========== åˆ†å¸ƒå¼äº‹åŠ¡ä½¿ç”¨ ========== class DistributedOrderService: """åˆ†å¸ƒå¼è®¢å•æœåŠ¡""" def __init__(self, tidb_client: TiDBClient): self.tidb = tidb_client async def create_order(self, order_data: dict, items: List[dict]) -> str: """åˆ›å»ºè®¢å•ï¼ˆåˆ†å¸ƒå¼äº‹åŠ¡ï¼‰""" try: # å¼€å¯äº‹åŠ¡ with self.tidb.conn as cursor: # 1. åˆ›å»ºè®¢å• order_sql = """ INSERT INTO orders (user_id, order_no, total_amount, status) VALUES (%s, %s, %s, %s) """ cursor.execute(order_sql, ( order_data['user_id'], order_data['order_no'], order_data['total_amount'], 'pending' )) order_id = cursor.lastrowid # 2. åˆ›å»ºè®¢å•æ˜ç»† for item in items: item_sql = """ INSERT INTO order_items ( order_id, product_id, quantity, price ) VALUES (%s, %s, %s, %s) """ cursor.execute(item_sql, ( order_id, item['product_id'], item['quantity'], item['price'] )) # 3. æ‰£å‡åº“å­˜ for item in items: inventory_sql = """ UPDATE inventory SET stock = stock - %s WHERE product_id = %s AND stock >= %s """ affected = cursor.execute(inventory_sql, ( item['quantity'], item['product_id'], item['quantity'] )) if affected == 0: # åº“å­˜ä¸è¶³ï¼Œå›æ»šäº‹åŠ¡ raise Exception(f"Insufficient stock for product {item['product_id']}") # 4. åˆ›å»ºæ”¯ä»˜è®°å½• payment_sql = """ INSERT INTO payments ( order_id, amount, status, payment_method ) VALUES (%s, %s, %s, %s) """ cursor.execute(payment_sql, ( order_id, order_data['total_amount'], 'pending', order_data['payment_method'] )) # æäº¤äº‹åŠ¡ self.tidb.conn.commit() return order_id except Exception as e: # å›æ»šäº‹åŠ¡ self.tidb.conn.rollback() raise e 3.2 åˆ†å¸ƒå¼ç¼“å­˜ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 # ========== Redisé›†ç¾¤ ========== import redis from rediscluster import RedisCluster class RedisClusterClient: """Redisé›†ç¾¤å®¢æˆ·ç«¯""" def __init__(self, startup_nodes: List[dict]): """ startup_nodes: [ {'host': 'redis1.example.com', 'port': 7000}, {'host': 'redis2.example.com', 'port': 7001}, {'host': 'redis3.example.com', 'port': 7002} ] """ self.client = RedisCluster( startup_nodes=startup_nodes, decode_responses=True, skip_full_coverage_check=True, max_connections=32 ) def set(self, key: str, value: str, expire: int = None): """è®¾ç½®é”®å€¼""" return self.client.set(key, value, ex=expire) def get(self, key: str) -> str: """è·å–å€¼""" return self.client.get(key) def mget(self, keys: List[str]) -> List[str]: """æ‰¹é‡è·å–""" return self.client.mget(keys) def delete(self, *keys: str): """åˆ é™¤é”®""" return self.client.delete(*keys) def exists(self, *keys: str) -> int: """æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨""" return self.client.exists(*keys) def expire(self, key: str, seconds: int): """è®¾ç½®è¿‡æœŸæ—¶é—´""" return self.client.expire(key, seconds) def incr(self, key: str, amount: int = 1) -> int: """é€’å¢""" return self.client.incrby(key, amount) def decr(self, key: str, amount: int = 1) -> int: """é€’å‡""" return self.client.decrby(key, amount) def hset(self, name: str, key: str, value: str): """å“ˆå¸Œè¡¨è®¾ç½®""" return self.client.hset(name, key, value) def hget(self, name: str, key: str) -> str: """å“ˆå¸Œè¡¨è·å–""" return self.client.hget(name, key) def hgetall(self, name: str) -> dict: """è·å–æ•´ä¸ªå“ˆå¸Œè¡¨""" return self.client.hgetall(name) # ========== ç¼“å­˜ç­–ç•¥ ========== class CacheStrategy: """ç¼“å­˜ç­–ç•¥""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def cache_aside(self, key: str, load_func, expire: int = 3600): """Cache-Asideæ¨¡å¼""" # å…ˆæŸ¥ç¼“å­˜ value = self.redis.get(key) if value is not None: return value # ç¼“å­˜æœªå‘½ä¸­ï¼ŒåŠ è½½æ•°æ® value = load_func() # å†™å…¥ç¼“å­˜ self.redis.set(key, value, expire) return value def invalidate(self, *keys: str): """ä½¿ç¼“å­˜å¤±æ•ˆ""" self.redis.delete(*keys) def warm_up(self, data: dict, expire: int = 3600): """ç¼“å­˜é¢„çƒ­""" pipe = self.redis.client.pipeline() for key, value in data.items(): pipe.set(key, value, expire) pipe.execute() def update(self, key: str, value: str, expire: int = 3600): """æ›´æ–°ç¼“å­˜""" self.redis.set(key, value, expire) # ========== åˆ†å¸ƒå¼é” ========== class DistributedLock: """åˆ†å¸ƒå¼é”""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def acquire( self, lock_name: str, acquire_timeout: int = 10, lock_timeout: int = 30 ) -> bool: """è·å–é”""" import time lock_key = f"lock:{lock_name}" lock_value = f"{time.time()}" end_time = time.time() + acquire_timeout while time.time() &lt; end_time: # å°è¯•è·å–é” if self.redis.client.set( lock_key, lock_value, nx=True, ex=lock_timeout ): return True time.sleep(0.001) return False def release(self, lock_name: str): """é‡Šæ”¾é”""" lock_key = f"lock:{lock_name}" # ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åªé‡Šæ”¾è‡ªå·±çš„é” lua_script = """ if redis.call("get", KEYS[1]) == ARGV[1] then return redis.call("del", KEYS[1]) else return 0 end """ self.redis.client.eval( lua_script, 1, lock_key, self.redis.get(lock_key) ) # ========== é™æµå™¨ ========== class RateLimiter: """åˆ†å¸ƒå¼é™æµå™¨""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def is_allowed( self, key: str, limit: int, window: int ) -> bool: """ æ»‘åŠ¨çª—å£é™æµ key: é™æµé”®ï¼ˆå¦‚ç”¨æˆ·IDã€IPç­‰ï¼‰ limit: æ—¶é—´çª—å£å†…æœ€å¤§è¯·æ±‚æ•° window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ """ import time now = time.time() window_start = now - window pipe = self.redis.client.pipeline() # ç§»é™¤æ—¶é—´çª—å£å¤–çš„è®°å½• pipe.zremrangebyscore(key, 0, window_start) # è·å–å½“å‰è®¡æ•° pipe.zcard(key) # æ·»åŠ å½“å‰è¯·æ±‚ pipe.zadd(key, {str(now): now}) # è®¾ç½®è¿‡æœŸæ—¶é—´ pipe.expire(key, window + 1) results = pipe.execute() current_count = results[1] return current_count &lt; limit å››ã€æ•°æ®åº“ç›‘æ§ä¸è¿ç»´ 4.1 æ€§èƒ½ç›‘æ§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 # ========== æ•°æ®åº“ç›‘æ§ ========== class DatabaseMonitor: """æ•°æ®åº“ç›‘æ§""" def __init__(self, connection): self.conn = connection def get_connection_stats(self) -> dict: """è·å–è¿æ¥ç»Ÿè®¡""" with self.conn.cursor() as cursor: cursor.execute(""" SHOW STATUS LIKE 'Threads%' """) stats = cursor.fetchall() return { 'threads_connected': next( (s[1] for s in stats if s[0] == 'Threads_connected'), 0 ), 'threads_running': next( (s[1] for s in stats if s[0] == 'Threads_running'), 0 ) } def get_query_stats(self) -> dict: """è·å–æŸ¥è¯¢ç»Ÿè®¡""" with self.conn.cursor() as cursor: # æ…¢æŸ¥è¯¢ç»Ÿè®¡ cursor.execute(""" SELECT COUNT(*) as slow_query_count, AVG(query_time) as avg_query_time, MAX(query_time) as max_query_time FROM mysql.slow_log WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR) """) slow_stats = cursor.fetchone() # QPS/TPSç»Ÿè®¡ cursor.execute(""" SHOW STATUS LIKE 'Questions' """) questions = cursor.fetchone() cursor.execute(""" SHOW STATUS LIKE 'Uptime' """) uptime = cursor.fetchone() qps = questions[1] / uptime[1] if uptime[1] > 0 else 0 return { 'slow_query_count': slow_stats[0], 'avg_query_time': float(slow_stats[1]) if slow_stats[1] else 0, 'max_query_time': float(slow_stats[2]) if slow_stats[2] else 0, 'qps': round(qps, 2) } def get_replication_lag(self) -> int: """è·å–ä¸»ä»å»¶è¿Ÿ""" with self.conn.cursor() as cursor: cursor.execute("SHOW SLAVE STATUS") status = cursor.fetchone() if status: return status['Seconds_Behind_Master'] return 0 def get_innodb_stats(self) -> dict: """è·å–InnoDBç»Ÿè®¡""" with self.conn.cursor() as cursor: cursor.execute(""" SHOW STATUS LIKE 'Innodb_%' """) stats = cursor.fetchall() return { 'row_lock_waits': next( (s[1] for s in stats if s[0] == 'Innodb_row_lock_current_waits'), 0 ), 'deadlocks': next( (s[1] for s in stats if s[0] == 'Innodb_deadlocks'), 0 ), 'buffer_pool_hit_rate': self._calculate_hit_rate(stats) } def _calculate_hit_rate(self, stats: list) -> float: """è®¡ç®—ç¼“å†²æ± å‘½ä¸­ç‡""" reads = next( (s[1] for s in stats if s[0] == 'Innodb_buffer_pool_reads'), 0 ) read_requests = next( (s[1] for s in stats if s[0] == 'Innodb_buffer_pool_read_requests'), 1 ) if read_requests == 0: return 100.0 hit_rate = (1 - reads / read_requests) * 100 return round(hit_rate, 2) # ========== æ…¢æŸ¥è¯¢åˆ†æ ========== class SlowQueryAnalyzer: """æ…¢æŸ¥è¯¢åˆ†æå™¨""" def __init__(self, connection): self.conn = connection def get_slow_queries(self, limit: int = 100) -> List[dict]: """è·å–æ…¢æŸ¥è¯¢""" with self.conn.cursor() as cursor: sql = """ SELECT query_time, lock_time, rows_sent, rows_examined, sql_text FROM mysql.slow_log ORDER BY query_time DESC LIMIT %s """ cursor.execute(sql, (limit,)) return cursor.fetchall() def analyze_slow_query(self, query: str) -> dict: """åˆ†ææ…¢æŸ¥è¯¢""" analyzer = SQLQueryOptimizer() return analyzer.optimize(query) def suggest_indexes(self, query: str) -> List[str]: """æ¨èç´¢å¼•""" # æå–WHEREã€JOINã€ORDER BYå­å¥ä¸­çš„å­—æ®µ # è¿™é‡Œç®€åŒ–å¤„ç† import re # æå–è¡¨å tables = re.findall(r'FROM\s+(\w+)', query, re.IGNORECASE) tables += re.findall(r'JOIN\s+(\w+)', query, re.IGNORECASE) # æå–WHEREæ¡ä»¶å­—æ®µ where_fields = re.findall( r'WHERE\s+(\w+)\.\w+\s*=', query, re.IGNORECASE ) suggestions = [] for table in set(tables): for field in set(where_fields): suggestions.append( f"CREATE INDEX idx_{table}_{field} ON {table}({field})" ) return suggestions 4.2 å¤‡ä»½ä¸æ¢å¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 # ========== æ•°æ®åº“å¤‡ä»½ ========== import subprocess import os from datetime import datetime from typing import List class DatabaseBackup: """æ•°æ®åº“å¤‡ä»½""" def __init__( self, host: str, user: str, password: str, backup_dir: str = '/backup' ): self.host = host self.user = user self.password = password self.backup_dir = backup_dir os.makedirs(backup_dir, exist_ok=True) def backup_database( self, database: str, backup_type: str = 'full' ) -> str: """å¤‡ä»½æ•°æ®åº“""" timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') backup_file = os.path.join( self.backup_dir, f"{database}_{backup_type}_{timestamp}.sql" ) # ä½¿ç”¨mysqldumpå¤‡ä»½ command = [ 'mysqldump', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}', '--single-transaction', '--routines', '--triggers', '--events', '--quick', database ] with open(backup_file, 'w') as f: subprocess.run( command, stdout=f, stderr=subprocess.PIPE, check=True ) # å‹ç¼©å¤‡ä»½æ–‡ä»¶ self._compress_file(backup_file) return f"{backup_file}.gz" def backup_all_databases(self) -> str: """å¤‡ä»½æ‰€æœ‰æ•°æ®åº“""" timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') backup_file = os.path.join( self.backup_dir, f"all_databases_{timestamp}.sql" ) command = [ 'mysqldump', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}', '--all-databases', '--single-transaction', '--routines', '--triggers', '--events' ] with open(backup_file, 'w') as f: subprocess.run( command, stdout=f, stderr=subprocess.PIPE, check=True ) self._compress_file(backup_file) return f"{backup_file}.gz" def _compress_file(self, filepath: str): """å‹ç¼©æ–‡ä»¶""" import gzip with open(filepath, 'rb') as f_in: with gzip.open(f"{filepath}.gz", 'wb') as f_out: f_out.writelines(f_in) os.remove(filepath) def restore_database(self, backup_file: str, database: str = None): """æ¢å¤æ•°æ®åº“""" # è§£å‹å¤‡ä»½æ–‡ä»¶ if backup_file.endswith('.gz'): import gzip temp_file = backup_file[:-3] with gzip.open(backup_file, 'rb') as f_in: with open(temp_file, 'wb') as f_out: f_out.writelines(f_in) backup_file = temp_file # æ¢å¤æ•°æ®åº“ command = [ 'mysql', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}' ] if database: command.append(database) with open(backup_file, 'r') as f: subprocess.run( command, stdin=f, stderr=subprocess.PIPE, check=True ) # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ if backup_file.endswith('.sql'): os.remove(backup_file) def list_backups(self) -> List[dict]: """åˆ—å‡ºå¤‡ä»½æ–‡ä»¶""" backups = [] for filename in os.listdir(self.backup_dir): if filename.endswith('.sql.gz'): filepath = os.path.join(self.backup_dir, filename) stat = os.stat(filepath) backups.append({ 'filename': filename, 'size': stat.st_size, 'created_at': datetime.fromtimestamp(stat.st_ctime) }) return sorted(backups, key=lambda x: x['created_at'], reverse=True) def cleanup_old_backups(self, keep_days: int = 7): """æ¸…ç†æ—§å¤‡ä»½""" from datetime import timedelta cutoff_time = datetime.now() - timedelta(days=keep_days) for filename in os.listdir(self.backup_dir): filepath = os.path.join(self.backup_dir, filename) stat = os.stat(filepath) if datetime.fromtimestamp(stat.st_ctime) &lt; cutoff_time: os.remove(filepath) print(f"Removed old backup: {filename}") æ€»ç»“ æ„å»ºé«˜æ€§èƒ½çš„æ•°æ®æ¶æ„éœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/ class=category-link>æ•°æ®åº“</a><a href=/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/ class=category-link>åˆ†å¸ƒå¼ç³»ç»Ÿ</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to æ•°æ®åº“ä¼˜åŒ–ä¸åˆ†å¸ƒå¼å­˜å‚¨ï¼šæ„å»ºé«˜æ€§èƒ½æ•°æ®æ¶æ„" href=/blog/articles/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%9E%84%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ç½‘ç»œå®‰å…¨ä¸æ¼æ´æ·±åº¦åˆ†æï¼šä»æ”»å‡»åˆ°é˜²å¾¡çš„å®Œæ•´æŒ‡å—</h2></header><div class=entry-content><p>å¼•è¨€ ç½‘ç»œå®‰å…¨æ˜¯æ•°å­—åŒ–æ—¶ä»£çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚éšç€æ”»å‡»æ‰‹æ®µçš„ä¸æ–­æ¼”è¿›ï¼Œäº†è§£å¸¸è§æ¼æ´ã€æ”»å‡»æ–¹æ³•å’Œé˜²å¾¡ç­–ç•¥å˜å¾—è‡³å…³é‡è¦ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æç½‘ç»œå®‰å…¨é¢†åŸŸçš„æ ¸å¿ƒä¸»é¢˜ï¼Œå¸®åŠ©è¯»è€…æ„å»ºæ›´å®‰å…¨çš„ç³»ç»Ÿã€‚
ä¸€ã€OWASP Top 10æ·±åº¦è§£æ 1.1 æ³¨å…¥æ¼æ´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 # ========== SQLæ³¨å…¥ ========== # ä¸å®‰å…¨çš„ä»£ç ç¤ºä¾‹ def get_user_by_id(user_id): """å±é™©ï¼šç›´æ¥æ‹¼æ¥SQL""" query = f"SELECT * FROM users WHERE id = {user_id}" return db.execute(query) # æ”»å‡»ç¤ºä¾‹ # user_id = "1 OR 1=1" # å®é™…æ‰§è¡Œçš„SQL: SELECT * FROM users WHERE id = 1 OR 1=1 # ç»“æœï¼šè¿”å›æ‰€æœ‰ç”¨æˆ·æ•°æ® # å®‰å…¨çš„ä»£ç ç¤ºä¾‹ import sqlite3 from typing import Optional class UserRepository: """å®‰å…¨çš„ç”¨æˆ·ä»“åº“""" def __init__(self, db_path: str): self.conn = sqlite3.connect(db_path) def get_user_by_id(self, user_id: int) -> Optional[dict]: """ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢""" cursor = self.conn.cursor() # ä½¿ç”¨?å ä½ç¬¦ï¼Œæ•°æ®åº“é©±åŠ¨ä¼šæ­£ç¡®è½¬ä¹‰å‚æ•° query = "SELECT * FROM users WHERE id = ?" cursor.execute(query, (user_id,)) row = cursor.fetchone() if row: return { 'id': row[0], 'username': row[1], 'email': row[2] } return None def search_users(self, keyword: str) -> list: """å®‰å…¨çš„æœç´¢åŠŸèƒ½""" cursor = self.conn.cursor() query = """ SELECT id, username, email FROM users WHERE username LIKE ? OR email LIKE ? """ # ä½¿ç”¨é€šé…ç¬¦è¿›è¡Œæ¨¡ç³Šæœç´¢ pattern = f"%{keyword}%" cursor.execute(query, (pattern, pattern)) return cursor.fetchall() # ========== SQLæ³¨å…¥æ£€æµ‹ä¸é˜²å¾¡ ========== class SQLInjectionDetector: """SQLæ³¨å…¥æ£€æµ‹å™¨""" # å¸¸è§SQLæ³¨å…¥ç‰¹å¾ INJECTION_PATTERNS = [ r"(\%27)|(\')", # å•å¼•å· r"(\-\-)|(#)", # æ³¨é‡Šç¬¦ r"(\bor\b|\band\b).*?=.*?", # é€»è¾‘è¿ç®—ç¬¦ r"(\bunion\b.*\bselect\b)", # UNIONæŸ¥è¯¢ r"(\bselect\b.*\bfrom\b)", # SELECTæŸ¥è¯¢ r"(\bexec\b|\bexecute\b)", # æ‰§è¡Œå‘½ä»¤ r"(;|\bxp_cmdshell\b)", # å‘½ä»¤åˆ†éš”ç¬¦å’Œå­˜å‚¨è¿‡ç¨‹ r"(\bdrop\b|\bdelete\b|\btruncate\b)", # å±é™©æ“ä½œ ] @classmethod def detect_injection(cls, input_string: str) -> bool: """æ£€æµ‹SQLæ³¨å…¥""" import re for pattern in cls.INJECTION_PATTERNS: if re.search(pattern, input_string, re.IGNORECASE): return True return False @classmethod def sanitize_input(cls, input_string: str) -> str: """æ¸…ç†è¾“å…¥""" import re # ç§»é™¤å±é™©å­—ç¬¦ sanitized = re.sub(r"[\'\"\;\-\-]", "", input_string) # é™åˆ¶é•¿åº¦ max_length = 100 sanitized = sanitized[:max_length] return sanitized # ========== ORMå®‰å…¨ä½¿ç”¨ ========== from sqlalchemy import create_engine, Column, Integer, String from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker Base = declarative_base() class User(Base): """ç”¨æˆ·æ¨¡å‹""" __tablename__ = 'users' id = Column(Integer, primary_key=True) username = Column(String(50), nullable=False) email = Column(String(100), nullable=False) class SecureUserRepository: """ä½¿ç”¨ORMçš„å®‰å…¨ä»“åº“""" def __init__(self, database_url: str): self.engine = create_engine(database_url) Session = sessionmaker(bind=self.engine) self.session = Session() def get_user_by_id(self, user_id: int) -> Optional[User]: """ORMè‡ªåŠ¨å¤„ç†å‚æ•°åŒ–""" return self.session.query(User).filter( User.id == user_id ).first() def search_users(self, keyword: str) -> list: """å®‰å…¨çš„æœç´¢""" return self.session.query(User).filter( (User.username.like(f"%{keyword}%")) | (User.email.like(f"%{keyword}%")) ).all() 1.2 è·¨ç«™è„šæœ¬æ”»å‡»(XSS) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 # ========== XSSæ”»å‡»ç±»å‹ ========== """ 1. åå°„å‹XSS (Reflected XSS) - æ¶æ„ä»£ç é€šè¿‡URLå‚æ•°åå°„ - ä¾‹å¦‚: http://example.com/search?q=&lt;script>alert('XSS')&lt;/script> 2. å­˜å‚¨å‹XSS (Stored XSS) - æ¶æ„ä»£ç å­˜å‚¨åœ¨æœåŠ¡å™¨ï¼Œæ¯æ¬¡è®¿é—®æ—¶æ‰§è¡Œ - ä¾‹å¦‚: è¯„è®ºã€ç”¨æˆ·èµ„æ–™ç­‰å¯å­˜å‚¨çš„å†…å®¹ 3. DOMå‹XSS (DOM-based XSS) - æ¶æ„ä»£ç é€šè¿‡DOMæ“ä½œæ‰§è¡Œ - ä¾‹å¦‚: #&lt;img src=x onerror=alert('XSS')> """ # ========== XSSé˜²å¾¡ ========== import html import re from typing import Dict, Any class XSSProtection: """XSSé˜²æŠ¤""" @staticmethod def escape_html(text: str) -> str: """HTMLè½¬ä¹‰""" return html.escape(text, quote=True) @staticmethod def escape_js(text: str) -> str: """JavaScriptå­—ç¬¦ä¸²è½¬ä¹‰""" escape_map = { '\\': '\\\\', '"': '\\"', "'": "\\'", '\n': '\\n', '\r': '\\r', '\t': '\\t', '\b': '\\b', '\f': '\\f', } for char, escaped in escape_map.items(): text = text.replace(char, escaped) return text @staticmethod def sanitize_html(content: str, allowed_tags: list = None) -> str: """HTMLå‡€åŒ–ï¼Œåªå…è®¸å®‰å…¨çš„æ ‡ç­¾""" if allowed_tags is None: allowed_tags = ['p', 'br', 'strong', 'em', 'u', 'a'] import bleach return bleach.clean( content, tags=allowed_tags, attributes={ 'a': ['href', 'title'], '*': ['class'] }, strip=True ) @staticmethod def validate_url(url: str) -> bool: """éªŒè¯URLå®‰å…¨æ€§""" import urllib.parse try: parsed = urllib.parse.urlparse(url) # æ£€æŸ¥åè®® if parsed.scheme not in ['http', 'https']: return False # æ£€æŸ¥æ˜¯å¦ä¸ºJavaScriptä¼ªåè®® if parsed.scheme.lower() == 'javascript': return False return True except Exception: return False # Webæ¡†æ¶é›†æˆç¤ºä¾‹ from flask import Flask, request, render_template_string app = Flask(__name__) # ä¸å®‰å…¨çš„ç¤ºä¾‹ @app.route('/unsafe') def unsafe_search(): query = request.args.get('q', '') # å±é™©ï¼šç›´æ¥æ¸²æŸ“ç”¨æˆ·è¾“å…¥ return render_template_string(f'&lt;p>æœç´¢ç»“æœ: {query}&lt;/p>') # å®‰å…¨çš„ç¤ºä¾‹ @app.route('/safe') def safe_search(): query = request.args.get('q', '') # è½¬ä¹‰ç”¨æˆ·è¾“å…¥ safe_query = XSSProtection.escape_html(query) # æˆ–ä½¿ç”¨æ¨¡æ¿å¼•æ“çš„è‡ªåŠ¨è½¬ä¹‰ return render_template_string( '&lt;p>æœç´¢ç»“æœ: {{ query }}&lt;/p>', query=safe_query ) # Content Security Policy (CSP) @app.after_request def add_security_headers(response): """æ·»åŠ å®‰å…¨å¤´""" csp = ( "default-src 'self'; " "script-src 'self' 'unsafe-inline' https://cdn.example.com; " "style-src 'self' 'unsafe-inline'; " "img-src 'self' data: https:; " "font-src 'self' data:; " "connect-src 'self'; " "frame-ancestors 'none';" ) response.headers['Content-Security-Policy'] = csp response.headers['X-Content-Type-Options'] = 'nosniff' response.headers['X-Frame-Options'] = 'DENY' response.headers['X-XSS-Protection'] = '1; mode=block' return response # ========== è¾“å…¥éªŒè¯ ========== class InputValidator: """è¾“å…¥éªŒè¯å™¨""" @staticmethod def validate_username(username: str) -> bool: """éªŒè¯ç”¨æˆ·å""" # é•¿åº¦æ£€æŸ¥ if len(username) &lt; 3 or len(username) > 20: return False # å­—ç¬¦æ£€æŸ¥ï¼šåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ import re pattern = r'^[a-zA-Z0-9_]+$' return bool(re.match(pattern, username)) @staticmethod def validate_email(email: str) -> bool: """éªŒè¯é‚®ç®±""" import re pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$' return bool(re.match(pattern, email)) @staticmethod def validate_phone(phone: str) -> bool: """éªŒè¯æ‰‹æœºå·""" import re pattern = r'^1[3-9]\d{9}$' return bool(re.match(pattern, phone)) 1.3 CSRFé˜²æŠ¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 # ========== CSRFæ”»å‡»åŸç† ========== """ CSRF (Cross-Site Request Forgery) è·¨ç«™è¯·æ±‚ä¼ªé€  æ”»å‡»åœºæ™¯ï¼š 1. ç”¨æˆ·ç™»å½•äº†é“¶è¡Œç½‘ç«™ bank.com 2. ç”¨æˆ·è®¿é—®äº†æ¶æ„ç½‘ç«™ evil.com 3. evil.com åŒ…å«æŒ‡å‘ bank.com çš„è¯·æ±‚ &lt;img src="http://bank.com/transfer?to=attacker&amp;amount=10000"> 4. æµè§ˆå™¨è‡ªåŠ¨æºå¸¦ bank.com çš„ cookie 5. é“¶è¡Œç½‘ç«™å¤„ç†è½¬è´¦è¯·æ±‚ é˜²å¾¡æªæ–½ï¼š 1. CSRF Token 2. SameSite Cookieå±æ€§ 3. éªŒè¯Referer/Originå¤´ 4. åŒé‡æäº¤Cookie """ # ========== CSRFé˜²æŠ¤å®ç° ========== import secrets from flask import Flask, request, session, render_template app = Flask(__name__) app.secret_key = secrets.token_hex(32) class CSRFProtection: """CSRFé˜²æŠ¤""" @staticmethod def generate_token() -> str: """ç”ŸæˆCSRF Token""" return secrets.token_hex(32) @staticmethod def validate_token(token: str, stored_token: str) -> bool: """éªŒè¯Token""" return secrets.compare_digest(token, stored_token) # åœ¨Flaskä¸­ä½¿ç”¨CSRFä¿æŠ¤ @app.before_request def csrf_protect(): """CSRFä¿æŠ¤ä¸­é—´ä»¶""" # è±å…å®‰å…¨çš„æ–¹æ³• if request.method in ['GET', 'HEAD', 'OPTIONS', 'TRACE']: return # æ£€æŸ¥CSRF Token token = request.headers.get('X-CSRF-Token') or request.form.get('csrf_token') if not token or token != session.get('csrf_token'): return 'Invalid CSRF token', 403 @app.route('/form') def show_form(): """æ˜¾ç¤ºè¡¨å•""" # ç”Ÿæˆå¹¶å­˜å‚¨CSRF Token csrf_token = CSRFProtection.generate_token() session['csrf_token'] = csrf_token return f''' &lt;form method="POST" action="/submit"> &lt;input type="hidden" name="csrf_token" value="{csrf_token}"> &lt;input type="text" name="username"> &lt;button type="submit">æäº¤&lt;/button> &lt;/form> ''' @app.route('/submit', methods=['POST']) def handle_submit(): """å¤„ç†è¡¨å•æäº¤""" # Tokenå·²åœ¨ä¸­é—´ä»¶éªŒè¯ username = request.form.get('username') # ä¸šåŠ¡é€»è¾‘ return f'Hello, {username}!' # ========== SameSite Cookie ========== @app.route('/login', methods=['POST']) def login(): """ç™»å½•""" # è®¾ç½®SameSiteå±æ€§ response = app.make_response('Login successful') # Strict: ä¸¥æ ¼æ¨¡å¼ï¼Œåªåœ¨åŒç«™ç‚¹è¯·æ±‚ä¸­å‘é€ response.set_cookie( 'session_id', value='session_data', httponly=True, secure=True, samesite='Strict' ) return response # ========== åŒé‡CookieéªŒè¯ ========== class DoubleSubmitCookie: """åŒé‡Cookie CSRFé˜²æŠ¤""" @staticmethod def generate_token(): """ç”ŸæˆTokenå¹¶è®¾ç½®åˆ°Cookie""" token = secrets.token_hex(32) @app.after_this_request def add_cookie(response): response.set_cookie( 'csrf_token', token, httponly=True, secure=True, samesite='Strict' ) return response return token @staticmethod def validate(request): """éªŒè¯Token""" cookie_token = request.cookies.get('csrf_token') request_token = request.form.get('csrf_token') or \ request.headers.get('X-CSRF-Token') return secrets.compare_digest(cookie_token, request_token) äºŒã€å…¶ä»–å¸¸è§Webæ¼æ´ 2.1 æ–‡ä»¶ä¸Šä¼ æ¼æ´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 # ========== æ–‡ä»¶ä¸Šä¼ å®‰å…¨ ========== import os import magic from werkzeug.utils import secure_filename from typing import Tuple class SecureFileUpload: """å®‰å…¨çš„æ–‡ä»¶ä¸Šä¼ """ # å…è®¸çš„æ–‡ä»¶ç±»å‹ ALLOWED_EXTENSIONS = { 'image': {'jpg', 'jpeg', 'png', 'gif', 'webp'}, 'document': {'pdf', 'doc', 'docx', 'txt'}, 'media': {'mp4', 'mp3', 'wav'} } # å…è®¸çš„MIMEç±»å‹ ALLOWED_MIME_TYPES = { 'image/jpeg', 'image/png', 'image/gif', 'image/webp', 'application/pdf', 'video/mp4', 'audio/mpeg' } # æœ€å¤§æ–‡ä»¶å¤§å° (10MB) MAX_FILE_SIZE = 10 * 1024 * 1024 def __init__(self, upload_dir: str): self.upload_dir = upload_dir os.makedirs(upload_dir, exist_ok=True) def validate_file(self, file) -> Tuple[bool, str]: """éªŒè¯æ–‡ä»¶""" # æ£€æŸ¥æ–‡ä»¶å filename = secure_filename(file.filename) if not filename: return False, "Invalid filename" # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else '' if ext not in set().union(*self.ALLOWED_EXTENSIONS.values()): return False, f"File extension '{ext}' not allowed" # æ£€æŸ¥æ–‡ä»¶å¤§å° file.seek(0, os.SEEK_END) file_size = file.tell() file.seek(0) if file_size > self.MAX_FILE_SIZE: return False, f"File size exceeds {self.MAX_FILE_SIZE} bytes" # æ£€æŸ¥MIMEç±»å‹ file_content = file.read() mime_type = magic.from_buffer(file_content, mime=True) if mime_type not in self.ALLOWED_MIME_TYPES: return False, f"MIME type '{mime_type}' not allowed" # éªŒè¯æ‰©å±•åå’ŒMIMEç±»å‹æ˜¯å¦åŒ¹é… ext_mime_map = { 'jpg': 'image/jpeg', 'jpeg': 'image/jpeg', 'png': 'image/png', 'gif': 'image/gif', 'pdf': 'application/pdf' } if ext in ext_mime_map and ext_mime_map[ext] != mime_type: return False, "File extension does not match content" return True, "Valid file" def save_file(self, file) -> Tuple[bool, str]: """ä¿å­˜æ–‡ä»¶""" # éªŒè¯æ–‡ä»¶ is_valid, message = self.validate_file(file) if not is_valid: return False, message # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å import uuid original_filename = secure_filename(file.filename) ext = original_filename.rsplit('.', 1)[1].lower() safe_filename = f"{uuid.uuid4().hex}.{ext}" # ä¿å­˜æ–‡ä»¶ filepath = os.path.join(self.upload_dir, safe_filename) file.seek(0) file.save(filepath) # è®¾ç½®æ–‡ä»¶æƒé™ os.chmod(filepath, 0o644) return True, safe_filename # Flaskè·¯ç”±ç¤ºä¾‹ from flask import Flask, request, jsonify app = Flask(__name__) uploader = SecureFileUpload('/var/uploads') @app.route('/upload', methods=['POST']) def upload_file(): """æ–‡ä»¶ä¸Šä¼ æ¥å£""" if 'file' not in request.files: return jsonify({'error': 'No file provided'}), 400 file = request.files['file'] if file.filename == '': return jsonify({'error': 'Empty filename'}), 400 # ä¿å­˜æ–‡ä»¶ success, message = uploader.save_file(file) if success: return jsonify({ 'success': True, 'filename': message }) else: return jsonify({ 'success': False, 'error': message }), 400 2.2 æƒé™ç»•è¿‡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 # ========== æƒé™æ§åˆ¶ ========== from functools import wraps from flask import session, request, jsonify class PermissionChecker: """æƒé™æ£€æŸ¥å™¨""" # æƒé™å®šä¹‰ PERMISSIONS = { 'user:read': 'æŸ¥çœ‹ç”¨æˆ·ä¿¡æ¯', 'user:write': 'ä¿®æ”¹ç”¨æˆ·ä¿¡æ¯', 'user:delete': 'åˆ é™¤ç”¨æˆ·', 'admin:panel': 'è®¿é—®ç®¡ç†é¢æ¿', 'system:config': 'ä¿®æ”¹ç³»ç»Ÿé…ç½®' } # è§’è‰²æƒé™æ˜ å°„ ROLE_PERMISSIONS = { 'guest': ['user:read'], 'user': ['user:read', 'user:write'], 'moderator': ['user:read', 'user:write', 'user:delete'], 'admin': ['admin:panel', 'system:config'], 'superadmin': ['*'] # æ‰€æœ‰æƒé™ } @classmethod def has_permission(cls, role: str, required_permission: str) -> bool: """æ£€æŸ¥è§’è‰²æ˜¯å¦æœ‰æƒé™""" if role not in cls.ROLE_PERMISSIONS: return False permissions = cls.ROLE_PERMISSIONS[role] # è¶…çº§ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™ if '*' in permissions: return True return required_permission in permissions # è£…é¥°å™¨å®ç°æƒé™æ§åˆ¶ def require_permission(permission: str): """æƒé™æ£€æŸ¥è£…é¥°å™¨""" def decorator(f): @wraps(f) def decorated_function(*args, **kwargs): # ä»sessionè·å–ç”¨æˆ·è§’è‰² role = session.get('role', 'guest') # æ£€æŸ¥æƒé™ if not PermissionChecker.has_permission(role, permission): return jsonify({ 'error': 'Permission denied', 'required': permission }), 403 return f(*args, **kwargs) return decorated_function return decorator # èµ„æºæ‰€æœ‰è€…æ£€æŸ¥ def require_owner_or_admin(model_name: str, id_param: str = 'id'): """èµ„æºæ‰€æœ‰è€…æˆ–ç®¡ç†å‘˜æƒé™æ£€æŸ¥""" def decorator(f): @wraps(f) def decorated_function(*args, **kwargs): user_id = session.get('user_id') role = session.get('role', 'guest') # ç®¡ç†å‘˜è·³è¿‡æ£€æŸ¥ if role == 'superadmin': return f(*args, **kwargs) # è·å–èµ„æºID resource_id = kwargs.get(id_param) or request.view_args.get(id_param) # æ£€æŸ¥èµ„æºæ‰€æœ‰è€… from database import get_db db = get_db() resource = db.query(model_name).get(resource_id) if resource and resource.owner_id == user_id: return f(*args, **kwargs) return jsonify({'error': 'Resource access denied'}), 403 return decorated_function return decorator # ä½¿ç”¨ç¤ºä¾‹ @app.route('/users/&lt;int:id>', methods=['GET']) @require_permission('user:read') def get_user(id): """è·å–ç”¨æˆ·ä¿¡æ¯""" return jsonify({'user': f'User {id}'}) @app.route('/users/&lt;int:id>', methods=['PUT']) @require_permission('user:write') @require_owner_or_admin('User', 'id') def update_user(id): """æ›´æ–°ç”¨æˆ·ä¿¡æ¯""" return jsonify({'success': True}) @app.route('/users/&lt;int:id>', methods=['DELETE']) @require_permission('user:delete') def delete_user(id): """åˆ é™¤ç”¨æˆ·""" return jsonify({'success': True}) # ========== æ°´å¹³è¶Šæƒé˜²æŠ¤ ========== class AccessControl: """è®¿é—®æ§åˆ¶""" @staticmethod def check_resource_access(user_id: int, resource_id: int, resource_type: str) -> bool: """æ£€æŸ¥èµ„æºè®¿é—®æƒé™""" from database import get_db db = get_db() # æ£€æŸ¥èµ„æºæ˜¯å¦å­˜åœ¨ resource = db.query(resource_type).get(resource_id) if not resource: return False # æ£€æŸ¥èµ„æºæ‰€æœ‰è€… if resource.owner_id == user_id: return True # æ£€æŸ¥å…±äº«æƒé™ if hasattr(resource, 'shared_with'): if user_id in resource.shared_with: return True return False @staticmethod def check_id_or_id_list(user_input, max_length: int = 1000) -> bool: """æ£€æŸ¥IDå‚æ•°ï¼Œé˜²æ­¢IDéå†æ”»å‡»""" # å•ä¸ªID if isinstance(user_input, int): return 0 &lt; user_input &lt; max_length # IDåˆ—è¡¨ if isinstance(user_input, list): if len(user_input) > 100: # é™åˆ¶åˆ—è¡¨é•¿åº¦ return False return all( isinstance(id, int) and 0 &lt; id &lt; max_length for id in user_input ) return False ä¸‰ã€æ¸—é€æµ‹è¯•ä¸æ¼æ´æŒ–æ˜ 3.1 ä¿¡æ¯æ”¶é›† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 # ========== ä¿¡æ¯æ”¶é›†å·¥å…· ========== import requests import dns.resolver import socket from typing import List, Dict, Set from urllib.parse import urlparse import re class InformationGathering: """ä¿¡æ¯æ”¶é›†""" def __init__(self, target: str): self.target = target self.results = { 'subdomains': set(), 'open_ports': [], 'technologies': [], 'sensitive_files': [], 'emails': set(), 'social_accounts': set() } def enumerate_subdomains(self) -> Set[str]: """å­åŸŸåæšä¸¾""" wordlist = [ 'www', 'mail', 'ftp', 'admin', 'blog', 'api', 'dev', 'staging', 'test', 'app', 'mobile' ] for subdomain in wordlist: domain = f"{subdomain}.{self.target}" try: # DNSæŸ¥è¯¢ dns.resolver.resolve(domain, 'A') self.results['subdomains'].add(domain) except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer): continue return self.results['subdomains'] def scan_ports(self, ports: List[int] = None) -> List[int]: """ç«¯å£æ‰«æ""" if ports is None: ports = [21, 22, 23, 25, 53, 80, 110, 443, 445, 3306, 3389, 8080] open_ports = [] for port in ports: sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.settimeout(1) try: sock.connect((self.target, port)) open_ports.append(port) except socket.error: pass finally: sock.close() self.results['open_ports'] = open_ports return open_ports def identify_technologies(self) -> List[str]: """æŠ€æœ¯æ ˆè¯†åˆ«""" url = f"http://{self.target}" try: response = requests.get(url, timeout=10) # æ£€æŸ¥å“åº”å¤´ headers = response.headers technologies = [] # Serverå¤´ if 'Server' in headers: technologies.append(f"Server: {headers['Server']}") # X-Powered-Byå¤´ if 'X-Powered-By' in headers: technologies.append(f"PoweredBy: {headers['X-Powered-By']}") # æ£€æŸ¥HTMLä¸­çš„æŠ€æœ¯ç‰¹å¾ content = response.text # WordPress if 'wp-content' in content: technologies.append("WordPress") # jQuery if 'jquery' in content.lower(): technologies.append("jQuery") # React if 'react' in content.lower(): technologies.append("React") # Vue if 'vue' in content.lower(): technologies.append("Vue") self.results['technologies'] = technologies except requests.RequestException: pass return self.results['technologies'] def find_sensitive_files(self) -> List[str]: """æ•æ„Ÿæ–‡ä»¶æ‰«æ""" sensitive_paths = [ '/robots.txt', '/.git/config', '/.env', '/wp-config.php', '/web.config', '/.htaccess', '/admin', '/phpmyadmin', '/backup.zip', '/database.sql' ] found_files = [] for path in sensitive_paths: url = f"http://{self.target}{path}" try: response = requests.get(url, timeout=5) if response.status_code in [200, 301, 302]: found_files.append(path) except requests.RequestException: continue self.results['sensitive_files'] = found_files return found_files def extract_emails(self) -> Set[str]: """æå–é‚®ç®±åœ°å€""" url = f"http://{self.target}" try: response = requests.get(url, timeout=10) content = response.text # é‚®ç®±æ­£åˆ™ email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b' emails = set(re.findall(email_pattern, content, re.IGNORECASE)) self.results['emails'] = emails except requests.RequestException: pass return self.results['emails'] def generate_report(self) -> Dict: """ç”ŸæˆæŠ¥å‘Š""" return { 'target': self.target, 'subdomains': list(self.results['subdomains']), 'open_ports': self.results['open_ports'], 'technologies': self.results['technologies'], 'sensitive_files': self.results['sensitive_files'], 'emails': list(self.results['emails']), 'social_accounts': list(self.results['social_accounts']) } 3.2 æ¼æ´æ‰«æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 # ========== æ¼æ´æ‰«æå™¨ ========== import requests from typing import Dict, List import re class VulnerabilityScanner: """æ¼æ´æ‰«æå™¨""" def __init__(self, target: str): self.target = target self.vulnerabilities = [] def scan_sql_injection(self, urls: List[str]) -> List[Dict]: """SQLæ³¨å…¥æ‰«æ""" payloads = [ "'", "' OR '1'='1", "' OR '1'='1'--", "admin'--", "1' ORDER BY 1--", "1' UNION SELECT NULL--" ] found = [] for url in urls: for payload in payloads: try: # æµ‹è¯•GETå‚æ•° if '?' in url: test_url = f"{url}{payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥SQLé”™è¯¯ç‰¹å¾ sql_errors = [ "You have an error in your SQL syntax", "Warning: mysql_fetch_array()", "ORA-01756: quoted string not properly terminated", "Unclosed quotation mark after the character string" ] if any(error in response.text for error in sql_errors): found.append({ 'type': 'SQL Injection', 'url': url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def scan_xss(self, urls: List[str]) -> List[Dict]: """XSSæ‰«æ""" payloads = [ "&lt;script>alert('XSS')&lt;/script>", "&lt;img src=x onerror=alert('XSS')>", "&lt;svg onload=alert('XSS')>", "javascript:alert('XSS')", "'>&lt;script>alert('XSS')&lt;/script>" ] found = [] for url in urls: for payload in payloads: try: # URLç¼–ç payload import urllib.parse encoded_payload = urllib.parse.quote(payload) test_url = f"{url}{encoded_payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥payloadæ˜¯å¦è¢«åå°„ if payload in response.text or encoded_payload in response.text: found.append({ 'type': 'XSS', 'url': url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def check_security_headers(self, url: str) -> Dict: """å®‰å…¨å¤´æ£€æŸ¥""" try: response = requests.get(url, timeout=10) headers = response.headers missing_headers = [] # æ£€æŸ¥å¿…è¦çš„å®‰å…¨å¤´ security_headers = { 'X-Frame-Options': 'é˜²æ­¢ç‚¹å‡»åŠ«æŒ', 'X-Content-Type-Options': 'é˜²æ­¢MIMEç±»å‹å—…æ¢', 'X-XSS-Protection': 'XSSè¿‡æ»¤', 'Content-Security-Policy': 'å†…å®¹å®‰å…¨ç­–ç•¥', 'Strict-Transport-Security': 'å¼ºåˆ¶HTTPS' } for header, description in security_headers.items(): if header not in headers: missing_headers.append({ 'header': header, 'description': description }) return { 'url': url, 'missing_headers': missing_headers, 'severity': 'Medium' if missing_headers else 'Low' } except requests.RequestException: return {'error': 'Failed to check headers'} def scan_directory_traversal(self, base_url: str) -> List[Dict]: """ç›®å½•éå†æ‰«æ""" payloads = [ '../../../etc/passwd', '..\\..\\..\\windows\\win.ini', '....//....//....//etc/passwd', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd' ] found = [] # å¸¸è§çš„å¯æµ‹è¯•ç«¯ç‚¹ test_paths = [ '/download', '/file', '/image', '/document' ] for path in test_paths: for payload in payloads: try: test_url = f"{base_url}{path}?file={payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥å“åº”å†…å®¹ if 'root:' in response.text or '[extensions]' in response.text: found.append({ 'type': 'Directory Traversal', 'url': test_url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def generate_report(self) -> Dict: """ç”Ÿæˆæ‰«ææŠ¥å‘Š""" # ç»Ÿè®¡æ¼æ´ vuln_count = { 'Critical': 0, 'High': 0, 'Medium': 0, 'Low': 0 } for vuln in self.vulnerabilities: severity = vuln.get('severity', 'Low') vuln_count[severity] = vuln_count.get(severity, 0) + 1 return { 'target': self.target, 'total_vulnerabilities': len(self.vulnerabilities), 'by_severity': vuln_count, 'vulnerabilities': self.vulnerabilities } å››ã€å®‰å…¨ç¼–ç æœ€ä½³å®è·µ 4.1 å¯†ç å®‰å…¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 # ========== å¯†ç å“ˆå¸Œä¸éªŒè¯ ========== import bcrypt import secrets import hashlib from typing import Tuple class PasswordSecurity: """å¯†ç å®‰å…¨""" @staticmethod def hash_password(password: str) -> str: """å“ˆå¸Œå¯†ç """ # ç”Ÿæˆç›å€¼ salt = bcrypt.gensalt(rounds=12) # å“ˆå¸Œå¯†ç  hashed = bcrypt.hashpw(password.encode('utf-8'), salt) return hashed.decode('utf-8') @staticmethod def verify_password(password: str, hashed: str) -> bool: """éªŒè¯å¯†ç """ try: return bcrypt.checkpw( password.encode('utf-8'), hashed.encode('utf-8') ) except Exception: return False @staticmethod def validate_password_strength(password: str) -> Tuple[bool, list]: """éªŒè¯å¯†ç å¼ºåº¦""" errors = [] # é•¿åº¦æ£€æŸ¥ if len(password) &lt; 8: errors.append("å¯†ç é•¿åº¦è‡³å°‘8ä½") if len(password) > 128: errors.append("å¯†ç é•¿åº¦ä¸è¶…è¿‡128ä½") # å¤æ‚åº¦æ£€æŸ¥ has_upper = any(c.isupper() for c in password) has_lower = any(c.islower() for c in password) has_digit = any(c.isdigit() for c in password) has_special = any(c in "!@#$%^&*()_+-=[]{}|;:,.&lt;>?" for c in password) if not (has_upper and has_lower): errors.append("å¯†ç å¿…é¡»åŒ…å«å¤§å°å†™å­—æ¯") if not has_digit: errors.append("å¯†ç å¿…é¡»åŒ…å«æ•°å­—") if not has_special: errors.append("å¯†ç å¿…é¡»åŒ…å«ç‰¹æ®Šå­—ç¬¦") # å¸¸è§å¼±å¯†ç æ£€æŸ¥ common_passwords = [ 'password', '12345678', 'qwerty', 'abc123', 'admin', 'welcome', 'password123' ] if password.lower() in common_passwords: errors.append("å¯†ç è¿‡äºå¸¸è§") return len(errors) == 0, errors @staticmethod def generate_reset_token() -> str: """ç”Ÿæˆå¯†ç é‡ç½®ä»¤ç‰Œ""" return secrets.token_urlsafe(32) @staticmethod def hash_reset_token(token: str) -> str: """å“ˆå¸Œé‡ç½®ä»¤ç‰Œç”¨äºå­˜å‚¨""" return hashlib.sha256(token.encode()).hexdigest() # ========== å¯†ç ç­–ç•¥ ========== class PasswordPolicy: """å¯†ç ç­–ç•¥""" def __init__( self, min_length: int = 8, max_length: int = 128, require_uppercase: bool = True, require_lowercase: bool = True, require_digit: bool = True, require_special: bool = True, expire_days: int = 90, prevent_reuse: int = 5 ): self.min_length = min_length self.max_length = max_length self.require_uppercase = require_uppercase self.require_lowercase = require_lowercase self.require_digit = require_digit self.require_special = require_special self.expire_days = expire_days self.prevent_reuse = prevent_reuse def validate(self, password: str, user_history: list = None) -> Tuple[bool, list]: """éªŒè¯å¯†ç """ errors = [] # é•¿åº¦ if len(password) &lt; self.min_length: errors.append(f"å¯†ç é•¿åº¦è‡³å°‘{self.min_length}ä½") if len(password) > self.max_length: errors.append(f"å¯†ç é•¿åº¦ä¸è¶…è¿‡{self.max_length}ä½") # å¤æ‚åº¦ if self.require_uppercase and not any(c.isupper() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«å¤§å†™å­—æ¯") if self.require_lowercase and not any(c.islower() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«å°å†™å­—æ¯") if self.require_digit and not any(c.isdigit() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«æ•°å­—") if self.require_special and not any( c in "!@#$%^&*()_+-=[]{}|;:,.&lt;>?" for c in password ): errors.append("å¯†ç å¿…é¡»åŒ…å«ç‰¹æ®Šå­—ç¬¦") # å†å²å¯†ç æ£€æŸ¥ if user_history and self.prevent_reuse: recent_passwords = user_history[:self.prevent_reuse] for old_hashed in recent_passwords: if PasswordSecurity.verify_password(password, old_hashed): errors.append(f"ä¸èƒ½ä½¿ç”¨æœ€è¿‘{self.prevent_reuse}æ¬¡ä½¿ç”¨è¿‡çš„å¯†ç ") break return len(errors) == 0, errors 4.2 æ•æ„Ÿæ•°æ®ä¿æŠ¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 # ========== æ•æ„Ÿæ•°æ®åŠ å¯† ========== from cryptography.fernet import Fernet from cryptography.hazmat.primitives import hashes from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2 import os import base64 from typing import Any import json class DataEncryption: """æ•°æ®åŠ å¯†""" @staticmethod def generate_key() -> bytes: """ç”ŸæˆåŠ å¯†å¯†é’¥""" return Fernet.generate_key() @staticmethod def encrypt_data(data: str, key: bytes) -> str: """åŠ å¯†æ•°æ®""" f = Fernet(key) encrypted = f.encrypt(data.encode()) return base64.b64encode(encrypted).decode() @staticmethod def decrypt_data(encrypted_data: str, key: bytes) -> str: """è§£å¯†æ•°æ®""" f = Fernet(key) encrypted = base64.b64decode(encrypted_data.encode()) decrypted = f.decrypt(encrypted) return decrypted.decode() @staticmethod def encrypt_dict(data: dict, key: bytes) -> str: """åŠ å¯†å­—å…¸æ•°æ®""" json_str = json.dumps(data) return DataEncryption.encrypt_data(json_str, key) @staticmethod def decrypt_dict(encrypted_data: str, key: bytes) -> dict: """è§£å¯†å­—å…¸æ•°æ®""" json_str = DataEncryption.decrypt_data(encrypted_data, key) return json.loads(json_str) class SecureStorage: """å®‰å…¨å­˜å‚¨""" def __init__(self, encryption_key: bytes): self.encryption_key = encryption_key def store_sensitive_data(self, key: str, data: Any): """å­˜å‚¨æ•æ„Ÿæ•°æ®""" # åºåˆ—åŒ–æ•°æ® if isinstance(data, dict): encrypted = DataEncryption.encrypt_dict(data, self.encryption_key) else: encrypted = DataEncryption.encrypt_data(str(data), self.encryption_key) # å­˜å‚¨åˆ°æ•°æ®åº“æˆ–æ–‡ä»¶ # è¿™é‡Œç®€åŒ–ä¸ºå†…å­˜å­˜å‚¨ self.storage[key] = encrypted def retrieve_sensitive_data(self, key: str) -> Any: """æ£€ç´¢æ•æ„Ÿæ•°æ®""" encrypted = self.storage.get(key) if not encrypted: return None # å°è¯•è§£å¯†ä¸ºå­—å…¸ try: return DataEncryption.decrypt_dict(encrypted, self.encryption_key) except: return DataEncryption.decrypt_data(encrypted, self.encryption_key) # ========== æ—¥å¿—è„±æ• ========== import re class LogSanitizer: """æ—¥å¿—è„±æ•""" # æ•æ„Ÿä¿¡æ¯æ­£åˆ™æ¨¡å¼ PATTERNS = { 'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 'phone': r'\b1[3-9]\d{9}\b', 'id_card': r'\b\d{17}[\dXx]\b', 'credit_card': r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b', 'password': r'(password|pwd|passwd)\s*[=:]\s*\S+', 'token': r'(token|api_key|secret)\s*[=:]\s*\S+', 'ip': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b' } @classmethod def sanitize(cls, log_message: str) -> str: """è„±æ•æ—¥å¿—""" sanitized = log_message for pattern_type, pattern in cls.PATTERNS.items(): if pattern_type == 'email': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[0]}***@{m.group(0).split('@')[1]}", sanitized ) elif pattern_type == 'phone': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[:3]}****{m.group(0)[7:]}", sanitized ) elif pattern_type == 'id_card': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[:6]}********{m.group(0)[14:]}", sanitized ) elif pattern_type in ['password', 'token', 'credit_card']: sanitized = re.sub( pattern, lambda m: f"{m.group(0).split('=')[0].split(':')[0]}=***", sanitized ) elif pattern_type == 'ip': sanitized = re.sub( pattern, lambda m: f"{m.group(0).rsplit('.', 1)[0]}.*", sanitized ) return sanitized @classmethod def sanitize_dict(cls, data: dict) -> dict: """è„±æ•å­—å…¸æ•°æ®""" sanitized = {} for key, value in data.items(): if isinstance(value, str): sanitized[key] = cls.sanitize(value) elif isinstance(value, dict): sanitized[key] = cls.sanitize_dict(value) else: sanitized[key] = value return sanitized æ€»ç»“ ç½‘ç»œå®‰å…¨æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E5%AE%89%E5%85%A8/ class=category-link>å®‰å…¨</a><a href=/blog/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/ class=category-link>ç½‘ç»œå®‰å…¨</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to ç½‘ç»œå®‰å…¨ä¸æ¼æ´æ·±åº¦åˆ†æï¼šä»æ”»å‡»åˆ°é˜²å¾¡çš„å®Œæ•´æŒ‡å—" href=/blog/articles/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%B8%8E%E6%BC%8F%E6%B4%9E%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90%E4%BB%8E%E6%94%BB%E5%87%BB%E5%88%B0%E9%98%B2%E5%BE%A1%E7%9A%84%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=/blog/posts/page/2/>Â«&nbsp;&nbsp;
</a><a class=next href=/blog/posts/page/4/>&nbsp;&nbsp;Â»</a></nav></footer></main><footer class=footer><span>Â© 2024-2025 æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢</span> Â·</footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>