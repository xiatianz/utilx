<!doctype html><html lang=zh-cn dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>æ‰€æœ‰æ–‡ç«  | æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·</title><meta name=keywords content="æŠ€æœ¯æ–‡ç« ,åšå®¢æ–‡ç« ,å¼€å‘æ•™ç¨‹,å·¥å…·ä½¿ç”¨"><meta name=description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><meta name=author content="util.cn Team"><link rel=canonical href=/blog/posts/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.7e8505b7cdf8bb22ab2305e53c2700bb06c7e64faeb72cd3468823a9a3bd3d6e.css integrity="sha256-foUFt834uyKrIwXlPCcAuwbH5k+utyzTRogjqaO9PW4=" rel="preload stylesheet" as=style><link rel=icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=apple-touch-icon href=/blog/apple-touch-icon.png><link rel=mask-icon href=/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=/blog/posts/feed.xml title=rss><link rel=alternate hreflang=zh-cn href=/blog/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script src=/js/external-link-config.js></script><script src=/js/external-link-interceptor.js></script><link rel=stylesheet href=/blog/css/custom.css media=screen><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","name":"æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«","url":"https://www.util.cn/blog/","description":"æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚æä¾›JSONæ ¼å¼åŒ–ã€SQLä¼˜åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰åœ¨çº¿å·¥å…·çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…æå‡å·¥ä½œæ•ˆç‡ã€‚","publisher":{"@type":"Organization","name":"æœ‰æ¡å·¥å…·","url":"https://www.util.cn","logo":{"@type":"ImageObject","url":"https://www.util.cn/blog/logo/logo-256.png","width":256,"height":256}},"potentialAction":[{"@type":"SearchAction","target":"https://www.util.cn/blog/search?q={search_term_string}","query-input":"required name=search_term_string"}]}</script><meta property="og:type" content="website"><meta property="og:title" content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«"><meta property="og:description" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚æä¾›JSONæ ¼å¼åŒ–ã€SQLä¼˜åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰åœ¨çº¿å·¥å…·çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼Œå¸®åŠ©å¼€å‘è€…æå‡å·¥ä½œæ•ˆç‡ã€‚"><meta property="og:url" content="https://www.util.cn/blog/"><meta property="og:site_name" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢"><meta property="og:image" content="https://www.util.cn/blog/logo/logo-256.png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· | å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ & ç¼–ç¨‹æŠ€å·§åˆ†äº«"><meta name=twitter:description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ - åˆ†äº«å¼€å‘è€…å·¥å…·ä½¿ç”¨æ•™ç¨‹ã€ç¼–ç¨‹æŠ€å·§å’Œå®æˆ˜å¼€å‘ç»éªŒã€‚"><meta name=twitter:image content="https://www.util.cn/blog/logo/logo-256.png"><meta name=baidu-site-verification content><meta name=category content="æŠ€æœ¯åšå®¢,å¼€å‘è€…å·¥å…·,ç¼–ç¨‹æ•™ç¨‹"><meta name=coverage content="Worldwide"><meta name=distribution content="Global"><meta name=rating content="General"><script id=51la_code async crossorigin=anonymous src="https://sdk.51.la/js-sdk-pro.min.js?id=3OM52V0xJAPv6ozF&hash=pro"></script><script>window.addEventListener("load",function(){setTimeout(function(){typeof la!="undefined"?console.log("51laç»Ÿè®¡å·²åŠ è½½"):(console.warn("51laç»Ÿè®¡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ"),function(){var e=document.createElement("script");e.src="https://sdk.51.la/js-sdk-pro.min.js?id=3OM52V0xJAPv6ozF&hash=backup",e.async=!0,document.head.appendChild(e)}())},3e3)})</script><meta property="og:url" content="/blog/posts/"><meta property="og:site_name" content="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·"><meta property="og:title" content="æ‰€æœ‰æ–‡ç« "><meta property="og:description" content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="æ‰€æœ‰æ–‡ç« "><meta name=twitter:description content="æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"æ‰€æœ‰æ–‡ç« ","item":"/blog/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=/blog/ accesskey=h title="æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…· (Alt + H)">æŠ€æœ¯åšå®¢ - æœ‰æ¡å·¥å…·</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/blog/posts/ title="æ‰€æœ‰æ–‡ç« åˆ—è¡¨ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŸ¥çœ‹æ‰€æœ‰æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹"><span class=active>æ–‡ç« </span></a></li><li><a href=https://www.util.cn title="æœ‰æ¡å·¥å…· - å¼€å‘è€…çš„å¸¸ç”¨å·¥å…·é›†åˆï¼šæ— å¹¿å‘Š Â· æœ¬åœ°è®¡ç®— Â· å³å¼€å³ç”¨çš„åœ¨çº¿å·¥å…·å¹³å°ï¼Œæä¾›JSONæ ¼å¼åŒ–ã€SQLæ ¼å¼åŒ–ã€Markdownç¼–è¾‘å™¨ç­‰å®ç”¨å·¥å…·"><span>æœ‰æ¡å·¥å…·</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=/blog/categories/ title="æ–‡ç« åˆ†ç±» - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŒ‰æŠ€æœ¯é¢†åŸŸåˆ†ç±»çš„ä¼˜è´¨æ–‡ç« ï¼ŒåŒ…æ‹¬å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰"><span>åˆ†ç±»</span></a></li><li><a href=/blog/tags/ title="æ ‡ç­¾äº‘ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šé€šè¿‡æ ‡ç­¾å¿«é€Ÿæ‰¾åˆ°æ„Ÿå…´è¶£çš„æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹"><span>æ ‡ç­¾</span></a></li><li><a href=/blog/archives/ title="æ–‡ç« å½’æ¡£ - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šæŒ‰æ—¶é—´æŸ¥çœ‹å†å²æ–‡ç« "><span>å½’æ¡£</span></a></li><li><a href=/blog/search/ title="æœç´¢æ–‡ç«  - æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢ï¼šé€šè¿‡å…³é”®è¯æœç´¢æ‰¾åˆ°æ„Ÿå…´è¶£çš„æŠ€æœ¯æ–‡ç« å’Œæ•™ç¨‹å†…å®¹ï¼Œæ”¯æŒæ ‡é¢˜ã€å†…å®¹ã€åˆ†ç±»å’Œæ ‡ç­¾æœç´¢"><span>æœç´¢</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>æ‰€æœ‰æ–‡ç« </h1><div class=post-description>æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢çš„æ‰€æœ‰æŠ€æœ¯æ–‡ç« åˆ—è¡¨ï¼ŒåŒ…å«å‰ç«¯å¼€å‘ã€å·¥å…·ä½¿ç”¨ã€ç¼–ç¨‹æŠ€å·§ç­‰å†…å®¹</div></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>2025æŠ€æœ¯æµªæ½®å›é¡¾ä¸2026è¶‹åŠ¿å‰ç»ï¼šå¼€å‘è€…å¿…çŸ¥çš„å˜é©æ–¹å‘</h2></header><div class=entry-content><p>å¼•è¨€ 2025å¹´æ˜¯æŠ€æœ¯å˜é©åŠ é€Ÿçš„ä¸€å¹´ã€‚AIç¼–ç¨‹åŠ©æ‰‹ä»å®éªŒæ€§å·¥å…·å˜ä¸ºå¼€å‘æ ‡é…ï¼ŒWebAssemblyç”Ÿæ€èµ°å‘æˆç†Ÿï¼ŒRuståœ¨ç³»ç»Ÿç¼–ç¨‹é¢†åŸŸçš„åœ°ä½ä¸æ–­å·©å›ºã€‚ç«™åœ¨2025å¹´çš„ç»ˆç‚¹ï¼Œè®©æˆ‘ä»¬æ·±åº¦å›é¡¾è¿™ä¸€å¹´çš„æŠ€æœ¯çªç ´ï¼Œå¹¶å±•æœ›2026å¹´çš„å‘å±•æ–¹å‘ã€‚
ä¸€ã€2025å¹´æŠ€æœ¯æ ¼å±€å˜é© 1.1 AIè¾…åŠ©ç¼–ç¨‹æˆä¸ºæ ‡é… ä»è¾…åŠ©åˆ°æ ¸å¿ƒ
2025å¹´ï¼ŒAIç¼–ç¨‹åŠ©æ‰‹å®Œæˆäº†ä»"é”¦ä¸Šæ·»èŠ±"åˆ°"ä¸å¯æˆ–ç¼º"çš„è½¬å˜ã€‚æ ¹æ®Stack Overflowçš„è°ƒæŸ¥ï¼Œè¶…è¿‡70%çš„å¼€å‘è€…æ—¥å¸¸ä½¿ç”¨AIç¼–ç¨‹å·¥å…·ã€‚
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // 2025å¹´çš„å…¸å‹å¼€å‘å·¥ä½œæµ class DeveloperWorkflow { // ä¼ ç»Ÿæ–¹å¼ï¼šæ‰‹åŠ¨ç¼–å†™æ‰€æœ‰ä»£ç  traditionalApproach() { const fetchUser = async (id: string) => { const response = await fetch(`/api/users/${id}`); return response.json(); }; const updateUser = async (id: string, data: any) => { const response = await fetch(`/api/users/${id}`, { method: 'PUT', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(data) }); return response.json(); }; // è¿˜éœ€è¦æ‰‹åŠ¨å†™æµ‹è¯•ã€æ–‡æ¡£ã€é”™è¯¯å¤„ç†... } // 2025å¹´AIè¾…åŠ©æ–¹å¼ï¼šAIç”ŸæˆåŸºç¡€ä»£ç ï¼Œå¼€å‘è€…ä¸“æ³¨ä¸šåŠ¡é€»è¾‘ aiAssistedApproach() { // AIç”Ÿæˆï¼šåŸºç¡€CRUDæ“ä½œã€ç±»å‹å®šä¹‰ã€é”™è¯¯å¤„ç† // å¼€å‘è€…ä¸“æ³¨ï¼šä¸šåŠ¡è§„åˆ™ã€è¾¹ç•Œæ¡ä»¶ã€æ€§èƒ½ä¼˜åŒ– const userService = { // AIç”Ÿæˆçš„åŸºç¡€ç»“æ„ async getUser(id: string): Promise&lt;User> { // AIå·²æ·»åŠ ï¼šé”™è¯¯å¤„ç†ã€ç±»å‹æ£€æŸ¥ã€æ—¥å¿—è®°å½• return await apiClient.get(`/users/${id}`); }, // å¼€å‘è€…æ·»åŠ ï¼šå¤æ‚çš„ä¸šåŠ¡é€»è¾‘ async getUserWithPermissions(id: string): Promise&lt;UserWithPermissions> { const user = await this.getUser(id); const permissions = await permissionService.loadForUser(user); return { ...user, permissions }; }, // å¼€å‘è€…ä¼˜åŒ–ï¼šç¼“å­˜ç­–ç•¥ async getUserCached(id: string): Promise&lt;User> { return cache.remember(`user:${id}`, () => this.getUser(id), 3600); } }; } } AIå·¥å…·çš„è¿›åŒ–
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/ class=category-link>æŠ€æœ¯è¶‹åŠ¿</a><a href=/blog/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/ class=category-link>å¹´åº¦æ€»ç»“</a></div><span class=post-date>2025-12-31</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to 2025æŠ€æœ¯æµªæ½®å›é¡¾ä¸2026è¶‹åŠ¿å‰ç»ï¼šå¼€å‘è€…å¿…çŸ¥çš„å˜é©æ–¹å‘" href=/blog/articles/2025%E6%8A%80%E6%9C%AF%E6%B5%AA%E6%BD%AE%E5%9B%9E%E9%A1%BE%E4%B8%8E2026%E8%B6%8B%E5%8A%BF%E5%89%8D%E7%9E%BB%E5%BC%80%E5%8F%91%E8%80%85%E5%BF%85%E7%9F%A5%E7%9A%84%E5%8F%98%E9%9D%A9%E6%96%B9%E5%90%91/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>å¼€å‘è€…å·¥å…·å®Œå…¨æŒ‡å—ï¼šæå‡ç¼–ç¨‹æ•ˆç‡çš„å®ç”¨å·¥å…·é›†</h2></header><div class=entry-content><p>å¼•è¨€ å·¥æ¬²å–„å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨ã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»å¼€å‘è€…å¿…å¤‡å·¥å…·ï¼Œå¸®åŠ©ä½ æ„å»ºé«˜æ•ˆçš„å¼€å‘ç¯å¢ƒã€‚
ä¸€ã€ä»£ç ç¼–è¾‘å™¨ 1.1 VS Codeé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // settings.json { "editor.formatOnSave": true, "editor.codeActionsOnSave": { "source.fixAll.eslint": true }, "editor.tabSize": 2, "editor.wordWrap": "on", "files.autoSave": "afterDelay", "files.autoSaveDelay": 1000 } // æ¨èæ‰©å±• { "recommendations": [ "dbaeumer.vscode-eslint", "esbenp.prettier-vscode", "ms-python.python", "ms-python.debugpy", "formulahendry.auto-rename-tag", "christian-kohler.path-intellisense", "streetsidesoftware.code-spell-checker" ] } äºŒã€Gitæœ€ä½³å®è·µ 2.1 Gitåˆ«åé…ç½® 1 2 3 4 5 6 7 8 # å¸¸ç”¨åˆ«å git config --global alias.co checkout git config --global alias.br branch git config --global alias.ci commit git config --global alias.st status git config --global alias.unstage 'reset HEAD --' git config --global alias.last 'log -1 HEAD' git config --global alias.visual '!gitk' 2.2 Gitå·¥ä½œæµ 1 2 3 4 5 6 7 8 9 10 11 # åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ git checkout -b feature/new-feature git add . git commit -m "feat: add new feature" git push origin feature/new-feature # åˆ›å»ºPull Request # ä»£ç å®¡æŸ¥é€šè¿‡å git checkout main git merge feature/new-feature git branch -d feature/new-feature ä¸‰ã€è°ƒè¯•å·¥å…· 3.1 Chrome DevTools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // ConsoleæŠ€å·§ console.table(data); console.time('timer'); // ä»£ç ... console.timeEnd('timer'); console.trace('è¿½è¸ªè°ƒç”¨æ ˆ'); // æ–­ç‚¹è°ƒè¯• debugger; // æ€§èƒ½åˆ†æ performance.mark('start'); // ä»£ç ... performance.mark('end'); performance.measure('My Code', 'start', 'end'); å››ã€APIæµ‹è¯•å·¥å…· 4.1 cURLæŠ€å·§ 1 2 3 4 5 6 7 8 # GETè¯·æ±‚ curl -X GET "https://api.example.com/users" \ -H "Authorization: Bearer TOKEN" # POSTè¯·æ±‚ curl -X POST "https://api.example.com/users" \ -H "Content-Type: application/json" \ -d '{"name":"John","email":"john@example.com"}' äº”ã€åœ¨çº¿å¼€å‘å·¥å…· æœ‰æ¡å·¥å…·ï¼ˆutil.cnï¼‰æä¾›ä»¥ä¸‹å®ç”¨å·¥å…·ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/ class=category-link>å¼€å‘å·¥å…·</a><a href=/blog/categories/%E7%94%9F%E4%BA%A7%E5%8A%9B/ class=category-link>ç”Ÿäº§åŠ›</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to å¼€å‘è€…å·¥å…·å®Œå…¨æŒ‡å—ï¼šæå‡ç¼–ç¨‹æ•ˆç‡çš„å®ç”¨å·¥å…·é›†" href=/blog/articles/%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E6%8F%90%E5%8D%87%E7%BC%96%E7%A8%8B%E6%95%88%E7%8E%87%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%E9%9B%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Web3ä¸åŒºå—é“¾å¼€å‘å®Œå…¨æŒ‡å—ï¼šä»æ™ºèƒ½åˆçº¦åˆ°DApp</h2></header><div class=entry-content><p>å¼•è¨€ Web3å’ŒåŒºå—é“¾æŠ€æœ¯æ­£åœ¨é‡å¡‘äº’è”ç½‘çš„å½¢æ€ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨æ™ºèƒ½åˆçº¦å¼€å‘ã€DeFiåè®®ã€NFTç­‰æ ¸å¿ƒä¸»é¢˜ï¼Œå¸®åŠ©å¼€å‘è€…è¿›å…¥Web3ä¸–ç•Œã€‚
ä¸€ã€Solidityæ™ºèƒ½åˆçº¦ 1.1 åŸºç¡€åˆçº¦ç»“æ„ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // SPDX-License-Identifier: MIT pragma solidity ^0.8.20; import "@openzeppelin/contracts/token/ERC20/ERC20.sol"; import "@openzeppelin/contracts/access/Ownable.sol"; contract MyToken is ERC20, Ownable { uint256 public constant MAX_SUPPLY = 1_000_000_000 * 10**18; constructor() ERC20("MyToken", "MTK") { _mint(msg.sender, MAX_SUPPLY); } function mint(address to, uint256 amount) public onlyOwner { _mint(to, amount); } function burn(uint256 amount) public { _burn(msg.sender, amount); } } 1.2 å®‰å…¨æœ€ä½³å®è·µ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // ========== é‡å…¥æ”»å‡»é˜²æŠ¤ ========== contract ReentrancyGuard { bool private locked; modifier noReentrant() { require(!locked, "Reentrant call"); locked = true; _; locked = false; } function withdraw() external noReentrant { // ... } } // ========== è®¿é—®æ§åˆ¶ ========== contract AccessControl { mapping(address => bool) public admins; modifier onlyAdmin() { require(admins[msg.sender], "Not admin"); _; } function addAdmin(address admin) external onlyAdmin { admins[admin] = true; } } // ========== å®‰å…¨æ•°å­¦è¿ç®— ========== library SafeMath { function add(uint256 a, uint256 b) internal pure returns (uint256) { require(a + b >= a, "Overflow"); return a + b; } function sub(uint256 a, uint256 b) internal pure returns (uint256) { require(a >= b, "Underflow"); return a - b; } } äºŒã€DeFiåè®®å¼€å‘ 2.1 AMMäº¤æ¢æ±  1 2 3 4 5 6 7 8 9 10 11 12 contract AMMPool { uint256 public reserve0; uint256 public reserve1; function addLiquidity(uint256 amount0, uint256 amount1) external { // ... } function swap(uint256 amount0In, uint256 amount1In) external { // ... } } ä¸‰ã€NFTå¼€å‘ 1 2 3 4 5 6 7 8 9 10 11 12 import "@openzeppelin/contracts/token/ERC721/extensions/ERC721URIStorage.sol"; contract MyNFT is ERC721URIStorage { uint256 private _tokenIdCounter; function mint(address to, string memory uri) public returns (uint256) { uint256 tokenId = _tokenIdCounter++; _safeMint(to, tokenId); _setTokenURI(tokenId, uri); return tokenId; } } å››ã€å‰ç«¯é›†æˆ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { ethers } from 'ethers'; // è¿æ¥é’±åŒ… async function connectWallet() { const provider = new ethers.BrowserProvider(window.ethereum); await provider.send("eth_requestAccounts", []); const signer = await provider.getSigner(); return signer; } // è°ƒç”¨åˆçº¦ async function mintNFT(signer, contractAddress, uri) { const contract = new ethers.Contract( contractAddress, ['function mint(address to, string memory uri) returns (uint256)'], signer ); const tx = await contract.mint(await signer.getAddress(), uri); await tx.wait(); } æ€»ç»“ Web3å¼€å‘éœ€è¦æŒæ¡æ™ºèƒ½åˆçº¦ã€åŒºå—é“¾åŸç†å’Œå‰ç«¯é›†æˆã€‚æŒç»­å…³æ³¨å®‰å…¨æœ€ä½³å®è·µè‡³å…³é‡è¦ã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/web3/ class=category-link>Web3</a><a href=/blog/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/ class=category-link>åŒºå—é“¾</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to Web3ä¸åŒºå—é“¾å¼€å‘å®Œå…¨æŒ‡å—ï¼šä»æ™ºèƒ½åˆçº¦åˆ°DApp" href=/blog/articles/web3%E4%B8%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E4%BB%8E%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%88%B0dapp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>äº‘åŸç”Ÿæ¶æ„å®Œå…¨æŒ‡å—ï¼šKubernetesä¸å¾®æœåŠ¡å®è·µ</h2></header><div class=entry-content><p>å¼•è¨€ äº‘åŸç”Ÿæ¶æ„æ˜¯ç°ä»£åº”ç”¨éƒ¨ç½²çš„æ ‡å‡†æ¨¡å¼ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å¦‚ä½•ä½¿ç”¨Kubernetesã€æœåŠ¡ç½‘æ ¼å’ŒDevOpså®è·µæ„å»ºå¼¹æ€§ã€å¯æ‰©å±•çš„äº‘åŸç”Ÿåº”ç”¨ã€‚
ä¸€ã€Kubernetesæ ¸å¿ƒæ¦‚å¿µ 1.1 Podä¸Deployment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # ========== Podé…ç½® ========== apiVersion: v1 kind: Pod metadata: name: nginx-pod labels: app: nginx spec: containers: - name: nginx image: nginx:1.25 ports: - containerPort: 80 resources: requests: memory: "64Mi" cpu: "250m" limits: memory: "128Mi" cpu: "500m" livenessProbe: httpGet: path: / port: 80 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: / port: 80 initialDelaySeconds: 5 periodSeconds: 5 --- # ========== Deploymenté…ç½® ========== apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 selector: matchLabels: app: nginx strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 0 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.25 ports: - containerPort: 80 env: - name: ENVIRONMENT value: "production" volumeMounts: - name: config-volume mountPath: /etc/nginx/config.d volumes: - name: config-volume configMap: name: nginx-config 1.2 Serviceä¸Ingress 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # ========== Serviceé…ç½® ========== apiVersion: v1 kind: Service metadata: name: nginx-service spec: type: ClusterIP selector: app: nginx ports: - port: 80 targetPort: 80 protocol: TCP --- # ========== Ingressé…ç½® ========== apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx-ingress annotations: kubernetes.io/ingress.class: nginx cert-manager.io/cluster-issuer: letsencrypt-prod nginx.ingress.kubernetes.io/ssl-redirect: "true" spec: tls: - hosts: - app.example.com secretName: app-tls rules: - host: app.example.com http: paths: - path: / pathType: Prefix backend: service: name: nginx-service port: number: 80 äºŒã€æœåŠ¡ç½‘æ ¼ 2.1 Istioé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # ========== Istio VirtualService ========== apiVersion: networking.istio.io/v1beta1 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - match: - headers: end-user: exact: jason fault: delay: percentage: value: 100 fixedDelay: 3s route: - destination: host: reviews subset: v2 - route: - destination: host: reviews subset: v1 --- # ========== Istio DestinationRule ========== apiVersion: networking.istio.io/v1beta1 kind: DestinationRule metadata: name: reviews spec: host: reviews trafficPolicy: loadBalancer: simple: LEAST_CONN subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 trafficPolicy: loadBalancer: simple: RANDOM ä¸‰ã€äº‘åŸç”Ÿæœ€ä½³å®è·µ 3.1 å¥åº·æ£€æŸ¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 3 startupProbe: httpGet: path: /health/startup port: 8080 initialDelaySeconds: 0 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 30 3.2 èµ„æºé™åˆ¶ 1 2 3 4 5 6 7 resources: requests: memory: "256Mi" cpu: "250m" limits: memory: "512Mi" cpu: "500m" æ€»ç»“ äº‘åŸç”Ÿæ¶æ„æ˜¯ç°ä»£åº”ç”¨éƒ¨ç½²çš„æœ€ä½³å®è·µã€‚é€šè¿‡Kubernetesã€æœåŠ¡ç½‘æ ¼å’ŒDevOpsçš„ç»“åˆï¼Œå¯ä»¥æ„å»ºå¼¹æ€§ã€å¯æ‰©å±•çš„åº”ç”¨ç³»ç»Ÿã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/ class=category-link>äº‘åŸç”Ÿ</a><a href=/blog/categories/kubernetes/ class=category-link>Kubernetes</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to äº‘åŸç”Ÿæ¶æ„å®Œå…¨æŒ‡å—ï¼šKubernetesä¸å¾®æœåŠ¡å®è·µ" href=/blog/articles/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%9E%B6%E6%9E%84%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97kubernetes%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>è·¨å¹³å°ç§»åŠ¨å¼€å‘å®Œå…¨æŒ‡å—ï¼šReact Nativeä¸Flutteræ·±åº¦å®è·µ</h2></header><div class=entry-content><p>å¼•è¨€ è·¨å¹³å°ç§»åŠ¨å¼€å‘æŠ€æœ¯æ—¥è¶‹æˆç†Ÿï¼ŒReact Nativeå’ŒFlutterå·²æˆä¸ºä¸»æµé€‰æ‹©ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æä¸¤å¤§æ¡†æ¶çš„æ¶æ„è®¾è®¡ã€æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºé«˜è´¨é‡çš„ç§»åŠ¨åº”ç”¨ã€‚
ä¸€ã€React Nativeæ·±åº¦å®è·µ 1.1 æ¶æ„è®¾è®¡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 // ========== React Nativeé¡¹ç›®æ¶æ„ ========== /** * æ¨èçš„é¡¹ç›®ç»“æ„ * * src/ * â”œâ”€â”€ api/ # APIæ¥å£ * â”œâ”€â”€ assets/ # é™æ€èµ„æº * â”œâ”€â”€ components/ # é€šç”¨ç»„ä»¶ * â”‚ â”œâ”€â”€ common/ # åŸºç¡€ç»„ä»¶ * â”‚ â””â”€â”€ business/ # ä¸šåŠ¡ç»„ä»¶ * â”œâ”€â”€ navigation/ # å¯¼èˆªé…ç½® * â”œâ”€â”€ screens/ # é¡µé¢ç»„ä»¶ * â”œâ”€â”€ services/ # ä¸šåŠ¡æœåŠ¡ * â”œâ”€â”€ store/ # çŠ¶æ€ç®¡ç† * â”œâ”€â”€ utils/ # å·¥å…·å‡½æ•° * â””â”€â”€ types/ # ç±»å‹å®šä¹‰ */ // ========== çŠ¶æ€ç®¡ç†ï¼šZustand ========== import create from 'zustand'; // å®šä¹‰Storeç±»å‹ interface UserStore { user: User | null; token: string | null; isLoading: boolean; // Actions login: (credentials: Credentials) => Promise&lt;void>; logout: () => void; updateUser: (data: Partial&lt;User>) => void; } // åˆ›å»ºStore const useUserStore = create&lt;UserStore>((set, get) => ({ user: null, token: null, isLoading: false, login: async (credentials) => { set({ isLoading: true }); try { const { user, token } = await api.login(credentials); set({ user, token, isLoading: false }); // æŒä¹…åŒ– await AsyncStorage.setItem('token', token); } catch (error) { set({ isLoading: false }); throw error; } }, logout: () => { set({ user: null, token: null }); AsyncStorage.removeItem('token'); }, updateUser: (data) => { const { user } = get(); if (user) { set({ user: { ...user, ...data } }); } } })); // ========== å¯¼èˆªé…ç½® ========== import { NavigationContainer } from '@react-navigation/native'; import { createBottomTabNavigator } from '@react-navigation/bottom-tabs'; import { createStackNavigator } from '@react-navigation/stack'; // Stack Navigator const Stack = createStackNavigator(); function AppStack() { return ( &lt;Stack.Navigator screenOptions={{ headerShown: false }} > &lt;Stack.Screen name="Home" component={HomeScreen} /> &lt;Stack.Screen name="Profile" component={ProfileScreen} /> &lt;Stack.Screen name="Details" component={DetailsScreen} /> &lt;/Stack.Navigator> ); } // Tab Navigator const Tab = createBottomTabNavigator(); function AppTabs() { return ( &lt;Tab.Navigator screenOptions={({ route }) => ({ tabBarIcon: ({ focused, color, size }) => { return &lt;TabBarIcon focused={focused} name={route.name} />; }, })} > &lt;Tab.Screen name="Home" component={AppStack} /> &lt;Tab.Screen name="Search" component={SearchScreen} /> &lt;Tab.Screen name="Profile" component={ProfileScreen} /> &lt;/Tab.Navigator> ); } // ========== æ€§èƒ½ä¼˜åŒ– ========== import { memo, useMemo, useCallback, useState } from 'react'; // 1. ç»„ä»¶memoåŒ– const ListItem = memo(({ item, onPress }) => { return ( &lt;TouchableOpacity onPress={() => onPress(item)}> &lt;Text>{item.title}&lt;/Text> &lt;/TouchableOpacity> ); }, (prevProps, nextProps) => { return prevProps.item.id === nextProps.item.id; }); // 2. FlatListä¼˜åŒ– function OptimizedList({ data, onEndReached }) { const renderItem = useCallback(({ item }) => ( &lt;ListItem item={item} onPress={handlePress} /> ), []); const keyExtractor = useCallback((item) => item.id, []); return ( &lt;FlatList data={data} renderItem={renderItem} keyExtractor={keyExtractor} onEndReached={onEndReached} onEndReachedThreshold={0.5} maxToRenderPerBatch={10} windowSize={5} initialNumToRender={10} getItemLayout={(data, index) => ({ length: ITEM_HEIGHT, offset: ITEM_HEIGHT * index, index })} removeClippedSubviews={true} /> ); } // 3. å›¾ç‰‡ä¼˜åŒ– import FastImage from 'react-native-fast-image'; const OptimizedImage = memo(({ uri, style }) => { return ( &lt;FastImage style={style} source={{ uri, priority: FastImage.priority.normal, }} resizeMode={FastImage.resizeMode.cover} /> ); }); 1.2 åŸç”Ÿæ¨¡å—å¼€å‘ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 // ========== AndroidåŸç”Ÿæ¨¡å— ========== // UserModule.java package com.myapp; import com.facebook.react.bridge.ReactApplicationContext; import com.facebook.react.bridge.ReactContextBaseJavaModule; import com.facebook.react.bridge.ReactMethod; import com.facebook.react.bridge.Promise; import com.facebook.react.bridge.WritableMap; import com.facebook.react.bridge.Arguments; public class UserModule extends ReactContextBaseJavaModule { private static final String E_USER_NOT_FOUND = "E_USER_NOT_FOUND"; @Override public String getName() { return "UserModule"; } @ReactMethod public void getUserInfo(String userId, Promise promise) { try { // è°ƒç”¨Android API User user = UserManager.getUser(userId); if (user == null) { promise.reject(E_USER_NOT_FOUND, "User not found"); return; } // è½¬æ¢ä¸ºWritableMap WritableMap result = Arguments.createMap(); result.putString("id", user.getId()); result.putString("name", user.getName()); result.putString("email", user.getEmail()); promise.resolve(result); } catch (Exception e) { promise.reject("ERROR", e.getMessage()); } } } // ========== iOSåŸç”Ÿæ¨¡å— ========== // UserModule.m #import &lt;React/RCTBridgeModule.h> #import &lt;React/RCTEventEmitter.h> @interface RCT_EXTERN_MODULE(UserModule, NSObject) RCT_EXTERN_METHOD(getUserInfo:(NSString *)userId resolver:(RCTPromiseResolveBlock)resolve rejecter:(RCTPromiseRejectBlock)reject) @end // UserModule.swift @objc(UserModule) class UserModule: NSObject { @objc static func requiresMainQueueSetup() -> Bool { return false } @objc(getUserInfo:resolver:rejecter:) func getUserInfo(_ userId: String, resolver: @escaping RCTPromiseResolveBlock, rejecter: @escaping RCTPromiseRejectBlock) { DispatchQueue.global(qos: .background).async { do { // è°ƒç”¨iOS API guard let user = UserManager.shared.getUser(id: userId) else { rejecter("USER_NOT_FOUND", "User not found", nil) return } let result: [String: Any] = [ "id": user.id, "name": user.name, "email": user.email ] resolver(result) } catch { rejecter("ERROR", error.localizedDescription, error) } } } } // ========== TypeScriptç±»å‹å®šä¹‰ ========== // NativeModules.d.ts declare module 'react-native' { interface NativeModulesStatic { UserModule: { getUserInfo(userId: string): Promise&lt;UserInfo>; }; } } interface UserInfo { id: string; name: string; email: string; } // ä½¿ç”¨ import { NativeModules } from 'react-native'; const { UserModule } = NativeModules; async function getUserInfo(userId: string) { try { const userInfo = await UserModule.getUserInfo(userId); console.log(userInfo); } catch (error) { console.error(error); } } äºŒã€Flutteræ·±åº¦å®è·µ 2.1 æ¶æ„è®¾è®¡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 // ========== Flutteré¡¹ç›®ç»“æ„ ========== /** * lib/ * â”œâ”€â”€ core/ # æ ¸å¿ƒåŠŸèƒ½ * â”‚ â”œâ”€â”€ constants/ # å¸¸é‡ * â”‚ â”œâ”€â”€ errors/ # é”™è¯¯å¤„ç† * â”‚ â”œâ”€â”€ network/ # ç½‘ç»œè¯·æ±‚ * â”‚ â””â”€â”€ utils/ # å·¥å…·å‡½æ•° * â”œâ”€â”€ data/ # æ•°æ®å±‚ * â”‚ â”œâ”€â”€ models/ # æ•°æ®æ¨¡å‹ * â”‚ â”œâ”€â”€ repositories/ # ä»“åº“å®ç° * â”‚ â””â”€â”€ datasources/ # æ•°æ®æº * â”œâ”€â”€ domain/ # é¢†åŸŸå±‚ * â”‚ â”œâ”€â”€ entities/ # å®ä½“ * â”‚ â”œâ”€â”€ repositories/ # ä»“åº“æ¥å£ * â”‚ â””â”€â”€ usecases/ # ç”¨ä¾‹ * â”œâ”€â”€ presentation/ # è¡¨ç°å±‚ * â”‚ â”œâ”€â”€ pages/ # é¡µé¢ * â”‚ â”œâ”€â”€ widgets/ # ç»„ä»¶ * â”‚ â””â”€â”€ bloc/ # çŠ¶æ€ç®¡ç† * â””â”€â”€ main.dart */ // ========== BLoCçŠ¶æ€ç®¡ç† ========== // user_event.dart abstract class UserEvent {} class LoginRequested extends UserEvent { final String email; final String password; LoginRequested({required this.email, required this.password}); } class LogoutRequested extends UserEvent {} // user_state.dart abstract class UserState {} class UserInitial extends UserState {} class UserLoading extends UserState {} class UserLoaded extends UserState { final User user; UserLoaded(this.user); } class UserError extends UserState { final String message; UserError(this.message); } // user_bloc.dart class UserBloc extends Bloc&lt;UserEvent, UserState> { final LoginUseCase loginUseCase; final LogoutUseCase logoutUseCase; UserBloc({ required this.loginUseCase, required this.logoutUseCase, }) : super(UserInitial()) { on&lt;LoginRequested>(_onLoginRequested); on&lt;LogoutRequested>(_onLogoutRequested); } Future&lt;void> _onLoginRequested( LoginRequested event, Emitter&lt;UserState> emit, ) async { emit(UserLoading()); final result = await loginUseCase( LoginParams(email: event.email, password: event.password), ); result.fold( (failure) => emit(UserError(failure.message)), (user) => emit(UserLoaded(user)), ); } Future&lt;void> _onLogoutRequested( LogoutRequested event, Emitter&lt;UserState> emit, ) async { await logoutUseCase(); emit(UserInitial()); } } // ========== ä¾èµ–æ³¨å…¥ ========== // service_locator.dart final getIt = GetIt.instance; void initDependencies() { // å¤–éƒ¨ä¾èµ– getIt.registerLazySingleton(() => http.Client()); getIt.registerLazySingleton(() => SharedPreferences.getInstance()); // æ•°æ®æº getIt.registerLazySingleton&lt;UserRemoteDataSource>( () => UserRemoteDataSourceImpl(client: getIt()), ); getIt.registerLazySingleton&lt;UserLocalDataSource>( () => UserLocalDataSourceImpl(sharedPreferences: getIt()), ); // ä»“åº“ getIt.registerLazySingleton&lt;UserRepository>( () => UserRepositoryImpl( remoteDataSource: getIt(), localDataSource: getIt(), ), ); // ç”¨ä¾‹ getIt.registerLazySingleton( () => LoginUseCase(repository: getIt()), ); getIt.registerLazySingleton( () => LogoutUseCase(repository: getIt()), ); // BLoC getIt.registerFactory( () => UserBloc( loginUseCase: getIt(), logoutUseCase: getIt(), ), ); } 2.2 æ€§èƒ½ä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 // ========== æ€§èƒ½ä¼˜åŒ–æŠ€å·§ ========== // 1. ä½¿ç”¨constæ„é€ å‡½æ•° class MyWidget extends StatelessWidget { @override Widget build(BuildContext context) { return const Text('Hello'); // const } } // 2. é¿å…åœ¨buildä¸­åˆ›å»ºå¯¹è±¡ class OptimizedWidget extends StatelessWidget { final String text; const OptimizedWidget({Key? key, required this.text}) : super(key: key); static final _style = TextStyle(fontSize: 16); // é™æ€ @override Widget build(BuildContext context) { return Text(text, style: _style); } } // 3. ListViewä¼˜åŒ– class OptimizedListView extends StatelessWidget { final List&lt;Item> items; const OptimizedListView({Key? key, required this.items}) : super(key: key); @override Widget build(BuildContext context) { return ListView.builder( itemCount: items.length, // æ·»åŠ itemExtentæå‡æ€§èƒ½ itemExtent: 60, itemBuilder: (context, index) { return ListTile( title: Text(items[index].title), ); }, ); } } // 4. å›¾ç‰‡ç¼“å­˜ class CachedImageWidget extends StatelessWidget { final String imageUrl; const CachedImageWidget({Key? key, required this.imageUrl}) : super(key: key); @override Widget build(BuildContext context) { return CachedNetworkImage( imageUrl: imageUrl, placeholder: (context, url) => CircularProgressIndicator(), errorWidget: (context, url, error) => Icon(Icons.error), fadeInDuration: Duration(milliseconds: 300), ); } } // 5. ä½¿ç”¨RepaintBoundary class RepaintBoundaryWidget extends StatelessWidget { @override Widget build(BuildContext context) { return RepaintBoundary( child: AnimatedContainer( duration: Duration(milliseconds: 300), color: Colors.blue, ), ); } } // ========== Isolateä½¿ç”¨ ========== import 'dart:isolate'; // åœ¨æ–°Isolateä¸­æ‰§è¡Œè€—æ—¶æ“ä½œ Future&lt;ProcessedData> processInBackground(RawData data) async { final receivePort = ReceivePort(); await Isolate.spawn( _isolateEntryPoint, _IsolateMessage(data: data, sendPort: receivePort.sendPort), ); final result = await receivePort.first as ProcessedData; return result; } void _isolateEntryPoint(_IsolateMessage message) { final processed = _heavyComputation(message.data); message.sendPort.send(processed); } ProcessedData _heavyComputation(RawData data) { // æ‰§è¡Œè€—æ—¶è®¡ç®— return ProcessedData(/* ... */); } class _IsolateMessage { final RawData data; final SendPort sendPort; _IsolateMessage({required this.data, required this.sendPort}); } ä¸‰ã€è·¨å¹³å°æŠ€æœ¯é€‰å‹ ç‰¹æ€§ React Native Flutter å¼€å‘è¯­è¨€ JavaScript/TypeScript Dart æ€§èƒ½ æ¥è¿‘åŸç”Ÿ æ¥è¿‘åŸç”Ÿ UIæ¸²æŸ“ åŸç”Ÿç»„ä»¶ è‡ªç»˜å¼•æ“ çƒ­é‡è½½ æ”¯æŒ æ”¯æŒ åŒ…ä½“ç§¯ è¾ƒå° è¾ƒå¤§ å­¦ä¹ æ›²çº¿ è¾ƒå¹³ç¼“ ä¸­ç­‰ ç¤¾åŒºç”Ÿæ€ æˆç†Ÿ å¿«é€Ÿå¢é•¿ å¤§å‹åº”ç”¨ Facebookã€Instagram Google Adsã€Alibaba æ€»ç»“ é€‰æ‹©è·¨å¹³å°æ¡†æ¶éœ€è¦è€ƒè™‘å›¢é˜ŸæŠ€æœ¯æ ˆã€é¡¹ç›®éœ€æ±‚å’Œé•¿æœŸç»´æŠ¤ã€‚React Nativeé€‚åˆWebèƒŒæ™¯å›¢é˜Ÿï¼ŒFlutteråˆ™æä¾›æ›´å¥½çš„æ€§èƒ½å’Œä¸€è‡´æ€§ã€‚
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/ class=category-link>ç§»åŠ¨å¼€å‘</a><a href=/blog/categories/%E8%B7%A8%E5%B9%B3%E5%8F%B0/ class=category-link>è·¨å¹³å°</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to è·¨å¹³å°ç§»åŠ¨å¼€å‘å®Œå…¨æŒ‡å—ï¼šReact Nativeä¸Flutteræ·±åº¦å®è·µ" href=/blog/articles/%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97react-native%E4%B8%8Eflutter%E6%B7%B1%E5%BA%A6%E5%AE%9E%E8%B7%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>æ•°æ®åº“ä¼˜åŒ–ä¸åˆ†å¸ƒå¼å­˜å‚¨ï¼šæ„å»ºé«˜æ€§èƒ½æ•°æ®æ¶æ„</h2></header><div class=entry-content><p>å¼•è¨€ æ•°æ®æ˜¯ç°ä»£åº”ç”¨çš„æ ¸å¿ƒèµ„äº§ã€‚éšç€æ•°æ®é‡çš„çˆ†ç‚¸å¼å¢é•¿ï¼Œæ•°æ®åº“æ€§èƒ½å’Œå¯æ‰©å±•æ€§æˆä¸ºç³»ç»Ÿè®¾è®¡çš„å…³é”®æŒ‘æˆ˜ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨æ•°æ®åº“ä¼˜åŒ–æŠ€å·§å’Œåˆ†å¸ƒå¼å­˜å‚¨æ¶æ„ï¼Œå¸®åŠ©è¯»è€…æ„å»ºé«˜æ€§èƒ½çš„æ•°æ®æ¶æ„ã€‚
ä¸€ã€æ•°æ®åº“æ€§èƒ½ä¼˜åŒ– 1.1 ç´¢å¼•ä¼˜åŒ–ç­–ç•¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 -- ========== ç´¢å¼•åŸºç¡€ ========== -- 1. B-Treeç´¢å¼•ï¼ˆæœ€å¸¸ç”¨ï¼‰ -- é€‚åˆï¼šç­‰å€¼æŸ¥è¯¢ã€èŒƒå›´æŸ¥è¯¢ã€æ’åº CREATE INDEX idx_user_email ON users(email); CREATE INDEX idx_order_created ON orders(created_at); -- 2. å¤åˆç´¢å¼• -- æ³¨æ„ï¼šæœ€å·¦å‰ç¼€åŸåˆ™ CREATE INDEX idx_user_status_created ON users(status, created_at); -- æœ‰æ•ˆçš„æŸ¥è¯¢ï¼ˆèƒ½ä½¿ç”¨ç´¢å¼•ï¼‰ SELECT * FROM users WHERE status = 1 AND created_at > '2024-01-01'; SELECT * FROM users WHERE status = 1; -- æ— æ•ˆçš„æŸ¥è¯¢ï¼ˆä¸èƒ½ä½¿ç”¨ç´¢å¼•ï¼‰ SELECT * FROM users WHERE created_at > '2024-01-01'; -- 3. è¦†ç›–ç´¢å¼• -- åŒ…å«æŸ¥è¯¢æ‰€éœ€çš„æ‰€æœ‰å­—æ®µï¼Œé¿å…å›è¡¨ CREATE INDEX idx_user_cover ON users(status, created_at, id, name); -- 4. å”¯ä¸€ç´¢å¼• CREATE UNIQUE INDEX idx_user_username ON users(username); -- ========== ç´¢å¼•è®¾è®¡åŸåˆ™ ========== /* 1. é€‰æ‹©æ€§é«˜çš„å­—æ®µé€‚åˆå»ºç´¢å¼• - é«˜é€‰æ‹©æ€§ï¼šå”¯ä¸€å€¼å¤šï¼ˆå¦‚ç”¨æˆ·IDã€é‚®ç®±ï¼‰ - ä½é€‰æ‹©æ€§ï¼šé‡å¤å€¼å¤šï¼ˆå¦‚æ€§åˆ«ã€çŠ¶æ€ï¼‰ 2. WHEREã€JOINã€ORDER BYå­å¥çš„å­—æ®µ 3. å°å­—æ®µä¼˜å…ˆ - æ•´æ•° > æ—¥æœŸ > çŸ­å­—ç¬¦ä¸² > é•¿å­—ç¬¦ä¸² 4. è”åˆç´¢å¼•çš„é¡ºåº - æœ€å¸¸æŸ¥è¯¢çš„å­—æ®µæ”¾å‰é¢ - èŒƒå›´æŸ¥è¯¢å­—æ®µæ”¾åé¢ 5. é¿å…è¿‡å¤šç´¢å¼• - é™ä½å†™å…¥æ€§èƒ½ - å ç”¨å­˜å‚¨ç©ºé—´ */ -- ========== ç´¢å¼•ä¼˜åŒ–æ¡ˆä¾‹ ========== -- é—®é¢˜ï¼šæŸ¥è¯¢æ…¢ -- è€—æ—¶ï¼š2.5ç§’ SELECT * FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.status = 'pending' AND o.created_at > '2024-01-01' ORDER BY o.created_at DESC LIMIT 20; -- ä¼˜åŒ–1ï¼šæ·»åŠ åˆé€‚ç´¢å¼• CREATE INDEX idx_orders_status_created ON orders(status, created_at DESC); CREATE INDEX idx_orders_user_id ON orders(user_id); -- è€—æ—¶ï¼š0.3ç§’ -- ä¼˜åŒ–2ï¼šåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µ SELECT o.id, o.order_no, o.total_amount, u.username FROM orders o LEFT JOIN users u ON o.user_id = u.id WHERE o.status = 'pending' AND o.created_at > '2024-01-01' ORDER BY o.created_at DESC LIMIT 20; -- è€—æ—¶ï¼š0.1ç§’ -- ä¼˜åŒ–3ï¼šä½¿ç”¨è¦†ç›–ç´¢å¼• CREATE INDEX idx_orders_cover ON orders( status, created_at DESC, id, order_no, total_amount, user_id ); -- è€—æ—¶ï¼š0.05ç§’ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 # ========== ç´¢å¼•åˆ†æä¸ç»´æŠ¤ ========== import pymysql from typing import List, Dict, Tuple class IndexAnalyzer: """ç´¢å¼•åˆ†æå™¨""" def __init__(self, connection_config: dict): self.conn = pymysql.connect(**connection_config) def analyze_table_indexes(self, table_name: str) -> List[Dict]: """åˆ†æè¡¨çš„ç´¢å¼•ä½¿ç”¨æƒ…å†µ""" with self.conn.cursor() as cursor: # æŸ¥è¯¢ç´¢å¼•ä¿¡æ¯ sql = """ SHOW INDEX FROM %s """ % table_name cursor.execute(sql) indexes = cursor.fetchall() # æŸ¥è¯¢ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡ sql = """ SELECT table_name, index_name, cardinality, column_name, seq_in_index FROM information_schema.statistics WHERE table_schema = DATABASE() AND table_name = %s ORDER BY index_name, seq_in_index """ cursor.execute(sql, (table_name,)) stats = cursor.fetchall() return { 'indexes': indexes, 'statistics': stats } def find_unused_indexes(self) -> List[Dict]: """æŸ¥æ‰¾æœªä½¿ç”¨çš„ç´¢å¼•""" with self.conn.cursor() as cursor: # MySQL 5.7+ ä½¿ç”¨performance_schema sql = """ SELECT object_schema AS table_schema, object_name AS table_name, index_name FROM performance_schema.table_io_waits_summary_by_index_usage WHERE index_name IS NOT NULL AND count_star = 0 AND index_name != 'PRIMARY' ORDER BY object_schema, object_name """ cursor.execute(sql) return cursor.fetchall() def find_duplicate_indexes(self, table_name: str) -> List[Tuple]: """æŸ¥æ‰¾å†—ä½™ç´¢å¼•""" with self.conn.cursor() as cursor: # æŸ¥è¯¢ç´¢å¼•åŠå…¶åˆ— sql = """ SELECT index_name, GROUP_CONCAT(column_name ORDER BY seq_in_index) as columns FROM information_schema.statistics WHERE table_schema = DATABASE() AND table_name = %s GROUP BY index_name HAVING COUNT(*) > 1 """ cursor.execute(sql, (table_name,)) indexes = cursor.fetchall() # æŸ¥æ‰¾å†—ä½™ç´¢å¼• duplicates = [] for i, idx1 in enumerate(indexes): for idx2 in indexes[i+1:]: # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³ç³» if idx2[1].startswith(idx1[1]): duplicates.append((idx1[0], idx2[0])) return duplicates def suggest_indexes(self, table_name: str) -> List[Dict]: """æ¨èç´¢å¼•""" with self.conn.cursor() as cursor: # åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿— sql = """ SELECT sql_text, count(*) as frequency FROM mysql.slow_log WHERE sql_text LIKE %s GROUP BY sql_text ORDER BY frequency DESC LIMIT 10 """ cursor.execute(sql, (f'%{table_name}%',)) slow_queries = cursor.fetchall() suggestions = [] for query, freq in slow_queries: # æå–WHEREæ¡ä»¶å­—æ®µ # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦è§£æSQL # ... suggestions.append({ 'query': query, 'frequency': freq, 'suggested_index': 'å»ºè®®åŸºäºWHEREå­å¥åˆ›å»ºç´¢å¼•' }) return suggestions 1.2 æŸ¥è¯¢ä¼˜åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 -- ========== SQLæŸ¥è¯¢ä¼˜åŒ– ========== -- 1. é¿å…SELECT * -- ä¸æ¨è SELECT * FROM users WHERE id = 1; -- æ¨è SELECT id, username, email FROM users WHERE id = 1; -- 2. ä½¿ç”¨LIMITé™åˆ¶ç»“æœé›† SELECT * FROM orders WHERE status = 'pending' LIMIT 100; -- 3. ä¼˜åŒ–JOIN -- å°è¡¨é©±åŠ¨å¤§è¡¨ SELECT * FROM small_table s JOIN large_table l ON s.id = l.small_id; -- 4. å­æŸ¥è¯¢ä¼˜åŒ– -- ä¸æ¨è SELECT * FROM users WHERE id IN (SELECT user_id FROM orders WHERE amount > 1000); -- æ¨è SELECT DISTINCT u.* FROM users u INNER JOIN orders o ON u.id = o.user_id WHERE o.amount > 1000; -- 5. EXISTS vs IN -- å°è¡¨ç”¨INï¼Œå¤§è¡¨ç”¨EXISTS -- å°è¡¨ SELECT * FROM users WHERE id IN (1, 2, 3); -- å¤§è¡¨ SELECT * FROM users u WHERE EXISTS ( SELECT 1 FROM orders o WHERE o.user_id = u.id AND o.status = 'pending' ); -- 6. é¿å…åœ¨WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•° -- ä¸æ¨è SELECT * FROM orders WHERE DATE(created_at) = '2024-01-01'; -- æ¨è SELECT * FROM orders WHERE created_at >= '2024-01-01' AND created_at &lt; '2024-01-02'; -- 7. ä½¿ç”¨UNION ALLä»£æ›¿UNION -- ä¸æ¨èï¼ˆå»é‡å¼€é”€å¤§ï¼‰ SELECT user_id FROM orders_2024 UNION SELECT user_id FROM orders_2023; -- æ¨è SELECT user_id FROM orders_2024 UNION ALL SELECT user_id FROM orders_2023; -- 8. æ‰¹é‡æ“ä½œ -- ä¸æ¨èï¼ˆå¤šæ¬¡å•æ¡æ’å…¥ï¼‰ INSERT INTO logs (message) VALUES ('log1'); INSERT INTO logs (message) VALUES ('log2'); INSERT INTO logs (message) VALUES ('log3'); -- æ¨è INSERT INTO logs (message) VALUES ('log1'), ('log2'), ('log3'); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 # ========== æŸ¥è¯¢ä¼˜åŒ–å™¨ ========== import re from typing import List, Dict, Tuple class SQLQueryOptimizer: """SQLæŸ¥è¯¢ä¼˜åŒ–å™¨""" def __init__(self): self.rules = { 'select_star': self._check_select_star, 'missing_where': self._check_missing_where, 'function_in_where': self._check_function_in_where, 'subquery': self._check_subquery, 'nplus1': self._check_nplus1 } def optimize(self, sql: str) -> Dict: """ä¼˜åŒ–SQL""" issues = [] suggestions = [] for rule_name, rule_func in self.rules.items(): result = rule_func(sql) if result: issues.append(result['issue']) suggestions.append(result['suggestion']) return { 'original_sql': sql, 'issues': issues, 'suggestions': suggestions } def _check_select_star(self, sql: str) -> Dict: """æ£€æŸ¥SELECT ***""" if re.search(r'SELECT\s+\*\s+FROM', sql, re.IGNORECASE): return { 'issue': 'ä½¿ç”¨SELECT *', 'suggestion': 'åªæŸ¥è¯¢éœ€è¦çš„åˆ—ï¼Œå‡å°‘æ•°æ®ä¼ è¾“' } return None def _check_missing_where(self, sql: str) -> Dict: """æ£€æŸ¥ç¼ºå°‘WHEREæ¡ä»¶""" if re.search(r'(DELETE|UPDATE)\s+\w+\s+(?!WHERE)', sql, re.IGNORECASE): return { 'issue': 'DELETE/UPDATEç¼ºå°‘WHEREæ¡ä»¶', 'suggestion': 'æ·»åŠ WHEREæ¡ä»¶ï¼Œé¿å…å…¨è¡¨æ“ä½œ' } return None def _check_function_in_where(self, sql: str) -> Dict: """æ£€æŸ¥WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•°""" if re.search( r'WHERE\s+.*(?:DATE|YEAR|MONTH|DAY)\(', sql, re.IGNORECASE ): return { 'issue': 'WHEREå­å¥ä¸­ä½¿ç”¨å‡½æ•°', 'suggestion': 'å°†å‡½æ•°ä½œç”¨åˆ°æ¯”è¾ƒå€¼ä¸Šï¼Œè€Œéå­—æ®µ' } return None def _check_subquery(self, sql: str) -> Dict: """æ£€æŸ¥å­æŸ¥è¯¢""" if 'IN (SELECT' in sql.upper(): return { 'issue': 'ä½¿ç”¨INå­æŸ¥è¯¢', 'suggestion': 'è€ƒè™‘æ”¹ç”¨JOINæˆ–EXISTS' } return None def _check_nplus1(self, sql: str) -> Dict: """æ£€æŸ¥N+1æŸ¥è¯¢""" # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦åˆ†ææ‰§è¡Œæ¨¡å¼ return None class QueryExecutionAnalyzer: """æŸ¥è¯¢æ‰§è¡Œåˆ†æå™¨""" def __init__(self, connection): self.conn = connection def explain_query(self, sql: str) -> Dict: """åˆ†ææŸ¥è¯¢æ‰§è¡Œè®¡åˆ’""" with self.conn.cursor() as cursor: # æ‰§è¡ŒEXPLAIN explain_sql = f"EXPLAIN {sql}" cursor.execute(explain_sql) result = cursor.fetchall() analysis = { 'type': [], 'table': [], 'possible_keys': [], 'key': [], 'rows': [], 'filtered': [], 'extra': [] } for row in result: analysis['type'].append(row['type']) analysis['table'].append(row['table']) analysis['possible_keys'].append(row['possible_keys']) analysis['key'].append(row['key']) analysis['rows'].append(row['rows']) analysis['filtered'].append(row['filtered']) analysis['extra'].append(row['Extra']) # åˆ†æç»“æœ suggestions = [] # æ£€æŸ¥æ˜¯å¦å…¨è¡¨æ‰«æ if 'ALL' in analysis['type']: suggestions.append( 'è­¦å‘Šï¼šå­˜åœ¨å…¨è¡¨æ‰«æï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•' ) # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼• if None in analysis['key']: suggestions.append( 'éƒ¨åˆ†æŸ¥è¯¢æ²¡æœ‰ä½¿ç”¨ç´¢å¼•ï¼Œæ£€æŸ¥ç´¢å¼•è®¾è®¡' ) # æ£€æŸ¥æ‰«æè¡Œæ•° if analysis['rows'] and sum(analysis['rows']) > 10000: suggestions.append( 'æ‰«æè¡Œæ•°è¾ƒå¤šï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–ç´¢å¼•' ) return { 'explain_plan': result, 'suggestions': suggestions } def profile_query(self, sql: str) -> Dict: """åˆ†ææŸ¥è¯¢æ€§èƒ½""" with self.conn.cursor() as cursor: # å¼€å¯profiling cursor.execute("SET profiling = 1") # æ‰§è¡ŒæŸ¥è¯¢ cursor.execute(sql) # è·å–profilingç»“æœ cursor.execute("SHOW PROFILE") profile = cursor.fetchall() # è·å–æŸ¥è¯¢ç»Ÿè®¡ cursor.execute("SHOW PROFILE FOR QUERY 1") stats = cursor.fetchall() return { 'profile': profile, 'statistics': stats } äºŒã€åˆ†åº“åˆ†è¡¨ç­–ç•¥ 2.1 æ°´å¹³åˆ†è¡¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 # ========== åˆ†è¡¨ç­–ç•¥ ========== class ShardingStrategy: """åˆ†ç‰‡ç­–ç•¥""" def __init__(self, shard_count: int): self.shard_count = shard_count def hash_sharding(self, key: str) -> int: """å“ˆå¸Œåˆ†ç‰‡""" hash_value = hash(key) return hash_value % self.shard_count def range_sharding(self, key: int) -> int: """èŒƒå›´åˆ†ç‰‡""" # å‡è®¾keyæ˜¯è‡ªå¢ID shard_size = 1000000 # æ¯ä¸ªåˆ†ç‰‡100ä¸‡æ¡ return key // shard_size def modulo_sharding(self, key: int) -> int: """å–æ¨¡åˆ†ç‰‡""" return key % self.shard_count def consistent_hash_sharding(self, key: str) -> int: """ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡""" import hashlib hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16) return hash_value % self.shard_count class ShardingManager: """åˆ†ç‰‡ç®¡ç†å™¨""" def __init__(self, shard_configs: List[dict]): self.shards = {} for config in shard_configs: shard_id = config['id'] self.shards[shard_id] = { 'connection': self._create_connection(config), 'config': config } self.strategy = ShardingStrategy(len(shard_configs)) def _create_connection(self, config: dict): """åˆ›å»ºæ•°æ®åº“è¿æ¥""" import pymysql return pymysql.connect( host=config['host'], port=config['port'], user=config['user'], password=config['password'], database=config['database'] ) def get_shard(self, shard_key: str, sharding_type: str = 'hash'): """è·å–åˆ†ç‰‡è¿æ¥""" if sharding_type == 'hash': shard_id = self.strategy.hash_sharding(shard_key) elif sharding_type == 'consistent': shard_id = self.strategy.consistent_hash_sharding(shard_key) elif sharding_type == 'modulo': shard_id = self.strategy.modulo_sharding(int(shard_key)) else: raise ValueError(f"Unknown sharding type: {sharding_type}") return self.shards[shard_id]['connection'] def execute_on_shard(self, shard_key: str, sql: str, params=None): """åœ¨æŒ‡å®šåˆ†ç‰‡æ‰§è¡ŒSQL""" conn = self.get_shard(shard_key) with conn.cursor() as cursor: cursor.execute(sql, params or ()) return cursor.fetchall() def query_all_shards(self, sql: str, params=None): """æŸ¥è¯¢æ‰€æœ‰åˆ†ç‰‡""" results = [] for shard_id, shard in self.shards.items(): conn = shard['connection'] with conn.cursor() as cursor: cursor.execute(sql, params or ()) shard_results = cursor.fetchall() # æ·»åŠ åˆ†ç‰‡æ ‡è¯† for row in shard_results: if isinstance(row, dict): row['_shard_id'] = shard_id results.extend(shard_results) return results def broadcast_write(self, sql: str, params=None): """å¹¿æ’­å†™å…¥æ‰€æœ‰åˆ†ç‰‡""" results = [] for shard_id, shard in self.shards.items(): conn = shard['connection'] with conn.cursor() as cursor: cursor.execute(sql, params or ()) conn.commit() results.append({ 'shard_id': shard_id, 'affected_rows': cursor.rowcount }) return results # ========== åˆ†è¡¨è·¯ç”± ========== class TableRouter: """è¡¨è·¯ç”±""" def __init__(self, sharding_manager: ShardingManager): self.manager = sharding_manager self.table_rules = {} def add_rule(self, table_name: str, sharding_key: str, sharding_type: str): """æ·»åŠ åˆ†è¡¨è§„åˆ™""" self.table_rules[table_name] = { 'sharding_key': sharding_key, 'sharding_type': sharding_type } def get_table_name(self, original_table: str, shard_key: str) -> str: """è·å–å®é™…è¡¨å""" rule = self.table_rules.get(original_table) if not rule: return original_table # è®¡ç®—åˆ†ç‰‡ID if rule['sharding_type'] == 'hash': shard_id = hash(shard_key) % self.manager.strategy.shard_count elif rule['sharding_type'] == 'modulo': shard_id = int(shard_key) % self.manager.strategy.shard_count else: shard_id = 0 return f"{original_table}_{shard_id:04d}" def execute_query(self, table_name: str, query_template: str, **kwargs): """æ‰§è¡Œåˆ†è¡¨æŸ¥è¯¢""" # è·å–åˆ†ç‰‡é”®å€¼ rule = self.table_rules.get(table_name) if not rule: # ä¸åˆ†è¡¨ï¼Œç›´æ¥æ‰§è¡Œ return self.manager.execute_on_shard('0', query_template, kwargs) shard_key_value = kwargs.get(rule['sharding_key']) if not shard_key_value: raise ValueError(f"Missing sharding key: {rule['sharding_key']}") # è·å–å®é™…è¡¨å actual_table = self.get_table_name(table_name, str(shard_key_value)) # æ›¿æ¢è¡¨å actual_query = query_template.replace(f'FROM {table_name}', f'FROM {actual_table}') return self.manager.execute_on_shard(str(shard_key_value), actual_query, kwargs) # ä½¿ç”¨ç¤ºä¾‹ shard_configs = [ { 'id': 0, 'host': 'db0.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_0' }, { 'id': 1, 'host': 'db1.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_1' }, { 'id': 2, 'host': 'db2.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_2' }, { 'id': 3, 'host': 'db3.example.com', 'port': 3306, 'user': 'root', 'password': 'password', 'database': 'app_db_3' } ] sharding_manager = ShardingManager(shard_configs) table_router = TableRouter(sharding_manager) # é…ç½®ordersè¡¨æŒ‰user_idåˆ†è¡¨ table_router.add_rule('orders', 'user_id', 'modulo') # æ’å…¥è®¢å•ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„åˆ†ç‰‡ï¼‰ table_router.execute_query( 'orders', "INSERT INTO orders (user_id, order_no, total_amount) VALUES (:user_id, :order_no, :total_amount)", user_id=12345, order_no='ORD2024010112345', total_amount=9999.99 ) # æŸ¥è¯¢è®¢å•ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„åˆ†ç‰‡ï¼‰ results = table_router.execute_query( 'orders', "SELECT * FROM orders WHERE user_id = :user_id", user_id=12345 ) 2.2 å‚ç›´åˆ†åº“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 # ========== å‚ç›´åˆ†åº“ç­–ç•¥ ========== class VerticalSharding: """å‚ç›´åˆ†åº“""" def __init__(self): self.databases = { 'user_db': None, # ç”¨æˆ·ç›¸å…³è¡¨ 'order_db': None, # è®¢å•ç›¸å…³è¡¨ 'product_db': None, # å•†å“ç›¸å…³è¡¨ 'log_db': None # æ—¥å¿—ç›¸å…³è¡¨ } def route_by_module(self, table_name: str): """æŒ‰æ¨¡å—è·¯ç”±""" module_mapping = { # ç”¨æˆ·æ¨¡å— 'users': 'user_db', 'user_profiles': 'user_db', 'user_addresses': 'user_db', 'user_preferences': 'user_db', # è®¢å•æ¨¡å— 'orders': 'order_db', 'order_items': 'order_db', 'order_payments': 'order_db', 'order_shippings': 'order_db', # å•†å“æ¨¡å— 'products': 'product_db', 'categories': 'product_db', 'product_skus': 'product_db', 'inventory': 'product_db', # æ—¥å¿—æ¨¡å— 'operation_logs': 'log_db', 'access_logs': 'log_db', 'error_logs': 'log_db' } return self.databases.get(module_mapping.get(table_name)) def cross_database_query(self, queries: List[dict]): """è·¨åº“æŸ¥è¯¢""" results = {} for query_info in queries: db_name = query_info['database'] sql = query_info['sql'] params = query_info.get('params', {}) conn = self.databases[db_name] with conn.cursor() as cursor: cursor.execute(sql, params) results[db_name] = cursor.fetchall() # åœ¨åº”ç”¨å±‚åˆå¹¶ç»“æœ return self._merge_results(results) def _merge_results(self, results: dict) -> List[dict]: """åˆå¹¶è·¨åº“æŸ¥è¯¢ç»“æœ""" # æ ¹æ®ä¸šåŠ¡é€»è¾‘åˆå¹¶ç»“æœ # è¿™é‡Œæ˜¯ç®€åŒ–ç¤ºä¾‹ merged = [] # ä»user_dbè·å–ç”¨æˆ·ä¿¡æ¯ users = results.get('user_db', []) # ä»order_dbè·å–è®¢å•ä¿¡æ¯ orders = results.get('order_db', []) # åˆå¹¶æ•°æ® user_dict = {user['id']: user for user in users} for order in orders: user_id = order['user_id'] if user_id in user_dict: merged.append({ **user_dict[user_id], 'order': order }) return merged # ========== åˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆSagaæ¨¡å¼ï¼‰ ========== class DistributedTransaction: """åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç†å™¨""" def __init__(self): self.participants = [] self.compensations = [] def add_participant(self, database: str, operation: str, compensation: str): """æ·»åŠ äº‹åŠ¡å‚ä¸è€…""" self.participants.append({ 'database': database, 'operation': operation }) self.compensations.append({ 'database': database, 'operation': compensation }) async def execute(self) -> bool: """æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡""" executed = [] try: # é¡ºåºæ‰§è¡Œå„åˆ†åº“æ“ä½œ for participant in self.participants: conn = self.databases[participant['database']] with conn.cursor() as cursor: cursor.execute(participant['operation']) conn.commit() executed.append(participant) return True except Exception as e: # æ‰§è¡Œè¡¥å¿æ“ä½œ for i in range(len(executed) - 1, -1, -1): compensation = self.compensations[i] try: conn = self.databases[compensation['database']] with conn.cursor() as cursor: cursor.execute(compensation['operation']) conn.commit() except Exception as ce: # è¡¥å¿å¤±è´¥ï¼Œè®°å½•æ—¥å¿— print(f"Compensation failed: {ce}") return False ä¸‰ã€åˆ†å¸ƒå¼æ•°æ®åº“ 3.1 NewSQLæ•°æ®åº“ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 # ========== TiDBé›†æˆç¤ºä¾‹ ========== import MySQLdb class TiDBClient: """TiDBå®¢æˆ·ç«¯""" def __init__(self, host: str, port: int, user: str, password: str, database: str): self.conn = MySQLdb.connect( host=host, port=port, user=user, password=password, database=database, charset='utf8mb4' ) def insert_batch(self, table: str, records: List[dict]) -> int: """æ‰¹é‡æ’å…¥""" if not records: return 0 # æ„å»ºæ‰¹é‡æ’å…¥SQL columns = list(records[0].keys()) placeholders = ', '.join(['%s'] * len(columns)) sql = f""" INSERT INTO {table} ({', '.join(columns)}) VALUES ({placeholders}) """ values = [ tuple(record[col] for col in columns) for record in records ] with self.conn.cursor() as cursor: cursor.executemany(sql, values) self.conn.commit() return cursor.rowcount def select_with_pagination( self, table: str, where: str = None, order_by: str = None, limit: int = 100, offset: int = 0 ) -> List[dict]: """åˆ†é¡µæŸ¥è¯¢""" sql = f"SELECT * FROM {table}" if where: sql += f" WHERE {where}" if order_by: sql += f" ORDER BY {order_by}" sql += f" LIMIT {limit} OFFSET {offset}" with self.conn.cursor(MySQLdb.cursors.DictCursor) as cursor: cursor.execute(sql) return cursor.fetchall() def get_transaction_info(self) -> dict: """è·å–äº‹åŠ¡ä¿¡æ¯""" with self.conn.cursor() as cursor: # æŸ¥è¯¢å½“å‰äº‹åŠ¡ä¿¡æ¯ cursor.execute("SELECT @@txn_version as version") version = cursor.fetchone() cursor.execute("SELECT @@autocommit as autocommit") autocommit = cursor.fetchone() return { 'version': version[0] if version else None, 'autocommit': autocommit[0] if autocommit else None } # ========== åˆ†å¸ƒå¼äº‹åŠ¡ä½¿ç”¨ ========== class DistributedOrderService: """åˆ†å¸ƒå¼è®¢å•æœåŠ¡""" def __init__(self, tidb_client: TiDBClient): self.tidb = tidb_client async def create_order(self, order_data: dict, items: List[dict]) -> str: """åˆ›å»ºè®¢å•ï¼ˆåˆ†å¸ƒå¼äº‹åŠ¡ï¼‰""" try: # å¼€å¯äº‹åŠ¡ with self.tidb.conn as cursor: # 1. åˆ›å»ºè®¢å• order_sql = """ INSERT INTO orders (user_id, order_no, total_amount, status) VALUES (%s, %s, %s, %s) """ cursor.execute(order_sql, ( order_data['user_id'], order_data['order_no'], order_data['total_amount'], 'pending' )) order_id = cursor.lastrowid # 2. åˆ›å»ºè®¢å•æ˜ç»† for item in items: item_sql = """ INSERT INTO order_items ( order_id, product_id, quantity, price ) VALUES (%s, %s, %s, %s) """ cursor.execute(item_sql, ( order_id, item['product_id'], item['quantity'], item['price'] )) # 3. æ‰£å‡åº“å­˜ for item in items: inventory_sql = """ UPDATE inventory SET stock = stock - %s WHERE product_id = %s AND stock >= %s """ affected = cursor.execute(inventory_sql, ( item['quantity'], item['product_id'], item['quantity'] )) if affected == 0: # åº“å­˜ä¸è¶³ï¼Œå›æ»šäº‹åŠ¡ raise Exception(f"Insufficient stock for product {item['product_id']}") # 4. åˆ›å»ºæ”¯ä»˜è®°å½• payment_sql = """ INSERT INTO payments ( order_id, amount, status, payment_method ) VALUES (%s, %s, %s, %s) """ cursor.execute(payment_sql, ( order_id, order_data['total_amount'], 'pending', order_data['payment_method'] )) # æäº¤äº‹åŠ¡ self.tidb.conn.commit() return order_id except Exception as e: # å›æ»šäº‹åŠ¡ self.tidb.conn.rollback() raise e 3.2 åˆ†å¸ƒå¼ç¼“å­˜ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 # ========== Redisé›†ç¾¤ ========== import redis from rediscluster import RedisCluster class RedisClusterClient: """Redisé›†ç¾¤å®¢æˆ·ç«¯""" def __init__(self, startup_nodes: List[dict]): """ startup_nodes: [ {'host': 'redis1.example.com', 'port': 7000}, {'host': 'redis2.example.com', 'port': 7001}, {'host': 'redis3.example.com', 'port': 7002} ] """ self.client = RedisCluster( startup_nodes=startup_nodes, decode_responses=True, skip_full_coverage_check=True, max_connections=32 ) def set(self, key: str, value: str, expire: int = None): """è®¾ç½®é”®å€¼""" return self.client.set(key, value, ex=expire) def get(self, key: str) -> str: """è·å–å€¼""" return self.client.get(key) def mget(self, keys: List[str]) -> List[str]: """æ‰¹é‡è·å–""" return self.client.mget(keys) def delete(self, *keys: str): """åˆ é™¤é”®""" return self.client.delete(*keys) def exists(self, *keys: str) -> int: """æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨""" return self.client.exists(*keys) def expire(self, key: str, seconds: int): """è®¾ç½®è¿‡æœŸæ—¶é—´""" return self.client.expire(key, seconds) def incr(self, key: str, amount: int = 1) -> int: """é€’å¢""" return self.client.incrby(key, amount) def decr(self, key: str, amount: int = 1) -> int: """é€’å‡""" return self.client.decrby(key, amount) def hset(self, name: str, key: str, value: str): """å“ˆå¸Œè¡¨è®¾ç½®""" return self.client.hset(name, key, value) def hget(self, name: str, key: str) -> str: """å“ˆå¸Œè¡¨è·å–""" return self.client.hget(name, key) def hgetall(self, name: str) -> dict: """è·å–æ•´ä¸ªå“ˆå¸Œè¡¨""" return self.client.hgetall(name) # ========== ç¼“å­˜ç­–ç•¥ ========== class CacheStrategy: """ç¼“å­˜ç­–ç•¥""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def cache_aside(self, key: str, load_func, expire: int = 3600): """Cache-Asideæ¨¡å¼""" # å…ˆæŸ¥ç¼“å­˜ value = self.redis.get(key) if value is not None: return value # ç¼“å­˜æœªå‘½ä¸­ï¼ŒåŠ è½½æ•°æ® value = load_func() # å†™å…¥ç¼“å­˜ self.redis.set(key, value, expire) return value def invalidate(self, *keys: str): """ä½¿ç¼“å­˜å¤±æ•ˆ""" self.redis.delete(*keys) def warm_up(self, data: dict, expire: int = 3600): """ç¼“å­˜é¢„çƒ­""" pipe = self.redis.client.pipeline() for key, value in data.items(): pipe.set(key, value, expire) pipe.execute() def update(self, key: str, value: str, expire: int = 3600): """æ›´æ–°ç¼“å­˜""" self.redis.set(key, value, expire) # ========== åˆ†å¸ƒå¼é” ========== class DistributedLock: """åˆ†å¸ƒå¼é”""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def acquire( self, lock_name: str, acquire_timeout: int = 10, lock_timeout: int = 30 ) -> bool: """è·å–é”""" import time lock_key = f"lock:{lock_name}" lock_value = f"{time.time()}" end_time = time.time() + acquire_timeout while time.time() &lt; end_time: # å°è¯•è·å–é” if self.redis.client.set( lock_key, lock_value, nx=True, ex=lock_timeout ): return True time.sleep(0.001) return False def release(self, lock_name: str): """é‡Šæ”¾é”""" lock_key = f"lock:{lock_name}" # ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åªé‡Šæ”¾è‡ªå·±çš„é” lua_script = """ if redis.call("get", KEYS[1]) == ARGV[1] then return redis.call("del", KEYS[1]) else return 0 end """ self.redis.client.eval( lua_script, 1, lock_key, self.redis.get(lock_key) ) # ========== é™æµå™¨ ========== class RateLimiter: """åˆ†å¸ƒå¼é™æµå™¨""" def __init__(self, redis_client: RedisClusterClient): self.redis = redis_client def is_allowed( self, key: str, limit: int, window: int ) -> bool: """ æ»‘åŠ¨çª—å£é™æµ key: é™æµé”®ï¼ˆå¦‚ç”¨æˆ·IDã€IPç­‰ï¼‰ limit: æ—¶é—´çª—å£å†…æœ€å¤§è¯·æ±‚æ•° window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ """ import time now = time.time() window_start = now - window pipe = self.redis.client.pipeline() # ç§»é™¤æ—¶é—´çª—å£å¤–çš„è®°å½• pipe.zremrangebyscore(key, 0, window_start) # è·å–å½“å‰è®¡æ•° pipe.zcard(key) # æ·»åŠ å½“å‰è¯·æ±‚ pipe.zadd(key, {str(now): now}) # è®¾ç½®è¿‡æœŸæ—¶é—´ pipe.expire(key, window + 1) results = pipe.execute() current_count = results[1] return current_count &lt; limit å››ã€æ•°æ®åº“ç›‘æ§ä¸è¿ç»´ 4.1 æ€§èƒ½ç›‘æ§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 # ========== æ•°æ®åº“ç›‘æ§ ========== class DatabaseMonitor: """æ•°æ®åº“ç›‘æ§""" def __init__(self, connection): self.conn = connection def get_connection_stats(self) -> dict: """è·å–è¿æ¥ç»Ÿè®¡""" with self.conn.cursor() as cursor: cursor.execute(""" SHOW STATUS LIKE 'Threads%' """) stats = cursor.fetchall() return { 'threads_connected': next( (s[1] for s in stats if s[0] == 'Threads_connected'), 0 ), 'threads_running': next( (s[1] for s in stats if s[0] == 'Threads_running'), 0 ) } def get_query_stats(self) -> dict: """è·å–æŸ¥è¯¢ç»Ÿè®¡""" with self.conn.cursor() as cursor: # æ…¢æŸ¥è¯¢ç»Ÿè®¡ cursor.execute(""" SELECT COUNT(*) as slow_query_count, AVG(query_time) as avg_query_time, MAX(query_time) as max_query_time FROM mysql.slow_log WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR) """) slow_stats = cursor.fetchone() # QPS/TPSç»Ÿè®¡ cursor.execute(""" SHOW STATUS LIKE 'Questions' """) questions = cursor.fetchone() cursor.execute(""" SHOW STATUS LIKE 'Uptime' """) uptime = cursor.fetchone() qps = questions[1] / uptime[1] if uptime[1] > 0 else 0 return { 'slow_query_count': slow_stats[0], 'avg_query_time': float(slow_stats[1]) if slow_stats[1] else 0, 'max_query_time': float(slow_stats[2]) if slow_stats[2] else 0, 'qps': round(qps, 2) } def get_replication_lag(self) -> int: """è·å–ä¸»ä»å»¶è¿Ÿ""" with self.conn.cursor() as cursor: cursor.execute("SHOW SLAVE STATUS") status = cursor.fetchone() if status: return status['Seconds_Behind_Master'] return 0 def get_innodb_stats(self) -> dict: """è·å–InnoDBç»Ÿè®¡""" with self.conn.cursor() as cursor: cursor.execute(""" SHOW STATUS LIKE 'Innodb_%' """) stats = cursor.fetchall() return { 'row_lock_waits': next( (s[1] for s in stats if s[0] == 'Innodb_row_lock_current_waits'), 0 ), 'deadlocks': next( (s[1] for s in stats if s[0] == 'Innodb_deadlocks'), 0 ), 'buffer_pool_hit_rate': self._calculate_hit_rate(stats) } def _calculate_hit_rate(self, stats: list) -> float: """è®¡ç®—ç¼“å†²æ± å‘½ä¸­ç‡""" reads = next( (s[1] for s in stats if s[0] == 'Innodb_buffer_pool_reads'), 0 ) read_requests = next( (s[1] for s in stats if s[0] == 'Innodb_buffer_pool_read_requests'), 1 ) if read_requests == 0: return 100.0 hit_rate = (1 - reads / read_requests) * 100 return round(hit_rate, 2) # ========== æ…¢æŸ¥è¯¢åˆ†æ ========== class SlowQueryAnalyzer: """æ…¢æŸ¥è¯¢åˆ†æå™¨""" def __init__(self, connection): self.conn = connection def get_slow_queries(self, limit: int = 100) -> List[dict]: """è·å–æ…¢æŸ¥è¯¢""" with self.conn.cursor() as cursor: sql = """ SELECT query_time, lock_time, rows_sent, rows_examined, sql_text FROM mysql.slow_log ORDER BY query_time DESC LIMIT %s """ cursor.execute(sql, (limit,)) return cursor.fetchall() def analyze_slow_query(self, query: str) -> dict: """åˆ†ææ…¢æŸ¥è¯¢""" analyzer = SQLQueryOptimizer() return analyzer.optimize(query) def suggest_indexes(self, query: str) -> List[str]: """æ¨èç´¢å¼•""" # æå–WHEREã€JOINã€ORDER BYå­å¥ä¸­çš„å­—æ®µ # è¿™é‡Œç®€åŒ–å¤„ç† import re # æå–è¡¨å tables = re.findall(r'FROM\s+(\w+)', query, re.IGNORECASE) tables += re.findall(r'JOIN\s+(\w+)', query, re.IGNORECASE) # æå–WHEREæ¡ä»¶å­—æ®µ where_fields = re.findall( r'WHERE\s+(\w+)\.\w+\s*=', query, re.IGNORECASE ) suggestions = [] for table in set(tables): for field in set(where_fields): suggestions.append( f"CREATE INDEX idx_{table}_{field} ON {table}({field})" ) return suggestions 4.2 å¤‡ä»½ä¸æ¢å¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 # ========== æ•°æ®åº“å¤‡ä»½ ========== import subprocess import os from datetime import datetime from typing import List class DatabaseBackup: """æ•°æ®åº“å¤‡ä»½""" def __init__( self, host: str, user: str, password: str, backup_dir: str = '/backup' ): self.host = host self.user = user self.password = password self.backup_dir = backup_dir os.makedirs(backup_dir, exist_ok=True) def backup_database( self, database: str, backup_type: str = 'full' ) -> str: """å¤‡ä»½æ•°æ®åº“""" timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') backup_file = os.path.join( self.backup_dir, f"{database}_{backup_type}_{timestamp}.sql" ) # ä½¿ç”¨mysqldumpå¤‡ä»½ command = [ 'mysqldump', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}', '--single-transaction', '--routines', '--triggers', '--events', '--quick', database ] with open(backup_file, 'w') as f: subprocess.run( command, stdout=f, stderr=subprocess.PIPE, check=True ) # å‹ç¼©å¤‡ä»½æ–‡ä»¶ self._compress_file(backup_file) return f"{backup_file}.gz" def backup_all_databases(self) -> str: """å¤‡ä»½æ‰€æœ‰æ•°æ®åº“""" timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') backup_file = os.path.join( self.backup_dir, f"all_databases_{timestamp}.sql" ) command = [ 'mysqldump', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}', '--all-databases', '--single-transaction', '--routines', '--triggers', '--events' ] with open(backup_file, 'w') as f: subprocess.run( command, stdout=f, stderr=subprocess.PIPE, check=True ) self._compress_file(backup_file) return f"{backup_file}.gz" def _compress_file(self, filepath: str): """å‹ç¼©æ–‡ä»¶""" import gzip with open(filepath, 'rb') as f_in: with gzip.open(f"{filepath}.gz", 'wb') as f_out: f_out.writelines(f_in) os.remove(filepath) def restore_database(self, backup_file: str, database: str = None): """æ¢å¤æ•°æ®åº“""" # è§£å‹å¤‡ä»½æ–‡ä»¶ if backup_file.endswith('.gz'): import gzip temp_file = backup_file[:-3] with gzip.open(backup_file, 'rb') as f_in: with open(temp_file, 'wb') as f_out: f_out.writelines(f_in) backup_file = temp_file # æ¢å¤æ•°æ®åº“ command = [ 'mysql', f'--host={self.host}', f'--user={self.user}', f'--password={self.password}' ] if database: command.append(database) with open(backup_file, 'r') as f: subprocess.run( command, stdin=f, stderr=subprocess.PIPE, check=True ) # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ if backup_file.endswith('.sql'): os.remove(backup_file) def list_backups(self) -> List[dict]: """åˆ—å‡ºå¤‡ä»½æ–‡ä»¶""" backups = [] for filename in os.listdir(self.backup_dir): if filename.endswith('.sql.gz'): filepath = os.path.join(self.backup_dir, filename) stat = os.stat(filepath) backups.append({ 'filename': filename, 'size': stat.st_size, 'created_at': datetime.fromtimestamp(stat.st_ctime) }) return sorted(backups, key=lambda x: x['created_at'], reverse=True) def cleanup_old_backups(self, keep_days: int = 7): """æ¸…ç†æ—§å¤‡ä»½""" from datetime import timedelta cutoff_time = datetime.now() - timedelta(days=keep_days) for filename in os.listdir(self.backup_dir): filepath = os.path.join(self.backup_dir, filename) stat = os.stat(filepath) if datetime.fromtimestamp(stat.st_ctime) &lt; cutoff_time: os.remove(filepath) print(f"Removed old backup: {filename}") æ€»ç»“ æ„å»ºé«˜æ€§èƒ½çš„æ•°æ®æ¶æ„éœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/ class=category-link>æ•°æ®åº“</a><a href=/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/ class=category-link>åˆ†å¸ƒå¼ç³»ç»Ÿ</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to æ•°æ®åº“ä¼˜åŒ–ä¸åˆ†å¸ƒå¼å­˜å‚¨ï¼šæ„å»ºé«˜æ€§èƒ½æ•°æ®æ¶æ„" href=/blog/articles/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%9E%84%E5%BB%BA%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ç½‘ç»œå®‰å…¨ä¸æ¼æ´æ·±åº¦åˆ†æï¼šä»æ”»å‡»åˆ°é˜²å¾¡çš„å®Œæ•´æŒ‡å—</h2></header><div class=entry-content><p>å¼•è¨€ ç½‘ç»œå®‰å…¨æ˜¯æ•°å­—åŒ–æ—¶ä»£çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚éšç€æ”»å‡»æ‰‹æ®µçš„ä¸æ–­æ¼”è¿›ï¼Œäº†è§£å¸¸è§æ¼æ´ã€æ”»å‡»æ–¹æ³•å’Œé˜²å¾¡ç­–ç•¥å˜å¾—è‡³å…³é‡è¦ã€‚æœ¬æ–‡å°†æ·±å…¥åˆ†æç½‘ç»œå®‰å…¨é¢†åŸŸçš„æ ¸å¿ƒä¸»é¢˜ï¼Œå¸®åŠ©è¯»è€…æ„å»ºæ›´å®‰å…¨çš„ç³»ç»Ÿã€‚
ä¸€ã€OWASP Top 10æ·±åº¦è§£æ 1.1 æ³¨å…¥æ¼æ´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 # ========== SQLæ³¨å…¥ ========== # ä¸å®‰å…¨çš„ä»£ç ç¤ºä¾‹ def get_user_by_id(user_id): """å±é™©ï¼šç›´æ¥æ‹¼æ¥SQL""" query = f"SELECT * FROM users WHERE id = {user_id}" return db.execute(query) # æ”»å‡»ç¤ºä¾‹ # user_id = "1 OR 1=1" # å®é™…æ‰§è¡Œçš„SQL: SELECT * FROM users WHERE id = 1 OR 1=1 # ç»“æœï¼šè¿”å›æ‰€æœ‰ç”¨æˆ·æ•°æ® # å®‰å…¨çš„ä»£ç ç¤ºä¾‹ import sqlite3 from typing import Optional class UserRepository: """å®‰å…¨çš„ç”¨æˆ·ä»“åº“""" def __init__(self, db_path: str): self.conn = sqlite3.connect(db_path) def get_user_by_id(self, user_id: int) -> Optional[dict]: """ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢""" cursor = self.conn.cursor() # ä½¿ç”¨?å ä½ç¬¦ï¼Œæ•°æ®åº“é©±åŠ¨ä¼šæ­£ç¡®è½¬ä¹‰å‚æ•° query = "SELECT * FROM users WHERE id = ?" cursor.execute(query, (user_id,)) row = cursor.fetchone() if row: return { 'id': row[0], 'username': row[1], 'email': row[2] } return None def search_users(self, keyword: str) -> list: """å®‰å…¨çš„æœç´¢åŠŸèƒ½""" cursor = self.conn.cursor() query = """ SELECT id, username, email FROM users WHERE username LIKE ? OR email LIKE ? """ # ä½¿ç”¨é€šé…ç¬¦è¿›è¡Œæ¨¡ç³Šæœç´¢ pattern = f"%{keyword}%" cursor.execute(query, (pattern, pattern)) return cursor.fetchall() # ========== SQLæ³¨å…¥æ£€æµ‹ä¸é˜²å¾¡ ========== class SQLInjectionDetector: """SQLæ³¨å…¥æ£€æµ‹å™¨""" # å¸¸è§SQLæ³¨å…¥ç‰¹å¾ INJECTION_PATTERNS = [ r"(\%27)|(\')", # å•å¼•å· r"(\-\-)|(#)", # æ³¨é‡Šç¬¦ r"(\bor\b|\band\b).*?=.*?", # é€»è¾‘è¿ç®—ç¬¦ r"(\bunion\b.*\bselect\b)", # UNIONæŸ¥è¯¢ r"(\bselect\b.*\bfrom\b)", # SELECTæŸ¥è¯¢ r"(\bexec\b|\bexecute\b)", # æ‰§è¡Œå‘½ä»¤ r"(;|\bxp_cmdshell\b)", # å‘½ä»¤åˆ†éš”ç¬¦å’Œå­˜å‚¨è¿‡ç¨‹ r"(\bdrop\b|\bdelete\b|\btruncate\b)", # å±é™©æ“ä½œ ] @classmethod def detect_injection(cls, input_string: str) -> bool: """æ£€æµ‹SQLæ³¨å…¥""" import re for pattern in cls.INJECTION_PATTERNS: if re.search(pattern, input_string, re.IGNORECASE): return True return False @classmethod def sanitize_input(cls, input_string: str) -> str: """æ¸…ç†è¾“å…¥""" import re # ç§»é™¤å±é™©å­—ç¬¦ sanitized = re.sub(r"[\'\"\;\-\-]", "", input_string) # é™åˆ¶é•¿åº¦ max_length = 100 sanitized = sanitized[:max_length] return sanitized # ========== ORMå®‰å…¨ä½¿ç”¨ ========== from sqlalchemy import create_engine, Column, Integer, String from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker Base = declarative_base() class User(Base): """ç”¨æˆ·æ¨¡å‹""" __tablename__ = 'users' id = Column(Integer, primary_key=True) username = Column(String(50), nullable=False) email = Column(String(100), nullable=False) class SecureUserRepository: """ä½¿ç”¨ORMçš„å®‰å…¨ä»“åº“""" def __init__(self, database_url: str): self.engine = create_engine(database_url) Session = sessionmaker(bind=self.engine) self.session = Session() def get_user_by_id(self, user_id: int) -> Optional[User]: """ORMè‡ªåŠ¨å¤„ç†å‚æ•°åŒ–""" return self.session.query(User).filter( User.id == user_id ).first() def search_users(self, keyword: str) -> list: """å®‰å…¨çš„æœç´¢""" return self.session.query(User).filter( (User.username.like(f"%{keyword}%")) | (User.email.like(f"%{keyword}%")) ).all() 1.2 è·¨ç«™è„šæœ¬æ”»å‡»(XSS) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 # ========== XSSæ”»å‡»ç±»å‹ ========== """ 1. åå°„å‹XSS (Reflected XSS) - æ¶æ„ä»£ç é€šè¿‡URLå‚æ•°åå°„ - ä¾‹å¦‚: http://example.com/search?q=&lt;script>alert('XSS')&lt;/script> 2. å­˜å‚¨å‹XSS (Stored XSS) - æ¶æ„ä»£ç å­˜å‚¨åœ¨æœåŠ¡å™¨ï¼Œæ¯æ¬¡è®¿é—®æ—¶æ‰§è¡Œ - ä¾‹å¦‚: è¯„è®ºã€ç”¨æˆ·èµ„æ–™ç­‰å¯å­˜å‚¨çš„å†…å®¹ 3. DOMå‹XSS (DOM-based XSS) - æ¶æ„ä»£ç é€šè¿‡DOMæ“ä½œæ‰§è¡Œ - ä¾‹å¦‚: #&lt;img src=x onerror=alert('XSS')> """ # ========== XSSé˜²å¾¡ ========== import html import re from typing import Dict, Any class XSSProtection: """XSSé˜²æŠ¤""" @staticmethod def escape_html(text: str) -> str: """HTMLè½¬ä¹‰""" return html.escape(text, quote=True) @staticmethod def escape_js(text: str) -> str: """JavaScriptå­—ç¬¦ä¸²è½¬ä¹‰""" escape_map = { '\\': '\\\\', '"': '\\"', "'": "\\'", '\n': '\\n', '\r': '\\r', '\t': '\\t', '\b': '\\b', '\f': '\\f', } for char, escaped in escape_map.items(): text = text.replace(char, escaped) return text @staticmethod def sanitize_html(content: str, allowed_tags: list = None) -> str: """HTMLå‡€åŒ–ï¼Œåªå…è®¸å®‰å…¨çš„æ ‡ç­¾""" if allowed_tags is None: allowed_tags = ['p', 'br', 'strong', 'em', 'u', 'a'] import bleach return bleach.clean( content, tags=allowed_tags, attributes={ 'a': ['href', 'title'], '*': ['class'] }, strip=True ) @staticmethod def validate_url(url: str) -> bool: """éªŒè¯URLå®‰å…¨æ€§""" import urllib.parse try: parsed = urllib.parse.urlparse(url) # æ£€æŸ¥åè®® if parsed.scheme not in ['http', 'https']: return False # æ£€æŸ¥æ˜¯å¦ä¸ºJavaScriptä¼ªåè®® if parsed.scheme.lower() == 'javascript': return False return True except Exception: return False # Webæ¡†æ¶é›†æˆç¤ºä¾‹ from flask import Flask, request, render_template_string app = Flask(__name__) # ä¸å®‰å…¨çš„ç¤ºä¾‹ @app.route('/unsafe') def unsafe_search(): query = request.args.get('q', '') # å±é™©ï¼šç›´æ¥æ¸²æŸ“ç”¨æˆ·è¾“å…¥ return render_template_string(f'&lt;p>æœç´¢ç»“æœ: {query}&lt;/p>') # å®‰å…¨çš„ç¤ºä¾‹ @app.route('/safe') def safe_search(): query = request.args.get('q', '') # è½¬ä¹‰ç”¨æˆ·è¾“å…¥ safe_query = XSSProtection.escape_html(query) # æˆ–ä½¿ç”¨æ¨¡æ¿å¼•æ“çš„è‡ªåŠ¨è½¬ä¹‰ return render_template_string( '&lt;p>æœç´¢ç»“æœ: {{ query }}&lt;/p>', query=safe_query ) # Content Security Policy (CSP) @app.after_request def add_security_headers(response): """æ·»åŠ å®‰å…¨å¤´""" csp = ( "default-src 'self'; " "script-src 'self' 'unsafe-inline' https://cdn.example.com; " "style-src 'self' 'unsafe-inline'; " "img-src 'self' data: https:; " "font-src 'self' data:; " "connect-src 'self'; " "frame-ancestors 'none';" ) response.headers['Content-Security-Policy'] = csp response.headers['X-Content-Type-Options'] = 'nosniff' response.headers['X-Frame-Options'] = 'DENY' response.headers['X-XSS-Protection'] = '1; mode=block' return response # ========== è¾“å…¥éªŒè¯ ========== class InputValidator: """è¾“å…¥éªŒè¯å™¨""" @staticmethod def validate_username(username: str) -> bool: """éªŒè¯ç”¨æˆ·å""" # é•¿åº¦æ£€æŸ¥ if len(username) &lt; 3 or len(username) > 20: return False # å­—ç¬¦æ£€æŸ¥ï¼šåªå…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ import re pattern = r'^[a-zA-Z0-9_]+$' return bool(re.match(pattern, username)) @staticmethod def validate_email(email: str) -> bool: """éªŒè¯é‚®ç®±""" import re pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$' return bool(re.match(pattern, email)) @staticmethod def validate_phone(phone: str) -> bool: """éªŒè¯æ‰‹æœºå·""" import re pattern = r'^1[3-9]\d{9}$' return bool(re.match(pattern, phone)) 1.3 CSRFé˜²æŠ¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 # ========== CSRFæ”»å‡»åŸç† ========== """ CSRF (Cross-Site Request Forgery) è·¨ç«™è¯·æ±‚ä¼ªé€  æ”»å‡»åœºæ™¯ï¼š 1. ç”¨æˆ·ç™»å½•äº†é“¶è¡Œç½‘ç«™ bank.com 2. ç”¨æˆ·è®¿é—®äº†æ¶æ„ç½‘ç«™ evil.com 3. evil.com åŒ…å«æŒ‡å‘ bank.com çš„è¯·æ±‚ &lt;img src="http://bank.com/transfer?to=attacker&amp;amount=10000"> 4. æµè§ˆå™¨è‡ªåŠ¨æºå¸¦ bank.com çš„ cookie 5. é“¶è¡Œç½‘ç«™å¤„ç†è½¬è´¦è¯·æ±‚ é˜²å¾¡æªæ–½ï¼š 1. CSRF Token 2. SameSite Cookieå±æ€§ 3. éªŒè¯Referer/Originå¤´ 4. åŒé‡æäº¤Cookie """ # ========== CSRFé˜²æŠ¤å®ç° ========== import secrets from flask import Flask, request, session, render_template app = Flask(__name__) app.secret_key = secrets.token_hex(32) class CSRFProtection: """CSRFé˜²æŠ¤""" @staticmethod def generate_token() -> str: """ç”ŸæˆCSRF Token""" return secrets.token_hex(32) @staticmethod def validate_token(token: str, stored_token: str) -> bool: """éªŒè¯Token""" return secrets.compare_digest(token, stored_token) # åœ¨Flaskä¸­ä½¿ç”¨CSRFä¿æŠ¤ @app.before_request def csrf_protect(): """CSRFä¿æŠ¤ä¸­é—´ä»¶""" # è±å…å®‰å…¨çš„æ–¹æ³• if request.method in ['GET', 'HEAD', 'OPTIONS', 'TRACE']: return # æ£€æŸ¥CSRF Token token = request.headers.get('X-CSRF-Token') or request.form.get('csrf_token') if not token or token != session.get('csrf_token'): return 'Invalid CSRF token', 403 @app.route('/form') def show_form(): """æ˜¾ç¤ºè¡¨å•""" # ç”Ÿæˆå¹¶å­˜å‚¨CSRF Token csrf_token = CSRFProtection.generate_token() session['csrf_token'] = csrf_token return f''' &lt;form method="POST" action="/submit"> &lt;input type="hidden" name="csrf_token" value="{csrf_token}"> &lt;input type="text" name="username"> &lt;button type="submit">æäº¤&lt;/button> &lt;/form> ''' @app.route('/submit', methods=['POST']) def handle_submit(): """å¤„ç†è¡¨å•æäº¤""" # Tokenå·²åœ¨ä¸­é—´ä»¶éªŒè¯ username = request.form.get('username') # ä¸šåŠ¡é€»è¾‘ return f'Hello, {username}!' # ========== SameSite Cookie ========== @app.route('/login', methods=['POST']) def login(): """ç™»å½•""" # è®¾ç½®SameSiteå±æ€§ response = app.make_response('Login successful') # Strict: ä¸¥æ ¼æ¨¡å¼ï¼Œåªåœ¨åŒç«™ç‚¹è¯·æ±‚ä¸­å‘é€ response.set_cookie( 'session_id', value='session_data', httponly=True, secure=True, samesite='Strict' ) return response # ========== åŒé‡CookieéªŒè¯ ========== class DoubleSubmitCookie: """åŒé‡Cookie CSRFé˜²æŠ¤""" @staticmethod def generate_token(): """ç”ŸæˆTokenå¹¶è®¾ç½®åˆ°Cookie""" token = secrets.token_hex(32) @app.after_this_request def add_cookie(response): response.set_cookie( 'csrf_token', token, httponly=True, secure=True, samesite='Strict' ) return response return token @staticmethod def validate(request): """éªŒè¯Token""" cookie_token = request.cookies.get('csrf_token') request_token = request.form.get('csrf_token') or \ request.headers.get('X-CSRF-Token') return secrets.compare_digest(cookie_token, request_token) äºŒã€å…¶ä»–å¸¸è§Webæ¼æ´ 2.1 æ–‡ä»¶ä¸Šä¼ æ¼æ´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 # ========== æ–‡ä»¶ä¸Šä¼ å®‰å…¨ ========== import os import magic from werkzeug.utils import secure_filename from typing import Tuple class SecureFileUpload: """å®‰å…¨çš„æ–‡ä»¶ä¸Šä¼ """ # å…è®¸çš„æ–‡ä»¶ç±»å‹ ALLOWED_EXTENSIONS = { 'image': {'jpg', 'jpeg', 'png', 'gif', 'webp'}, 'document': {'pdf', 'doc', 'docx', 'txt'}, 'media': {'mp4', 'mp3', 'wav'} } # å…è®¸çš„MIMEç±»å‹ ALLOWED_MIME_TYPES = { 'image/jpeg', 'image/png', 'image/gif', 'image/webp', 'application/pdf', 'video/mp4', 'audio/mpeg' } # æœ€å¤§æ–‡ä»¶å¤§å° (10MB) MAX_FILE_SIZE = 10 * 1024 * 1024 def __init__(self, upload_dir: str): self.upload_dir = upload_dir os.makedirs(upload_dir, exist_ok=True) def validate_file(self, file) -> Tuple[bool, str]: """éªŒè¯æ–‡ä»¶""" # æ£€æŸ¥æ–‡ä»¶å filename = secure_filename(file.filename) if not filename: return False, "Invalid filename" # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else '' if ext not in set().union(*self.ALLOWED_EXTENSIONS.values()): return False, f"File extension '{ext}' not allowed" # æ£€æŸ¥æ–‡ä»¶å¤§å° file.seek(0, os.SEEK_END) file_size = file.tell() file.seek(0) if file_size > self.MAX_FILE_SIZE: return False, f"File size exceeds {self.MAX_FILE_SIZE} bytes" # æ£€æŸ¥MIMEç±»å‹ file_content = file.read() mime_type = magic.from_buffer(file_content, mime=True) if mime_type not in self.ALLOWED_MIME_TYPES: return False, f"MIME type '{mime_type}' not allowed" # éªŒè¯æ‰©å±•åå’ŒMIMEç±»å‹æ˜¯å¦åŒ¹é… ext_mime_map = { 'jpg': 'image/jpeg', 'jpeg': 'image/jpeg', 'png': 'image/png', 'gif': 'image/gif', 'pdf': 'application/pdf' } if ext in ext_mime_map and ext_mime_map[ext] != mime_type: return False, "File extension does not match content" return True, "Valid file" def save_file(self, file) -> Tuple[bool, str]: """ä¿å­˜æ–‡ä»¶""" # éªŒè¯æ–‡ä»¶ is_valid, message = self.validate_file(file) if not is_valid: return False, message # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å import uuid original_filename = secure_filename(file.filename) ext = original_filename.rsplit('.', 1)[1].lower() safe_filename = f"{uuid.uuid4().hex}.{ext}" # ä¿å­˜æ–‡ä»¶ filepath = os.path.join(self.upload_dir, safe_filename) file.seek(0) file.save(filepath) # è®¾ç½®æ–‡ä»¶æƒé™ os.chmod(filepath, 0o644) return True, safe_filename # Flaskè·¯ç”±ç¤ºä¾‹ from flask import Flask, request, jsonify app = Flask(__name__) uploader = SecureFileUpload('/var/uploads') @app.route('/upload', methods=['POST']) def upload_file(): """æ–‡ä»¶ä¸Šä¼ æ¥å£""" if 'file' not in request.files: return jsonify({'error': 'No file provided'}), 400 file = request.files['file'] if file.filename == '': return jsonify({'error': 'Empty filename'}), 400 # ä¿å­˜æ–‡ä»¶ success, message = uploader.save_file(file) if success: return jsonify({ 'success': True, 'filename': message }) else: return jsonify({ 'success': False, 'error': message }), 400 2.2 æƒé™ç»•è¿‡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 # ========== æƒé™æ§åˆ¶ ========== from functools import wraps from flask import session, request, jsonify class PermissionChecker: """æƒé™æ£€æŸ¥å™¨""" # æƒé™å®šä¹‰ PERMISSIONS = { 'user:read': 'æŸ¥çœ‹ç”¨æˆ·ä¿¡æ¯', 'user:write': 'ä¿®æ”¹ç”¨æˆ·ä¿¡æ¯', 'user:delete': 'åˆ é™¤ç”¨æˆ·', 'admin:panel': 'è®¿é—®ç®¡ç†é¢æ¿', 'system:config': 'ä¿®æ”¹ç³»ç»Ÿé…ç½®' } # è§’è‰²æƒé™æ˜ å°„ ROLE_PERMISSIONS = { 'guest': ['user:read'], 'user': ['user:read', 'user:write'], 'moderator': ['user:read', 'user:write', 'user:delete'], 'admin': ['admin:panel', 'system:config'], 'superadmin': ['*'] # æ‰€æœ‰æƒé™ } @classmethod def has_permission(cls, role: str, required_permission: str) -> bool: """æ£€æŸ¥è§’è‰²æ˜¯å¦æœ‰æƒé™""" if role not in cls.ROLE_PERMISSIONS: return False permissions = cls.ROLE_PERMISSIONS[role] # è¶…çº§ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™ if '*' in permissions: return True return required_permission in permissions # è£…é¥°å™¨å®ç°æƒé™æ§åˆ¶ def require_permission(permission: str): """æƒé™æ£€æŸ¥è£…é¥°å™¨""" def decorator(f): @wraps(f) def decorated_function(*args, **kwargs): # ä»sessionè·å–ç”¨æˆ·è§’è‰² role = session.get('role', 'guest') # æ£€æŸ¥æƒé™ if not PermissionChecker.has_permission(role, permission): return jsonify({ 'error': 'Permission denied', 'required': permission }), 403 return f(*args, **kwargs) return decorated_function return decorator # èµ„æºæ‰€æœ‰è€…æ£€æŸ¥ def require_owner_or_admin(model_name: str, id_param: str = 'id'): """èµ„æºæ‰€æœ‰è€…æˆ–ç®¡ç†å‘˜æƒé™æ£€æŸ¥""" def decorator(f): @wraps(f) def decorated_function(*args, **kwargs): user_id = session.get('user_id') role = session.get('role', 'guest') # ç®¡ç†å‘˜è·³è¿‡æ£€æŸ¥ if role == 'superadmin': return f(*args, **kwargs) # è·å–èµ„æºID resource_id = kwargs.get(id_param) or request.view_args.get(id_param) # æ£€æŸ¥èµ„æºæ‰€æœ‰è€… from database import get_db db = get_db() resource = db.query(model_name).get(resource_id) if resource and resource.owner_id == user_id: return f(*args, **kwargs) return jsonify({'error': 'Resource access denied'}), 403 return decorated_function return decorator # ä½¿ç”¨ç¤ºä¾‹ @app.route('/users/&lt;int:id>', methods=['GET']) @require_permission('user:read') def get_user(id): """è·å–ç”¨æˆ·ä¿¡æ¯""" return jsonify({'user': f'User {id}'}) @app.route('/users/&lt;int:id>', methods=['PUT']) @require_permission('user:write') @require_owner_or_admin('User', 'id') def update_user(id): """æ›´æ–°ç”¨æˆ·ä¿¡æ¯""" return jsonify({'success': True}) @app.route('/users/&lt;int:id>', methods=['DELETE']) @require_permission('user:delete') def delete_user(id): """åˆ é™¤ç”¨æˆ·""" return jsonify({'success': True}) # ========== æ°´å¹³è¶Šæƒé˜²æŠ¤ ========== class AccessControl: """è®¿é—®æ§åˆ¶""" @staticmethod def check_resource_access(user_id: int, resource_id: int, resource_type: str) -> bool: """æ£€æŸ¥èµ„æºè®¿é—®æƒé™""" from database import get_db db = get_db() # æ£€æŸ¥èµ„æºæ˜¯å¦å­˜åœ¨ resource = db.query(resource_type).get(resource_id) if not resource: return False # æ£€æŸ¥èµ„æºæ‰€æœ‰è€… if resource.owner_id == user_id: return True # æ£€æŸ¥å…±äº«æƒé™ if hasattr(resource, 'shared_with'): if user_id in resource.shared_with: return True return False @staticmethod def check_id_or_id_list(user_input, max_length: int = 1000) -> bool: """æ£€æŸ¥IDå‚æ•°ï¼Œé˜²æ­¢IDéå†æ”»å‡»""" # å•ä¸ªID if isinstance(user_input, int): return 0 &lt; user_input &lt; max_length # IDåˆ—è¡¨ if isinstance(user_input, list): if len(user_input) > 100: # é™åˆ¶åˆ—è¡¨é•¿åº¦ return False return all( isinstance(id, int) and 0 &lt; id &lt; max_length for id in user_input ) return False ä¸‰ã€æ¸—é€æµ‹è¯•ä¸æ¼æ´æŒ–æ˜ 3.1 ä¿¡æ¯æ”¶é›† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 # ========== ä¿¡æ¯æ”¶é›†å·¥å…· ========== import requests import dns.resolver import socket from typing import List, Dict, Set from urllib.parse import urlparse import re class InformationGathering: """ä¿¡æ¯æ”¶é›†""" def __init__(self, target: str): self.target = target self.results = { 'subdomains': set(), 'open_ports': [], 'technologies': [], 'sensitive_files': [], 'emails': set(), 'social_accounts': set() } def enumerate_subdomains(self) -> Set[str]: """å­åŸŸåæšä¸¾""" wordlist = [ 'www', 'mail', 'ftp', 'admin', 'blog', 'api', 'dev', 'staging', 'test', 'app', 'mobile' ] for subdomain in wordlist: domain = f"{subdomain}.{self.target}" try: # DNSæŸ¥è¯¢ dns.resolver.resolve(domain, 'A') self.results['subdomains'].add(domain) except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer): continue return self.results['subdomains'] def scan_ports(self, ports: List[int] = None) -> List[int]: """ç«¯å£æ‰«æ""" if ports is None: ports = [21, 22, 23, 25, 53, 80, 110, 443, 445, 3306, 3389, 8080] open_ports = [] for port in ports: sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.settimeout(1) try: sock.connect((self.target, port)) open_ports.append(port) except socket.error: pass finally: sock.close() self.results['open_ports'] = open_ports return open_ports def identify_technologies(self) -> List[str]: """æŠ€æœ¯æ ˆè¯†åˆ«""" url = f"http://{self.target}" try: response = requests.get(url, timeout=10) # æ£€æŸ¥å“åº”å¤´ headers = response.headers technologies = [] # Serverå¤´ if 'Server' in headers: technologies.append(f"Server: {headers['Server']}") # X-Powered-Byå¤´ if 'X-Powered-By' in headers: technologies.append(f"PoweredBy: {headers['X-Powered-By']}") # æ£€æŸ¥HTMLä¸­çš„æŠ€æœ¯ç‰¹å¾ content = response.text # WordPress if 'wp-content' in content: technologies.append("WordPress") # jQuery if 'jquery' in content.lower(): technologies.append("jQuery") # React if 'react' in content.lower(): technologies.append("React") # Vue if 'vue' in content.lower(): technologies.append("Vue") self.results['technologies'] = technologies except requests.RequestException: pass return self.results['technologies'] def find_sensitive_files(self) -> List[str]: """æ•æ„Ÿæ–‡ä»¶æ‰«æ""" sensitive_paths = [ '/robots.txt', '/.git/config', '/.env', '/wp-config.php', '/web.config', '/.htaccess', '/admin', '/phpmyadmin', '/backup.zip', '/database.sql' ] found_files = [] for path in sensitive_paths: url = f"http://{self.target}{path}" try: response = requests.get(url, timeout=5) if response.status_code in [200, 301, 302]: found_files.append(path) except requests.RequestException: continue self.results['sensitive_files'] = found_files return found_files def extract_emails(self) -> Set[str]: """æå–é‚®ç®±åœ°å€""" url = f"http://{self.target}" try: response = requests.get(url, timeout=10) content = response.text # é‚®ç®±æ­£åˆ™ email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b' emails = set(re.findall(email_pattern, content, re.IGNORECASE)) self.results['emails'] = emails except requests.RequestException: pass return self.results['emails'] def generate_report(self) -> Dict: """ç”ŸæˆæŠ¥å‘Š""" return { 'target': self.target, 'subdomains': list(self.results['subdomains']), 'open_ports': self.results['open_ports'], 'technologies': self.results['technologies'], 'sensitive_files': self.results['sensitive_files'], 'emails': list(self.results['emails']), 'social_accounts': list(self.results['social_accounts']) } 3.2 æ¼æ´æ‰«æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 # ========== æ¼æ´æ‰«æå™¨ ========== import requests from typing import Dict, List import re class VulnerabilityScanner: """æ¼æ´æ‰«æå™¨""" def __init__(self, target: str): self.target = target self.vulnerabilities = [] def scan_sql_injection(self, urls: List[str]) -> List[Dict]: """SQLæ³¨å…¥æ‰«æ""" payloads = [ "'", "' OR '1'='1", "' OR '1'='1'--", "admin'--", "1' ORDER BY 1--", "1' UNION SELECT NULL--" ] found = [] for url in urls: for payload in payloads: try: # æµ‹è¯•GETå‚æ•° if '?' in url: test_url = f"{url}{payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥SQLé”™è¯¯ç‰¹å¾ sql_errors = [ "You have an error in your SQL syntax", "Warning: mysql_fetch_array()", "ORA-01756: quoted string not properly terminated", "Unclosed quotation mark after the character string" ] if any(error in response.text for error in sql_errors): found.append({ 'type': 'SQL Injection', 'url': url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def scan_xss(self, urls: List[str]) -> List[Dict]: """XSSæ‰«æ""" payloads = [ "&lt;script>alert('XSS')&lt;/script>", "&lt;img src=x onerror=alert('XSS')>", "&lt;svg onload=alert('XSS')>", "javascript:alert('XSS')", "'>&lt;script>alert('XSS')&lt;/script>" ] found = [] for url in urls: for payload in payloads: try: # URLç¼–ç payload import urllib.parse encoded_payload = urllib.parse.quote(payload) test_url = f"{url}{encoded_payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥payloadæ˜¯å¦è¢«åå°„ if payload in response.text or encoded_payload in response.text: found.append({ 'type': 'XSS', 'url': url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def check_security_headers(self, url: str) -> Dict: """å®‰å…¨å¤´æ£€æŸ¥""" try: response = requests.get(url, timeout=10) headers = response.headers missing_headers = [] # æ£€æŸ¥å¿…è¦çš„å®‰å…¨å¤´ security_headers = { 'X-Frame-Options': 'é˜²æ­¢ç‚¹å‡»åŠ«æŒ', 'X-Content-Type-Options': 'é˜²æ­¢MIMEç±»å‹å—…æ¢', 'X-XSS-Protection': 'XSSè¿‡æ»¤', 'Content-Security-Policy': 'å†…å®¹å®‰å…¨ç­–ç•¥', 'Strict-Transport-Security': 'å¼ºåˆ¶HTTPS' } for header, description in security_headers.items(): if header not in headers: missing_headers.append({ 'header': header, 'description': description }) return { 'url': url, 'missing_headers': missing_headers, 'severity': 'Medium' if missing_headers else 'Low' } except requests.RequestException: return {'error': 'Failed to check headers'} def scan_directory_traversal(self, base_url: str) -> List[Dict]: """ç›®å½•éå†æ‰«æ""" payloads = [ '../../../etc/passwd', '..\\..\\..\\windows\\win.ini', '....//....//....//etc/passwd', '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd' ] found = [] # å¸¸è§çš„å¯æµ‹è¯•ç«¯ç‚¹ test_paths = [ '/download', '/file', '/image', '/document' ] for path in test_paths: for payload in payloads: try: test_url = f"{base_url}{path}?file={payload}" response = requests.get(test_url, timeout=5) # æ£€æŸ¥å“åº”å†…å®¹ if 'root:' in response.text or '[extensions]' in response.text: found.append({ 'type': 'Directory Traversal', 'url': test_url, 'payload': payload, 'severity': 'High' }) except requests.RequestException: continue self.vulnerabilities.extend(found) return found def generate_report(self) -> Dict: """ç”Ÿæˆæ‰«ææŠ¥å‘Š""" # ç»Ÿè®¡æ¼æ´ vuln_count = { 'Critical': 0, 'High': 0, 'Medium': 0, 'Low': 0 } for vuln in self.vulnerabilities: severity = vuln.get('severity', 'Low') vuln_count[severity] = vuln_count.get(severity, 0) + 1 return { 'target': self.target, 'total_vulnerabilities': len(self.vulnerabilities), 'by_severity': vuln_count, 'vulnerabilities': self.vulnerabilities } å››ã€å®‰å…¨ç¼–ç æœ€ä½³å®è·µ 4.1 å¯†ç å®‰å…¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 # ========== å¯†ç å“ˆå¸Œä¸éªŒè¯ ========== import bcrypt import secrets import hashlib from typing import Tuple class PasswordSecurity: """å¯†ç å®‰å…¨""" @staticmethod def hash_password(password: str) -> str: """å“ˆå¸Œå¯†ç """ # ç”Ÿæˆç›å€¼ salt = bcrypt.gensalt(rounds=12) # å“ˆå¸Œå¯†ç  hashed = bcrypt.hashpw(password.encode('utf-8'), salt) return hashed.decode('utf-8') @staticmethod def verify_password(password: str, hashed: str) -> bool: """éªŒè¯å¯†ç """ try: return bcrypt.checkpw( password.encode('utf-8'), hashed.encode('utf-8') ) except Exception: return False @staticmethod def validate_password_strength(password: str) -> Tuple[bool, list]: """éªŒè¯å¯†ç å¼ºåº¦""" errors = [] # é•¿åº¦æ£€æŸ¥ if len(password) &lt; 8: errors.append("å¯†ç é•¿åº¦è‡³å°‘8ä½") if len(password) > 128: errors.append("å¯†ç é•¿åº¦ä¸è¶…è¿‡128ä½") # å¤æ‚åº¦æ£€æŸ¥ has_upper = any(c.isupper() for c in password) has_lower = any(c.islower() for c in password) has_digit = any(c.isdigit() for c in password) has_special = any(c in "!@#$%^&*()_+-=[]{}|;:,.&lt;>?" for c in password) if not (has_upper and has_lower): errors.append("å¯†ç å¿…é¡»åŒ…å«å¤§å°å†™å­—æ¯") if not has_digit: errors.append("å¯†ç å¿…é¡»åŒ…å«æ•°å­—") if not has_special: errors.append("å¯†ç å¿…é¡»åŒ…å«ç‰¹æ®Šå­—ç¬¦") # å¸¸è§å¼±å¯†ç æ£€æŸ¥ common_passwords = [ 'password', '12345678', 'qwerty', 'abc123', 'admin', 'welcome', 'password123' ] if password.lower() in common_passwords: errors.append("å¯†ç è¿‡äºå¸¸è§") return len(errors) == 0, errors @staticmethod def generate_reset_token() -> str: """ç”Ÿæˆå¯†ç é‡ç½®ä»¤ç‰Œ""" return secrets.token_urlsafe(32) @staticmethod def hash_reset_token(token: str) -> str: """å“ˆå¸Œé‡ç½®ä»¤ç‰Œç”¨äºå­˜å‚¨""" return hashlib.sha256(token.encode()).hexdigest() # ========== å¯†ç ç­–ç•¥ ========== class PasswordPolicy: """å¯†ç ç­–ç•¥""" def __init__( self, min_length: int = 8, max_length: int = 128, require_uppercase: bool = True, require_lowercase: bool = True, require_digit: bool = True, require_special: bool = True, expire_days: int = 90, prevent_reuse: int = 5 ): self.min_length = min_length self.max_length = max_length self.require_uppercase = require_uppercase self.require_lowercase = require_lowercase self.require_digit = require_digit self.require_special = require_special self.expire_days = expire_days self.prevent_reuse = prevent_reuse def validate(self, password: str, user_history: list = None) -> Tuple[bool, list]: """éªŒè¯å¯†ç """ errors = [] # é•¿åº¦ if len(password) &lt; self.min_length: errors.append(f"å¯†ç é•¿åº¦è‡³å°‘{self.min_length}ä½") if len(password) > self.max_length: errors.append(f"å¯†ç é•¿åº¦ä¸è¶…è¿‡{self.max_length}ä½") # å¤æ‚åº¦ if self.require_uppercase and not any(c.isupper() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«å¤§å†™å­—æ¯") if self.require_lowercase and not any(c.islower() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«å°å†™å­—æ¯") if self.require_digit and not any(c.isdigit() for c in password): errors.append("å¯†ç å¿…é¡»åŒ…å«æ•°å­—") if self.require_special and not any( c in "!@#$%^&*()_+-=[]{}|;:,.&lt;>?" for c in password ): errors.append("å¯†ç å¿…é¡»åŒ…å«ç‰¹æ®Šå­—ç¬¦") # å†å²å¯†ç æ£€æŸ¥ if user_history and self.prevent_reuse: recent_passwords = user_history[:self.prevent_reuse] for old_hashed in recent_passwords: if PasswordSecurity.verify_password(password, old_hashed): errors.append(f"ä¸èƒ½ä½¿ç”¨æœ€è¿‘{self.prevent_reuse}æ¬¡ä½¿ç”¨è¿‡çš„å¯†ç ") break return len(errors) == 0, errors 4.2 æ•æ„Ÿæ•°æ®ä¿æŠ¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 # ========== æ•æ„Ÿæ•°æ®åŠ å¯† ========== from cryptography.fernet import Fernet from cryptography.hazmat.primitives import hashes from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2 import os import base64 from typing import Any import json class DataEncryption: """æ•°æ®åŠ å¯†""" @staticmethod def generate_key() -> bytes: """ç”ŸæˆåŠ å¯†å¯†é’¥""" return Fernet.generate_key() @staticmethod def encrypt_data(data: str, key: bytes) -> str: """åŠ å¯†æ•°æ®""" f = Fernet(key) encrypted = f.encrypt(data.encode()) return base64.b64encode(encrypted).decode() @staticmethod def decrypt_data(encrypted_data: str, key: bytes) -> str: """è§£å¯†æ•°æ®""" f = Fernet(key) encrypted = base64.b64decode(encrypted_data.encode()) decrypted = f.decrypt(encrypted) return decrypted.decode() @staticmethod def encrypt_dict(data: dict, key: bytes) -> str: """åŠ å¯†å­—å…¸æ•°æ®""" json_str = json.dumps(data) return DataEncryption.encrypt_data(json_str, key) @staticmethod def decrypt_dict(encrypted_data: str, key: bytes) -> dict: """è§£å¯†å­—å…¸æ•°æ®""" json_str = DataEncryption.decrypt_data(encrypted_data, key) return json.loads(json_str) class SecureStorage: """å®‰å…¨å­˜å‚¨""" def __init__(self, encryption_key: bytes): self.encryption_key = encryption_key def store_sensitive_data(self, key: str, data: Any): """å­˜å‚¨æ•æ„Ÿæ•°æ®""" # åºåˆ—åŒ–æ•°æ® if isinstance(data, dict): encrypted = DataEncryption.encrypt_dict(data, self.encryption_key) else: encrypted = DataEncryption.encrypt_data(str(data), self.encryption_key) # å­˜å‚¨åˆ°æ•°æ®åº“æˆ–æ–‡ä»¶ # è¿™é‡Œç®€åŒ–ä¸ºå†…å­˜å­˜å‚¨ self.storage[key] = encrypted def retrieve_sensitive_data(self, key: str) -> Any: """æ£€ç´¢æ•æ„Ÿæ•°æ®""" encrypted = self.storage.get(key) if not encrypted: return None # å°è¯•è§£å¯†ä¸ºå­—å…¸ try: return DataEncryption.decrypt_dict(encrypted, self.encryption_key) except: return DataEncryption.decrypt_data(encrypted, self.encryption_key) # ========== æ—¥å¿—è„±æ• ========== import re class LogSanitizer: """æ—¥å¿—è„±æ•""" # æ•æ„Ÿä¿¡æ¯æ­£åˆ™æ¨¡å¼ PATTERNS = { 'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 'phone': r'\b1[3-9]\d{9}\b', 'id_card': r'\b\d{17}[\dXx]\b', 'credit_card': r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b', 'password': r'(password|pwd|passwd)\s*[=:]\s*\S+', 'token': r'(token|api_key|secret)\s*[=:]\s*\S+', 'ip': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b' } @classmethod def sanitize(cls, log_message: str) -> str: """è„±æ•æ—¥å¿—""" sanitized = log_message for pattern_type, pattern in cls.PATTERNS.items(): if pattern_type == 'email': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[0]}***@{m.group(0).split('@')[1]}", sanitized ) elif pattern_type == 'phone': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[:3]}****{m.group(0)[7:]}", sanitized ) elif pattern_type == 'id_card': sanitized = re.sub( pattern, lambda m: f"{m.group(0)[:6]}********{m.group(0)[14:]}", sanitized ) elif pattern_type in ['password', 'token', 'credit_card']: sanitized = re.sub( pattern, lambda m: f"{m.group(0).split('=')[0].split(':')[0]}=***", sanitized ) elif pattern_type == 'ip': sanitized = re.sub( pattern, lambda m: f"{m.group(0).rsplit('.', 1)[0]}.*", sanitized ) return sanitized @classmethod def sanitize_dict(cls, data: dict) -> dict: """è„±æ•å­—å…¸æ•°æ®""" sanitized = {} for key, value in data.items(): if isinstance(value, str): sanitized[key] = cls.sanitize(value) elif isinstance(value, dict): sanitized[key] = cls.sanitize_dict(value) else: sanitized[key] = value return sanitized æ€»ç»“ ç½‘ç»œå®‰å…¨æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E5%AE%89%E5%85%A8/ class=category-link>å®‰å…¨</a><a href=/blog/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/ class=category-link>ç½‘ç»œå®‰å…¨</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to ç½‘ç»œå®‰å…¨ä¸æ¼æ´æ·±åº¦åˆ†æï¼šä»æ”»å‡»åˆ°é˜²å¾¡çš„å®Œæ•´æŒ‡å—" href=/blog/articles/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%B8%8E%E6%BC%8F%E6%B4%9E%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90%E4%BB%8E%E6%94%BB%E5%87%BB%E5%88%B0%E9%98%B2%E5%BE%A1%E7%9A%84%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DevOpsä¸CI/CDå®Œå…¨æŒ‡å—ï¼šæ„å»ºé«˜æ•ˆçš„è½¯ä»¶äº¤ä»˜æµæ°´çº¿</h2></header><div class=entry-content><p>å¼•è¨€ åœ¨å½“ä»Šå¿«é€Ÿè¿­ä»£çš„è½¯ä»¶å¼€å‘ç¯å¢ƒä¸­ï¼ŒDevOpså®è·µå’ŒCI/CDæµæ°´çº¿å·²æˆä¸ºå›¢é˜Ÿæé«˜äº¤ä»˜æ•ˆç‡ã€ä¿è¯è½¯ä»¶è´¨é‡çš„å…³é”®ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å¦‚ä½•æ„å»ºå®Œæ•´çš„DevOpsä½“ç³»ï¼Œä»ä»£ç æäº¤åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–å®è·µã€‚
ä¸€ã€DevOpsæ ¸å¿ƒç†å¿µ 1.1 DevOpsçš„CALMSæ¨¡å‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 # ========== DevOps CALMSæ¨¡å‹ ========== """ C - Culture (æ–‡åŒ–) â”œâ”€â”€ åä½œç²¾ç¥ â”œâ”€â”€ æŒç»­æ”¹è¿› â”œâ”€â”€ å®¹é”™å¿ƒæ€ â””â”€â”€ é€æ˜æ²Ÿé€š A - Automation (è‡ªåŠ¨åŒ–) â”œâ”€â”€ æ„å»ºè‡ªåŠ¨åŒ– â”œâ”€â”€ æµ‹è¯•è‡ªåŠ¨åŒ– â”œâ”€â”€ éƒ¨ç½²è‡ªåŠ¨åŒ– â””â”€â”€ ç›‘æ§è‡ªåŠ¨åŒ– L - Lean (ç²¾ç›Š) â”œâ”€â”€ æ¶ˆé™¤æµªè´¹ â”œâ”€â”€ æŒç»­äº¤ä»˜ â”œâ”€â”€ å¿«é€Ÿåé¦ˆ â””â”€â”€ ä»·å€¼æµä¼˜åŒ– M - Measurement (åº¦é‡) â”œâ”€â”€ å…³é”®æŒ‡æ ‡è¿½è¸ª â”œâ”€â”€ æ•°æ®é©±åŠ¨å†³ç­– â”œâ”€â”€ æŒç»­ç›‘æ§ â””â”€â”€ æ•ˆæœè¯„ä¼° S - Sharing (åˆ†äº«) â”œâ”€â”€ çŸ¥è¯†å…±äº« â”œâ”€â”€ æœ€ä½³å®è·µä¼ æ’­ â”œâ”€â”€ å·¥å…·å…±äº« â””â”€â”€ ç»éªŒæ€»ç»“ """ # DevOpsæˆç†Ÿåº¦è¯„ä¼°æ¨¡å‹ DEVOPS_MATURITY_LEVELS = { "Level 1 - åˆå§‹çº§": { "characteristics": [ "æ‰‹åŠ¨æ“ä½œä¸ºä¸»", "ç¼ºä¹æ ‡å‡†åŒ–æµç¨‹", "å¼€å‘å’Œè¿ç»´åˆ†ç¦»" ], "practices": [], "improvements": [ "å»ºç«‹åŸºç¡€è‡ªåŠ¨åŒ–æµç¨‹", "åˆ¶å®šæ ‡å‡†åŒ–è§„èŒƒ" ] }, "Level 2 - å¯é‡å¤çº§": { "characteristics": [ "æœ‰åŸºæœ¬çš„CIæµç¨‹", "ç¯å¢ƒé…ç½®åˆæ­¥æ ‡å‡†åŒ–", "æ–‡æ¡£åŒ–æµç¨‹" ], "practices": [ "ç‰ˆæœ¬æ§åˆ¶", "å•å…ƒæµ‹è¯•", "åŸºç¡€è‡ªåŠ¨åŒ–æ„å»º" ], "improvements": [ "æ‰©å±•è‡ªåŠ¨åŒ–èŒƒå›´", "å¢åŠ æµ‹è¯•è¦†ç›–ç‡" ] }, "Level 3 - å·²å®šä¹‰çº§": { "characteristics": [ "å®Œæ•´çš„CI/CDæµæ°´çº¿", "åŸºç¡€è®¾æ–½å³ä»£ç ", "è‡ªåŠ¨åŒ–æµ‹è¯•ä½“ç³»" ], "practices": [ "æŒç»­é›†æˆ", "æŒç»­éƒ¨ç½²", "è‡ªåŠ¨åŒ–æµ‹è¯•", "é…ç½®ç®¡ç†" ], "improvements": [ "ä¼˜åŒ–éƒ¨ç½²æµç¨‹", "å¢å¼ºç›‘æ§èƒ½åŠ›" ] }, "Level 4 - å¯ç®¡ç†çº§": { "characteristics": [ "å…¨é“¾è·¯è‡ªåŠ¨åŒ–", "å®Œå–„çš„ç›‘æ§ä½“ç³»", "å¿«é€Ÿæ•…éšœæ¢å¤" ], "practices": [ "è‡ªåŠ¨åŒ–è¿ç»´", "ç›‘æ§å‘Šè­¦", "æ•…éšœè‡ªæ„ˆ", "æ€§èƒ½ä¼˜åŒ–" ], "improvements": [ "æŒç»­ä¼˜åŒ–", "æˆæœ¬æ§åˆ¶" ] }, "Level 5 - ä¼˜åŒ–çº§": { "characteristics": [ "æ™ºèƒ½è¿ç»´", "é¢„æµ‹æ€§ç»´æŠ¤", "æŒç»­åˆ›æ–°" ], "practices": [ "AIè¾…åŠ©å†³ç­–", "æ··æ²Œå·¥ç¨‹", "è‡ªåŠ¨åŒ–ä¼˜åŒ–" ], "improvements": [ "æŒç»­æ¼”è¿›" ] } } 1.2 DevOpsæŒ‡æ ‡ä½“ç³» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 # ========== DORAæŒ‡æ ‡ ========== class DORAMetrics: """DORA (DevOps Research and Assessment) æ ¸å¿ƒæŒ‡æ ‡""" @staticmethod def deployment_frequency(deployments: int, days: int) -> float: """ éƒ¨ç½²é¢‘ç‡ - ç²¾è‹±çº§ï¼šæŒ‰éœ€éƒ¨ç½² (æ¯å¤©å¤šæ¬¡) - é«˜ç»©æ•ˆï¼šæ¯å‘¨1-6ä¸ªæœˆ - ä¸­ç­‰ç»©æ•ˆï¼šæ¯æœˆ1-6ä¸ªæœˆ - ä½ç»©æ•ˆï¼šå°‘äºæ¯6ä¸ªæœˆ1æ¬¡ """ return deployments / days @staticmethod def lead_time_for_changes(commit_time: str, deploy_time: str) -> float: """ å˜æ›´å‰ç½®æ—¶é—´ ä»ä»£ç æäº¤åˆ°æˆåŠŸéƒ¨ç½²çš„æ—¶é—´ - ç²¾è‹±çº§ï¼šå°äº1å°æ—¶ - é«˜ç»©æ•ˆï¼šå°äº1å¤© - ä¸­ç­‰ç»©æ•ˆï¼š1å‘¨-1ä¸ªæœˆ - ä½ç»©æ•ˆï¼šè¶…è¿‡1ä¸ªæœˆ """ from datetime import datetime commit = datetime.fromisoformat(commit_time) deploy = datetime.fromisoformat(deploy_time) return (deploy - commit).total_seconds() / 3600 # å°æ—¶ @staticmethod def time_to_restore_service(incident_time: str, restore_time: str) -> float: """ æœåŠ¡æ¢å¤æ—¶é—´ - ç²¾è‹±çº§ï¼šå°äº1å°æ—¶ - é«˜ç»©æ•ˆï¼šå°äº1å¤© - ä¸­ç­‰ç»©æ•ˆï¼š1å¤©-1å‘¨ - ä½ç»©æ•ˆï¼šè¶…è¿‡1å‘¨ """ from datetime import datetime incident = datetime.fromisoformat(incident_time) restore = datetime.fromisoformat(restore_time) return (restore - incident).total_seconds() / 3600 # å°æ—¶ @staticmethod def change_failure_rate(total_deployments: int, failed_deployments: int) -> float: """ å˜æ›´å¤±è´¥ç‡ - ç²¾è‹±çº§ï¼š0-15% - é«˜ç»©æ•ˆï¼š15-30% - ä¸­ç­‰ç»©æ•ˆï¼š30-60% - ä½ç»©æ•ˆï¼šè¶…è¿‡60% """ return (failed_deployments / total_deployments) * 100 @classmethod def evaluate_performance(cls, metrics: dict) -> str: """è¯„ä¼°å›¢é˜ŸDevOpsç»©æ•ˆç­‰çº§""" score = 0 if metrics['deployment_frequency'] >= 1: # æ¯å¤©è‡³å°‘1æ¬¡ score += 1 if metrics['lead_time'] &lt;= 1: # å°äº1å°æ—¶ score += 1 if metrics['restore_time'] &lt;= 1: # å°äº1å°æ—¶ score += 1 if metrics['failure_rate'] &lt;= 15: # å°äº15% score += 1 levels = { 4: "ç²¾è‹±çº§", 3: "é«˜ç»©æ•ˆ", 2: "ä¸­ç­‰ç»©æ•ˆ", 1: "ä½ç»©æ•ˆ", 0: "ä½ç»©æ•ˆ" } return levels[score] # ========== è‡ªå®šä¹‰DevOpsæŒ‡æ ‡ ========== class DevOpsMetricsCollector: """DevOpsæŒ‡æ ‡æ”¶é›†å™¨""" def __init__(self): self.metrics = { 'builds': [], 'deployments': [], 'incidents': [], 'tests': [] } def record_build(self, build_info: dict): """è®°å½•æ„å»ºä¿¡æ¯""" self.metrics['builds'].append({ 'timestamp': build_info['timestamp'], 'branch': build_info['branch'], 'commit': build_info['commit'], 'status': build_info['status'], 'duration': build_info['duration'], 'triggered_by': build_info['triggered_by'] }) def record_deployment(self, deployment_info: dict): """è®°å½•éƒ¨ç½²ä¿¡æ¯""" self.metrics['deployments'].append({ 'timestamp': deployment_info['timestamp'], 'environment': deployment_info['environment'], 'version': deployment_info['version'], 'status': deployment_info['status'], 'duration': deployment_info['duration'], 'deployed_by': deployment_info['deployed_by'] }) def record_incident(self, incident_info: dict): """è®°å½•æ•…éšœä¿¡æ¯""" self.metrics['incidents'].append({ 'detected_at': incident_info['detected_at'], 'resolved_at': incident_info.get('resolved_at'), 'severity': incident_info['severity'], 'affected_services': incident_info['affected_services'], 'root_cause': incident_info.get('root_cause') }) def calculate_metrics(self, days: int = 30) -> dict: """è®¡ç®—DevOpsæŒ‡æ ‡""" from datetime import datetime, timedelta cutoff_time = datetime.now() - timedelta(days=days) # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æ•°æ® recent_builds = [ b for b in self.metrics['builds'] if datetime.fromisoformat(b['timestamp']) > cutoff_time ] recent_deployments = [ d for d in self.metrics['deployments'] if datetime.fromisoformat(d['timestamp']) > cutoff_time ] recent_incidents = [ i for i in self.metrics['incidents'] if datetime.fromisoformat(i['detected_at']) > cutoff_time ] # è®¡ç®—æŒ‡æ ‡ total_builds = len(recent_builds) successful_builds = len([b for b in recent_builds if b['status'] == 'success']) build_success_rate = (successful_builds / total_builds * 100) if total_builds > 0 else 0 total_deployments = len(recent_deployments) successful_deployments = len([d for d in recent_deployments if d['status'] == 'success']) deployment_success_rate = (successful_deployments / total_deployments * 100) if total_deployments > 0 else 0 deployment_frequency = total_deployments / days total_incidents = len(recent_incidents) resolved_incidents = len([i for i in recent_incidents if i.get('resolved_at')]) avg_resolution_time = 0 if resolved_incidents > 0: resolution_times = [] for incident in recent_incidents: if incident.get('resolved_at'): detected = datetime.fromisoformat(incident['detected_at']) resolved = datetime.fromisoformat(incident['resolved_at']) resolution_times.append((resolved - detected).total_seconds() / 3600) avg_resolution_time = sum(resolution_times) / len(resolution_times) return { 'build_metrics': { 'total_builds': total_builds, 'success_rate': round(build_success_rate, 2), 'avg_duration': round( sum(b['duration'] for b in recent_builds) / total_builds if total_builds > 0 else 0, 2 ) }, 'deployment_metrics': { 'total_deployments': total_deployments, 'success_rate': round(deployment_success_rate, 2), 'frequency_per_day': round(deployment_frequency, 2) }, 'incident_metrics': { 'total_incidents': total_incidents, 'resolved_incidents': resolved_incidents, 'avg_resolution_time_hours': round(avg_resolution_time, 2) } } äºŒã€æŒç»­é›†æˆ(CI)å®è·µ 2.1 Gitå·¥ä½œæµ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 # ========== Gitå·¥ä½œæµæ¨¡å‹ ========== class GitWorkflow: """Gitå·¥ä½œæµç®¡ç†""" BRANCH_STRATEGIES = { "Git Flow": { "branches": { "main": "ç”Ÿäº§åˆ†æ”¯ï¼Œåªæ¥å—æ¥è‡ªreleaseçš„åˆå¹¶", "develop": "å¼€å‘ä¸»åˆ†æ”¯", "feature": "åŠŸèƒ½å¼€å‘åˆ†æ”¯ï¼Œä»developåˆ›å»º", "release": "å‘å¸ƒå‡†å¤‡åˆ†æ”¯ï¼Œä»developåˆ›å»º", "hotfix": "ç´§æ€¥ä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»º" }, "workflow": """ 1. ä»developåˆ›å»ºfeatureåˆ†æ”¯ 2. å®Œæˆå¼€å‘ååˆå¹¶å›develop 3. å‡†å¤‡å‘å¸ƒæ—¶åˆ›å»ºreleaseåˆ†æ”¯ 4. æµ‹è¯•é€šè¿‡ååˆå¹¶åˆ°mainå’Œdevelop 5. ç´§æ€¥ä¿®å¤ä»mainåˆ›å»ºhotfixåˆ†æ”¯ 6. ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop """ }, "GitHub Flow": { "branches": { "main": "å§‹ç»ˆå¯éƒ¨ç½²çš„ç”Ÿäº§åˆ†æ”¯", "feature": "åŠŸèƒ½åˆ†æ”¯ï¼Œä»mainåˆ›å»º" }, "workflow": """ 1. ä»mainåˆ›å»ºfeatureåˆ†æ”¯ 2. æäº¤å¹¶æ¨é€åˆ°è¿œç¨‹ 3. åˆ›å»ºPull Request 4. Code Reviewå’Œè®¨è®º 5. åˆå¹¶åˆ°main 6. ç«‹å³éƒ¨ç½² """ }, "GitLab Flow": { "branches": { "main": "ä¸»åˆ†æ”¯", "feature": "åŠŸèƒ½åˆ†æ”¯", "environment": "ç¯å¢ƒåˆ†æ”¯ï¼ˆstaging, productionï¼‰" }, "workflow": """ 1. ä»mainåˆ›å»ºfeatureåˆ†æ”¯ 2. å®Œæˆååˆå¹¶å›main 3. mainåˆ†æ”¯è§¦å‘CI/CD 4. é€šè¿‡æµ‹è¯•åéƒ¨ç½²åˆ°staging 5. äººå·¥éªŒè¯åéƒ¨ç½²åˆ°production """ }, "Trunk Based Development": { "branches": { "trunk/main": "ä¸»åˆ†æ”¯ï¼Œæ‰€æœ‰å¼€å‘åœ¨æ­¤è¿›è¡Œ" }, "workflow": """ 1. å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯æäº¤ 2. ä½¿ç”¨Feature Flagsæ§åˆ¶åŠŸèƒ½å‘å¸ƒ 3. é¢‘ç¹é›†æˆåˆ°ä¸»åˆ†æ”¯ 4. æŒç»­éƒ¨ç½² """ } } class BranchProtectionRules: """åˆ†æ”¯ä¿æŠ¤è§„åˆ™""" def __init__(self): self.rules = {} def add_protection(self, branch: str, rules: dict): """æ·»åŠ åˆ†æ”¯ä¿æŠ¤è§„åˆ™""" self.rules[branch] = { 'require_pull_request': rules.get('require_pull_request', True), 'require_approvals': rules.get('require_approvals', 1), 'dismiss_stale_reviews': rules.get('dismiss_stale_reviews', True), 'require_status_checks': rules.get('require_status_checks', True), 'required_status_checks': rules.get('required_status_checks', []), 'require_linear_history': rules.get('require_linear_history', True), 'allow_force_pushes': rules.get('allow_force_pushes', False), 'allow_deletions': rules.get('allow_deletions', False) } def check_protection(self, branch: str) -> dict: """æ£€æŸ¥åˆ†æ”¯ä¿æŠ¤çŠ¶æ€""" return self.rules.get(branch, {}) 2.2 CIæµæ°´çº¿é…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 # ========== Jenkins Pipeline ========== # Jenkinsfile pipeline { agent any tools { maven 'Maven 3.8' jdk 'JDK 11' } environment { APP_NAME = 'my-application' VERSION = "${env.BUILD_ID}" REGISTRY = 'registry.example.com' IMAGE_NAME = "${REGISTRY}/${APP_NAME}:${VERSION}" } stages { stage('Checkout') { steps { checkout scm } } stage('Setup') { steps { sh ''' echo "Setting up build environment..." python3 -m venv venv . venv/bin/activate pip install -r requirements.txt ''' } } stage('Code Quality') { parallel { stage('Lint') { steps { sh ''' . venv/bin/activate flake8 src/ --max-line-length=120 ''' } } stage('Security Scan') { steps { sh ''' . venv/bin/activate bandit -r src/ ''' } } } } stage('Unit Tests') { steps { sh ''' . venv/bin/activate pytest tests/unit/ --cov=src --cov-report=xml --cov-report=html ''' } post { always { junit 'test-results/*.xml' publishHTML([ allowMissing: false, alwaysLinkToLastBuild: true, keepAll: true, reportDir: 'htmlcov', reportFiles: 'index.html', reportName: 'Coverage Report' ]) } } } stage('Integration Tests') { steps { sh ''' docker-compose -f docker-compose.test.yml up -d sleep 10 . venv/bin/activate pytest tests/integration/ docker-compose -f docker-compose.test.yml down ''' } } stage('Build') { steps { sh ''' . venv/bin/activate python setup.py sdist bdist_wheel ''' } } stage('Docker Build') { steps { script { docker.build(image: IMAGE_NAME) } } } stage('Security Scan Image') { steps { sh ''' trivy image ${IMAGE_NAME} --severity HIGH,CRITICAL ''' } } stage('Push to Registry') { when { branch 'main' } steps { script { docker.withRegistry("https://${REGISTRY}", 'docker-registry-credentials') { docker.image(IMAGE_NAME).push() docker.image(IMAGE_NAME).push('latest') } } } } stage('Deploy to Staging') { when { branch 'main' } steps { sh ''' kubectl set image deployment/${APP_NAME} \ ${APP_NAME}=${IMAGE_NAME} \ --namespace=staging kubectl rollout status deployment/${APP_NAME} \ --namespace=staging ''' } } stage('Smoke Tests') { when { branch 'main' } steps { sh ''' . venv/bin/activate pytest tests/smoke/ --base-url=https://staging.example.com ''' } } stage('Deploy to Production') { when { branch 'main' approval { input 'Deploy to Production?' } } steps { sh ''' kubectl set image deployment/${APP_NAME} \ ${APP_NAME}=${IMAGE_NAME} \ --namespace=production kubectl rollout status deployment/${APP_NAME} \ --namespace=production ''' } } } post { success { echo "Pipeline succeeded!" cleanWs() } failure { echo "Pipeline failed!" mail to: 'team@example.com', subject: "Build Failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}", body: "Check console output at ${env.BUILD_URL}" } always { sh ''' docker system prune -f ''' } } } # ========== GitHub Actions Workflow ========== # .github/workflows/ci-cd.yml name: CI/CD Pipeline on: push: branches: [main, develop] pull_request: branches: [main, develop] env: REGISTRY: ghcr.io IMAGE_NAME: ${{ github.repository }} jobs: lint: name: Lint runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python uses: actions/setup-python@v4 with: python-version: '3.9' cache: 'pip' - name: Install dependencies run: | python -m pip install --upgrade pip pip install flake8 black isort - name: Run flake8 run: | flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics - name: Check code formatting run: | black --check src/ tests/ - name: Check import ordering run: | isort --check-only src/ tests/ test: name: Test runs-on: ubuntu-latest strategy: matrix: python-version: ['3.8', '3.9', '3.10', '3.11'] steps: - uses: actions/checkout@v3 - name: Set up Python ${{ matrix.python-version }} uses: actions/setup-python@v4 with: python-version: ${{ matrix.python-version }} cache: 'pip' - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt pip install -r requirements-dev.txt - name: Run tests run: | pytest tests/ --cov=src --cov-report=xml --cov-report=html - name: Upload coverage uses: codecov/codecov-action@v3 with: file: ./coverage.xml flags: unittests name: codecov-umbrella security: name: Security Scan runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Run Bandit run: | pip install bandit[toml] bandit -r src/ - name: Run Safety run: | pip install safety safety check --file requirements.txt - name: Run Trivy uses: aquasecurity/trivy-action@master with: scan-type: 'fs' scan-ref: '.' format: 'sarif' output: 'trivy-results.sarif' - name: Upload Trivy results uses: github/codeql-action/upload-sarif@v2 with: sarif_file: 'trivy-results.sarif' build: name: Build Docker Image runs-on: ubuntu-latest needs: [lint, test, security] if: github.event_name == 'push' && github.ref == 'refs/heads/main' permissions: contents: read packages: write steps: - uses: actions/checkout@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Log in to Container Registry uses: docker/login-action@v2 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} - name: Extract metadata id: meta uses: docker/metadata-action@v4 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} tags: | type=ref,event=branch type=semver,pattern={{version}} type=semver,pattern={{major}}.{{minor}} type=sha,prefix={{branch}}- - name: Build and push uses: docker/build-push-action@v4 with: context: . push: true tags: ${{ steps.meta.outputs.tags }} labels: ${{ steps.meta.outputs.labels }} cache-from: type=gha cache-to: type=gha,mode=max deploy: name: Deploy runs-on: ubuntu-latest needs: build if: github.event_name == 'push' && github.ref == 'refs/heads/main' environment: name: production url: https://example.com steps: - uses: actions/checkout@v3 - name: Configure AWS credentials uses: aws-actions/configure-aws-credentials@v2 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: us-east-1 - name: Update kubeconfig run: | aws eks update-kubeconfig --name production-cluster --region us-east-1 - name: Deploy to Kubernetes run: | kubectl set image deployment/app \ app=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \ --namespace=production - name: Verify deployment run: | kubectl rollout status deployment/app --namespace=production 2.3 æµ‹è¯•è‡ªåŠ¨åŒ–ç­–ç•¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 # ========== æµ‹è¯•é‡‘å­—å¡” ========== class TestAutomationStrategy: """æµ‹è¯•è‡ªåŠ¨åŒ–ç­–ç•¥""" TEST_PYRAMID = { "Unit Tests (70%)": { "scope": "å•ä¸ªå‡½æ•°/ç±»", "speed": "æ¯«ç§’çº§", "cost": "ä½", "isolation": "å®Œå…¨éš”ç¦»", "examples": [ "å‡½æ•°è¿”å›å€¼éªŒè¯", "è¾¹ç•Œæ¡ä»¶æµ‹è¯•", "å¼‚å¸¸å¤„ç†æµ‹è¯•" ] }, "Integration Tests (20%)": { "scope": "å¤šä¸ªç»„ä»¶åä½œ", "speed": "ç§’çº§", "cost": "ä¸­", "isolation": "éƒ¨åˆ†éš”ç¦»", "examples": [ "APIé›†æˆæµ‹è¯•", "æ•°æ®åº“é›†æˆæµ‹è¯•", "æœåŠ¡é—´é€šä¿¡æµ‹è¯•" ] }, "E2E Tests (10%)": { "scope": "å®Œæ•´ç”¨æˆ·æµç¨‹", "speed": "åˆ†é’Ÿçº§", "cost": "é«˜", "isolation": "æ— éš”ç¦»", "examples": [ "ç”¨æˆ·æ³¨å†Œæµç¨‹", "è´­ç‰©è½¦å®Œæ•´æµç¨‹", "æ”¯ä»˜å®Œæ•´æµç¨‹" ] } } class AutomatedTestSuite: """è‡ªåŠ¨åŒ–æµ‹è¯•å¥—ä»¶""" def __init__(self): self.unit_tests = [] self.integration_tests = [] self.e2e_tests = [] def add_unit_test(self, test_func): """æ·»åŠ å•å…ƒæµ‹è¯•""" self.unit_tests.append(test_func) def add_integration_test(self, test_func): """æ·»åŠ é›†æˆæµ‹è¯•""" self.integration_tests.append(test_func) def add_e2e_test(self, test_func): """æ·»åŠ E2Eæµ‹è¯•""" self.e2e_tests.append(test_func) def run_all_tests(self): """è¿è¡Œæ‰€æœ‰æµ‹è¯•""" results = { 'unit': self._run_tests(self.unit_tests), 'integration': self._run_tests(self.integration_tests), 'e2e': self._run_tests(self.e2e_tests) } return results def _run_tests(self, tests): """è¿è¡Œæµ‹è¯•""" passed = 0 failed = 0 for test in tests: try: test() passed += 1 except AssertionError as e: failed += 1 print(f"Test failed: {e}") return { 'total': len(tests), 'passed': passed, 'failed': failed } # ========== æµ‹è¯•é©±åŠ¨å¼€å‘(TDD)å·¥ä½œæµ ========== class TDDWorkflow: """TDDå·¥ä½œæµ""" @staticmethod def red_green_refactor(feature_name: str): """ Red-Green-Refactorå¾ªç¯ Red: ç¼–å†™å¤±è´¥çš„æµ‹è¯• Green: ç¼–å†™æœ€å°‘ä»£ç ä½¿æµ‹è¯•é€šè¿‡ Refactor: é‡æ„ä»£ç  """ print(f"\n=== TDD Workflow for {feature_name} ===") # Red: ç¼–å†™æµ‹è¯• print("\n[RED] Writing failing test...") test_code = f""" def test_{feature_name}(): result = {feature_name}() assert result is not None """ print(test_code) # Green: å®ç°åŠŸèƒ½ print("\n[GREEN] Implementing minimum code to pass...") impl_code = f""" def {feature_name}(): return True """ print(impl_code) # Refactor: é‡æ„ print("\n[REFACTOR] Improving code quality...") print("Optimizing implementation...") return True # ========== è¡Œä¸ºé©±åŠ¨å¼€å‘(BDD) ========== class BDDScenario: """BDDåœºæ™¯å®šä¹‰""" def __init__(self, name: str): self.name = name self.given_steps = [] self.when_steps = [] self.then_steps = [] def given(self, description: str, action=None): """Givenæ­¥éª¤""" self.given_steps.append({ 'description': description, 'action': action }) return self def when(self, description: str, action=None): """Whenæ­¥éª¤""" self.when_steps.append({ 'description': description, 'action': action }) return self def then(self, description: str, assertion=None): """Thenæ­¥éª¤""" self.then_steps.append({ 'description': description, 'assertion': assertion }) return self def execute(self): """æ‰§è¡Œåœºæ™¯""" print(f"\nScenario: {self.name}") # æ‰§è¡ŒGivenæ­¥éª¤ print("\nGiven:") context = {} for step in self.given_steps: print(f" {step['description']}") if step['action']: context.update(step['action'](context) or {}) # æ‰§è¡ŒWhenæ­¥éª¤ print("\nWhen:") for step in self.when_steps: print(f" {step['description']}") if step['action']: context.update(step['action'](context) or {}) # æ‰§è¡ŒThenæ­¥éª¤ print("\nThen:") for step in self.then_steps: print(f" {step['description']}") if step['assertion']: step['assertion'](context) return context # ä½¿ç”¨ç¤ºä¾‹ def user_login_scenario(): """ç”¨æˆ·ç™»å½•åœºæ™¯""" scenario = BDDScenario("User successfully logs in") scenario.given("a registered user with email 'user@example.com' and password 'password123'") .when("the user submits valid credentials") .then("the user should be authenticated") .then("the user should receive an authentication token") # å®é™…æ‰§è¡Œæ—¶ä¼šå®ç°å…·ä½“çš„actionå’Œassertion return scenario ä¸‰ã€æŒç»­éƒ¨ç½²(CD)å®è·µ 3.1 éƒ¨ç½²ç­–ç•¥ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 # ========== éƒ¨ç½²ç­–ç•¥ ========== class DeploymentStrategy: """éƒ¨ç½²ç­–ç•¥""" @staticmethod def rolling_update(deployment_config: dict): """ æ»šåŠ¨æ›´æ–° é€æ­¥æ›¿æ¢æ—§å®ä¾‹ï¼Œç¡®ä¿æœåŠ¡å§‹ç»ˆå¯ç”¨ """ total_replicas = deployment_config['replicas'] max_unavailable = deployment_config.get('max_unavailable', 1) max_surge = deployment_config.get('max_surge', 1) print(f"Starting rolling update...") print(f"Total replicas: {total_replicas}") print(f"Max unavailable: {max_unavailable}") print(f"Max surge: {max_surge}") for i in range(total_replicas): print(f"Updating replica {i+1}/{total_replicas}...") # éƒ¨ç½²æ–°å®ä¾‹ # ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡ # ç»ˆæ­¢æ—§å®ä¾‹ print("Rolling update completed!") @staticmethod def blue_green_deployment(deployment_config: dict): """ è“ç»¿éƒ¨ç½² å¹¶è¡Œç»´æŠ¤ä¸¤å¥—ç¯å¢ƒï¼Œé€šè¿‡åˆ‡æ¢æµé‡å®ç°é›¶åœæœºéƒ¨ç½² """ print("Starting blue-green deployment...") # å½“å‰ç¯å¢ƒ current_env = deployment_config['current_environment'] # 'blue' or 'green' # ç›®æ ‡ç¯å¢ƒ target_env = 'green' if current_env == 'blue' else 'blue' print(f"Current environment: {current_env}") print(f"Target environment: {target_env}") # 1. åœ¨ç›®æ ‡ç¯å¢ƒéƒ¨ç½²æ–°ç‰ˆæœ¬ print(f"\n1. Deploying new version to {target_env} environment...") # éƒ¨ç½²åˆ°ç›®æ ‡ç¯å¢ƒ # 2. ç­‰å¾…ç›®æ ‡ç¯å¢ƒå¥åº·æ£€æŸ¥ print(f"\n2. Waiting for {target_env} to be healthy...") # å¥åº·æ£€æŸ¥ # 3. åˆ‡æ¢æµé‡ print(f"\n3. Switching traffic from {current_env} to {target_env}...") # åˆ‡æ¢è´Ÿè½½å‡è¡¡å™¨ # 4. éªŒè¯æ–°ç‰ˆæœ¬ print(f"\n4. Validating {target_env}...") # è¿è¡ŒçƒŸé›¾æµ‹è¯• # 5. ä¿ç•™æ—§ç¯å¢ƒï¼ˆå¯é€‰å›æ»šï¼‰ print(f"\n5. Keeping {current_env} as rollback option...") print("Blue-green deployment completed!") @staticmethod def canary_deployment(deployment_config: dict): """ é‡‘ä¸é›€éƒ¨ç½² é€æ­¥å°†æµé‡å¼•å¯¼åˆ°æ–°ç‰ˆæœ¬ï¼Œç›‘æ§é—®é¢˜å¹¶å¿«é€Ÿå›æ»š """ print("Starting canary deployment...") canary_steps = deployment_config.get('canary_steps', [ {'percentage': 5, 'duration': 300}, # 5% æµé‡ï¼Œ5åˆ†é’Ÿ {'percentage': 25, 'duration': 600}, # 25% æµé‡ï¼Œ10åˆ†é’Ÿ {'percentage': 50, 'duration': 600}, # 50% æµé‡ï¼Œ10åˆ†é’Ÿ {'percentage': 100, 'duration': 0} # 100% æµé‡ ]) for step in canary_steps: percentage = step['percentage'] duration = step['duration'] print(f"\nRouting {percentage}% of traffic to canary...") # è°ƒæ•´æµé‡åˆ†é… # ç›‘æ§å…³é”®æŒ‡æ ‡ # å¦‚æœæ£€æµ‹åˆ°é—®é¢˜ï¼Œç«‹å³å›æ»š if duration > 0: print(f"Monitoring for {duration} seconds...") # ç­‰å¾…å¹¶ç›‘æ§ print("\nAll traffic routed to new version!") print("Canary deployment completed!") @staticmethod def a_b_testing_deployment(deployment_config: dict): """ A/Bæµ‹è¯•éƒ¨ç½² åŒæ—¶è¿è¡Œå¤šä¸ªç‰ˆæœ¬ï¼ŒæŒ‰ç‰¹å®šè§„åˆ™åˆ†é…æµé‡ """ print("Starting A/B testing deployment...") variants = deployment_config['variants'] # [{'name': 'A', 'percentage': 50}, ...] total_percentage = sum(v['percentage'] for v in variants) if total_percentage != 100: raise ValueError(f"Total percentage must be 100%, got {total_percentage}%") print("Traffic allocation:") for variant in variants: print(f" {variant['name']}: {variant['percentage']}%") # é…ç½®æµé‡åˆ†é…è§„åˆ™ # è®¾ç½®æŒ‡æ ‡æ”¶é›† # é…ç½®è‡ªåŠ¨å›æ»šè§„åˆ™ print("A/B testing deployment completed!") # ========== éƒ¨ç½²å›æ»š ========== class DeploymentRollback: """éƒ¨ç½²å›æ»š""" def __init__(self, deployment_manager): self.deployment_manager = deployment_manager self.rollback_history = [] def execute_rollback(self, target_version: str, reason: str): """æ‰§è¡Œå›æ»š""" print(f"\nInitiating rollback to version {target_version}") print(f"Reason: {reason}") # 1. è®°å½•å›æ»š rollback_record = { 'timestamp': datetime.now().isoformat(), 'from_version': self.deployment_manager.get_current_version(), 'to_version': target_version, 'reason': reason } self.rollback_history.append(rollback_record) # 2. æ‰§è¡Œå›æ»š try: # åœæ­¢å½“å‰ç‰ˆæœ¬ print("Stopping current version...") # éƒ¨ç½²ç›®æ ‡ç‰ˆæœ¬ print(f"Deploying version {target_version}...") # éªŒè¯å›æ»š print("Verifying rollback...") print(f"Rollback to version {target_version} completed successfully!") except Exception as e: print(f"Rollback failed: {e}") raise def get_rollback_history(self): """è·å–å›æ»šå†å²""" return self.rollback_history 3.2 GitOpså®è·µ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 # ========== GitOps with ArgoCD ========== # åº”ç”¨éƒ¨ç½²æ¸…å• # apps/application.yaml apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: my-application namespace: argocd spec: project: default source: repoURL: https://github.com/org/infrastructure.git targetRevision: main path: apps/my-application helm: valueFiles: - values-prod.yaml destination: server: https://kubernetes.default.svc namespace: production syncPolicy: automated: prune: true selfHeal: true syncOptions: - CreateNamespace=true # Kuberneteséƒ¨ç½²æ¸…å• # apps/my-application/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: my-application labels: app: my-application spec: replicas: 3 selector: matchLabels: app: my-application template: metadata: labels: app: my-application spec: containers: - name: app image: registry.example.com/my-application:{{ .Values.image.tag }} ports: - containerPort: 8080 resources: requests: memory: "128Mi" cpu: "100m" limits: memory: "256Mi" cpu: "200m" livenessProbe: httpGet: path: /health port: 8080 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: /ready port: 8080 initialDelaySeconds: 5 periodSeconds: 5 --- apiVersion: v1 kind: Service metadata: name: my-application spec: selector: app: my-application ports: - port: 80 targetPort: 8080 type: ClusterIP --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: my-application annotations: cert-manager.io/cluster-issuer: letsencrypt-prod nginx.ingress.kubernetes.io/ssl-redirect: "true" spec: ingressClassName: nginx tls: - hosts: - app.example.com secretName: my-application-tls rules: - host: app.example.com http: paths: - path: / pathType: Prefix backend: service: name: my-application port: number: 80 # Helm Values # apps/my-application/values-prod.yaml image: tag: "1.2.3" replicas: 3 resources: requests: memory: "256Mi" cpu: "200m" limits: memory: "512Mi" cpu: "500m" autoscaling: enabled: true minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 70 targetMemoryUtilizationPercentage: 80 database: host: postgres-production.example.com port: 5432 name: app_production sslMode: require å››ã€åŸºç¡€è®¾æ–½å³ä»£ç (IaC) 4.1 Terraformé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 # ========== Terraformé…ç½®ç¤ºä¾‹ ========== # ä¸»é…ç½®æ–‡ä»¶ # main.tf terraform { required_version = ">= 1.0" required_providers { aws = { source = "hashicorp/aws" version = "~> 5.0" } } backend "s3" { bucket = "terraform-state-prod" key = "production/terraform.tfstate" region = "us-east-1" encrypt = true dynamodb_table = "terraform-locks" } } provider "aws" { region = var.aws_region default_tags { tags = { Environment = var.environment Project = var.project_name ManagedBy = "Terraform" } } } # VPCé…ç½® # modules/vpc/main.tf resource "aws_vpc" "main" { cidr_block = var.vpc_cidr enable_dns_hostnames = true enable_dns_support = true tags = { Name = "${var.project_name}-vpc" } } resource "aws_internet_gateway" "main" { vpc_id = aws_vpc.main.id tags = { Name = "${var.project_name}-igw" } } resource "aws_subnet" "public" { count = length(var.availability_zones) vpc_id = aws_vpc.main.id cidr_block = cidrsubnet(var.vpc_cidr, 8, count.index) availability_zone = var.availability_zones[count.index] map_public_ip_on_launch = true tags = { Name = "${var.project_name}-public-${count.index}" Type = "Public" } } resource "aws_subnet" "private" { count = length(var.availability_zones) vpc_id = aws_vpc.main.id cidr_block = cidrsubnet(var.vpc_cidr, 8, count.index + length(var.availability_zones)) availability_zone = var.availability_zones[count.index] tags = { Name = "${var.project_name}-private-${count.index}" Type = "Private" } } resource "aws_eip" "nat" { count = length(var.availability_zones) domain = "vpc" tags = { Name = "${var.project_name}-nat-${count.index}" } depends_on = [aws_internet_gateway.main] } resource "aws_nat_gateway" "main" { count = length(var.availability_zones) allocation_id = aws_eip.nat[count.index].id subnet_id = aws_subnet.public[count.index].id tags = { Name = "${var.project_name}-nat-${count.index}" } depends_on = [aws_internet_gateway.main] } # EKSé›†ç¾¤é…ç½® # modules/eks/main.tf resource "aws_eks_cluster" "main" { name = "${var.project_name}-cluster" role_arn = aws_iam_role.cluster.arn version = var.kubernetes_version vpc_config { subnet_ids = concat( aws_subnet.private[*].id, aws_subnet.public[*].id ) endpoint_private_access = true endpoint_public_access = true public_access_cidrs = var.allowed_public_access_cidrs } enabled_cluster_log_types = var.cluster_log_types depends_on = [ aws_iam_role_policy_attachment.cluster_amazon_eks_cluster_policy, aws_iam_role_policy_attachment.cluster_amazon_eks_vpc_resource_controller, ] tags = { Name = "${var.project_name}-eks" } } resource "aws_eks_node_group" "main" { cluster_name = aws_eks_cluster.main.name node_group_name = "${var.project_name}-node-group" node_role_arn = aws_iam_role.node.arn subnet_ids = aws_subnet.private[*].id scaling_config { desired_size = var.node_group_desired_size max_size = var.node_group_max_size min_size = var.node_group_min_size } instance_types = var.node_instance_types remote_access { ec2_ssh_key = var.ssh_key_name source_security_group_ids = [aws_security_group.node.id] } labels = { Environment = var.environment Project = var.project_name } tags = { Name = "${var.project_name}-node" } depends_on = [ aws_iam_role_policy_attachment.node_amazon_eks_worker_node_policy, aws_iam_role_policy_attachment.node_amazon_eks_cni_policy, aws_iam_role_policy_attachment.node_amazon_ec2_container_registry_read_only, ] } # å˜é‡å®šä¹‰ # variables.tf variable "aws_region" { description = "AWS region" type = string default = "us-east-1" } variable "environment" { description = "Environment name" type = string validation { condition = contains(["development", "staging", "production"], var.environment) error_message = "Environment must be development, staging, or production." } } variable "project_name" { description = "Project name" type = string } variable "vpc_cidr" { description = "CIDR block for VPC" type = string default = "10.0.0.0/16" } variable "availability_zones" { description = "List of availability zones" type = list(string) default = ["us-east-1a", "us-east-1b", "us-east-1c"] } # è¾“å‡ºå®šä¹‰ # outputs.tf output "cluster_id" { description = "EKS cluster ID" value = aws_eks_cluster.main.id } output "cluster_endpoint" { description = "EKS cluster endpoint" value = aws_eks_cluster.main.endpoint } output "cluster_security_group_id" { description = "Security group ID attached to the EKS cluster" value = aws_eks_cluster.main.vpc_config[0].cluster_security_group_id } output "cluster_certificate_authority_data" { description = "Base64 encoded certificate data required to communicate with the cluster" value = aws_eks_cluster.main.certificate_authority[0].data } 4.2 Dockerä¸Kubernetesé…ç½® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 # ========== Dockeré…ç½® ========== # Dockerfile FROM python:3.11-slim # è®¾ç½®å·¥ä½œç›®å½• WORKDIR /app # è®¾ç½®ç¯å¢ƒå˜é‡ ENV PYTHONDONTWRITEBYTECODE=1 \ PYTHONUNBUFFERED=1 \ PIP_NO_CACHE_DIR=1 \ PIP_DISABLE_PIP_VERSION_CHECK=1 # å®‰è£…ç³»ç»Ÿä¾èµ– RUN apt-get update && \ apt-get install -y --no-install-recommends \ gcc \ libc6-dev \ && rm -rf /var/lib/apt/lists/* # å¤åˆ¶ä¾èµ–æ–‡ä»¶ COPY requirements.txt . # å®‰è£…Pythonä¾èµ– RUN pip install --no-cache-dir -r requirements.txt # å¤åˆ¶åº”ç”¨ä»£ç  COPY src/ ./src/ COPY config/ ./config/ # åˆ›å»ºérootç”¨æˆ· RUN useradd -m -u 1000 appuser && \ chown -R appuser:appuser /app USER appuser # æš´éœ²ç«¯å£ EXPOSE 8080 # å¥åº·æ£€æŸ¥ HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \ CMD curl -f http://localhost:8080/health || exit 1 # å¯åŠ¨åº”ç”¨ CMD ["gunicorn", "src.app:app", "--bind", "0.0.0.0:8080", "--workers", "4"] # docker-compose.yml version: '3.8' services: app: build: context: . dockerfile: Dockerfile image: my-application:latest ports: - "8080:8080" environment: - DATABASE_URL=postgresql://user:password@db:5432/app - REDIS_URL=redis://redis:6379 depends_on: db: condition: service_healthy redis: condition: service_started healthcheck: test: ["CMD", "curl", "-f", "http://localhost:8080/health"] interval: 30s timeout: 10s retries: 3 start_period: 40s restart: unless-stopped db: image: postgres:15-alpine environment: - POSTGRES_DB=app - POSTGRES_USER=user - POSTGRES_PASSWORD=password volumes: - postgres_data:/var/lib/postgresql/data healthcheck: test: ["CMD-SHELL", "pg_isready -U user -d app"] interval: 10s timeout: 5s retries: 5 restart: unless-stopped redis: image: redis:7-alpine volumes: - redis_data:/data restart: unless-stopped nginx: image: nginx:alpine ports: - "80:80" - "443:443" volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ./nginx/ssl:/etc/nginx/ssl:ro depends_on: - app restart: unless-stopped volumes: postgres_data: redis_data: # ========== Kubernetesé…ç½® ========== # deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: my-application labels: app: my-application spec: replicas: 3 strategy: type: RollingUpdate rollingUpdate: maxSurge: 1 maxUnavailable: 0 selector: matchLabels: app: my-application template: metadata: labels: app: my-application spec: serviceAccountName: my-application securityContext: runAsNonRoot: true runAsUser: 1000 fsGroup: 1000 containers: - name: app image: registry.example.com/my-application:1.0.0 ports: - name: http containerPort: 8080 protocol: TCP env: - name: DATABASE_URL valueFrom: secretKeyRef: name: app-secrets key: database-url - name: REDIS_URL valueFrom: configMapKeyRef: name: app-config key: redis-url resources: requests: memory: "128Mi" cpu: "100m" limits: memory: "256Mi" cpu: "200m" livenessProbe: httpGet: path: /health port: http initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 failureThreshold: 3 readinessProbe: httpGet: path: /ready port: http initialDelaySeconds: 5 periodSeconds: 5 timeoutSeconds: 3 failureThreshold: 3 lifecycle: preStop: exec: command: - sh - -c - sleep 15 terminationGracePeriodSeconds: 30 # service.yaml apiVersion: v1 kind: Service metadata: name: my-application spec: type: ClusterIP selector: app: my-application ports: - name: http port: 80 targetPort: http protocol: TCP # hpa.yaml apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: my-application spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: my-application minReplicas: 3 maxReplicas: 10 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 70 - type: Resource resource: name: memory target: type: Utilization averageUtilization: 80 behavior: scaleDown: stabilizationWindowSeconds: 300 policies: - type: Percent value: 50 periodSeconds: 60 scaleUp: stabilizationWindowSeconds: 0 policies: - type: Percent value: 100 periodSeconds: 30 - type: Pods value: 2 periodSeconds: 60 selectPolicy: Max æ€»ç»“ æ„å»ºé«˜æ•ˆçš„DevOpså’ŒCI/CDæµæ°´çº¿éœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/devops/ class=category-link>DevOps</a><a href=/blog/categories/ci/cd/ class=category-link>CI/CD</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to DevOpsä¸CI/CDå®Œå…¨æŒ‡å—ï¼šæ„å»ºé«˜æ•ˆçš„è½¯ä»¶äº¤ä»˜æµæ°´çº¿" href=/blog/articles/devops%E4%B8%8Eci/cd%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E6%9E%84%E5%BB%BA%E9%AB%98%E6%95%88%E7%9A%84%E8%BD%AF%E4%BB%B6%E4%BA%A4%E4%BB%98%E6%B5%81%E6%B0%B4%E7%BA%BF/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>AIä¸æœºå™¨å­¦ä¹ å·¥ç¨‹åŒ–å®è·µï¼šä»æ¨¡å‹åˆ°ç”Ÿäº§ç³»ç»Ÿçš„å®Œæ•´æŒ‡å—</h2></header><div class=entry-content><p>å¼•è¨€ å°†AI/MLæ¨¡å‹ä»ç ”ç©¶ç¯å¢ƒæ¨å‘ç”Ÿäº§ç¯å¢ƒæ˜¯ä¸€é¡¹å¤æ‚çš„å·¥ç¨‹æŒ‘æˆ˜ã€‚é™¤äº†æ¨¡å‹æœ¬èº«çš„å‡†ç¡®æ€§ï¼Œè¿˜éœ€è¦è€ƒè™‘å¯æ‰©å±•æ€§ã€å¯é æ€§ã€å¯ç»´æŠ¤æ€§ç­‰å¤šä¸ªæ–¹é¢ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨AI/MLç³»ç»Ÿçš„å·¥ç¨‹åŒ–å®è·µï¼Œå¸®åŠ©å›¢é˜Ÿæ„å»ºç¨³å®šé«˜æ•ˆçš„ç”Ÿäº§çº§AIç³»ç»Ÿã€‚
ä¸€ã€MLOpsæ¦‚è¿° 1.1 MLOpsçš„æ ¸å¿ƒç»„ä»¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # ========== MLOpsæ¶æ„æ¦‚è§ˆ ========== """ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ æ•°æ®å±‚ â”‚ â”‚ - åŸå§‹æ•°æ® â”‚ â”‚ - ç‰¹å¾å­˜å‚¨ â”‚ â”‚ - è®­ç»ƒæ•°æ® â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ è®­ç»ƒå±‚ â”‚ â”‚ - ç‰¹å¾å·¥ç¨‹ â”‚ â”‚ - æ¨¡å‹è®­ç»ƒ â”‚ â”‚ - è¶…å‚æ•°è°ƒä¼˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ è¯„ä¼°å±‚ â”‚ â”‚ - æ¨¡å‹è¯„ä¼° â”‚ â”‚ - A/Bæµ‹è¯• â”‚ â”‚ - æ¨¡å‹éªŒè¯ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ éƒ¨ç½²å±‚ â”‚ â”‚ - æ¨¡å‹æœåŠ¡ â”‚ â”‚ - æ‰¹é‡æ¨ç† â”‚ â”‚ - è¾¹ç¼˜éƒ¨ç½² â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ ç›‘æ§å±‚ â”‚ â”‚ - æ€§èƒ½ç›‘æ§ â”‚ â”‚ - æ•°æ®æ¼‚ç§»æ£€æµ‹ â”‚ â”‚ - å‘Šè­¦ç³»ç»Ÿ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ """ # MLOpså„é˜¶æ®µçš„å…³é”®ä»»åŠ¡ MLOPS_PIPELINE = { "data": { "ingestion": "æ•°æ®é‡‡é›†ä¸æ¸…æ´—", "validation": "æ•°æ®è´¨é‡æ£€æŸ¥", "feature_engineering": "ç‰¹å¾æå–ä¸è½¬æ¢", "feature_store": "ç‰¹å¾å­˜å‚¨ä¸ç‰ˆæœ¬ç®¡ç†" }, "training": { "experiment_tracking": "å®éªŒè¿½è¸ª", "hyperparameter_tuning": "è¶…å‚æ•°ä¼˜åŒ–", "model_training": "æ¨¡å‹è®­ç»ƒ", "model_evaluation": "æ¨¡å‹è¯„ä¼°" }, "deployment": { "model_serving": "æ¨¡å‹æœåŠ¡åŒ–", "canary_deployment": "é‡‘ä¸é›€éƒ¨ç½²", "model_versioning": "æ¨¡å‹ç‰ˆæœ¬ç®¡ç†", "rollback": "å›æ»šæœºåˆ¶" }, "monitoring": { "performance_monitoring": "æ€§èƒ½ç›‘æ§", "data_drift_detection": "æ•°æ®æ¼‚ç§»æ£€æµ‹", "model_explainability": "æ¨¡å‹å¯è§£é‡Šæ€§", "alerting": "å‘Šè­¦ç³»ç»Ÿ" } } 1.2 å®éªŒç®¡ç†ä¸è¿½è¸ª 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 # ========== å®éªŒè¿½è¸ªç³»ç»Ÿ ========== import mlflow import mlflow.sklearn from datetime import datetime from typing import Any, Dict, Optional class ExperimentTracker: """å®éªŒè¿½è¸ªå™¨""" def __init__(self, tracking_uri: str, experiment_name: str): mlflow.set_tracking_uri(tracking_uri) mlflow.set_experiment(experiment_name) self.experiment_name = experiment_name def start_run(self, run_name: Optional[str] = None): """å¼€å§‹ä¸€æ¬¡è¿è¡Œ""" self.run = mlflow.start_run(run_name=run_name) return self.run def log_params(self, params: Dict[str, Any]): """è®°å½•å‚æ•°""" mlflow.log_params(params) def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None): """è®°å½•æŒ‡æ ‡""" mlflow.log_metrics(metrics, step=step) def log_model(self, model: Any, artifact_path: str = "model"): """è®°å½•æ¨¡å‹""" mlflow.sklearn.log_model(model, artifact_path) def log_artifact(self, file_path: str): """è®°å½•æ–‡ä»¶""" mlflow.log_artifact(file_path) def log_figure(self, figure, artifact_file: str): """è®°å½•å›¾è¡¨""" mlflow.log_figure(figure, artifact_file) def end_run(self, status: str = "FINISHED"): """ç»“æŸè¿è¡Œ""" mlflow.end_run(status=status) # ä½¿ç”¨ç¤ºä¾‹ def train_model_with_tracking(X_train, y_train, X_test, y_test, params): """è®­ç»ƒæ¨¡å‹å¹¶è¿½è¸ªå®éªŒ""" tracker = ExperimentTracker( tracking_uri="http://mlflow-server:5000", experiment_name="fraud-detection" ) tracker.start_run(run_name=f"experiment-{datetime.now().strftime('%Y%m%d-%H%M%S')}") try: # è®°å½•å‚æ•° tracker.log_params(params) # è®­ç»ƒæ¨¡å‹ model = train_model(X_train, y_train, params) # è¯„ä¼°æ¨¡å‹ metrics = evaluate_model(model, X_test, y_test) tracker.log_metrics(metrics) # è®°å½•æ¨¡å‹ tracker.log_model(model) # è®°å½•å­¦ä¹ æ›²çº¿ fig = plot_learning_curve(model, X_train, y_train) tracker.log_figure(fig, "learning_curve.png") # è®°å½•ç‰¹å¾é‡è¦æ€§ fig = plot_feature_importance(model) tracker.log_figure(fig, "feature_importance.png") tracker.end_run(status="FINISHED") return model, metrics except Exception as e: tracker.end_run(status="FAILED") raise e # ========== è¶…å‚æ•°ä¼˜åŒ– ========== import optuna from optuna.integration.mlflow import MLflowCallback class HyperparameterOptimizer: """è¶…å‚æ•°ä¼˜åŒ–å™¨""" def __init__(self, n_trials: int = 100, timeout: Optional[int] = None): self.n_trials = n_trials self.timeout = timeout self.study = None def objective(self, trial, X_train, y_train, X_val, y_val): """ä¼˜åŒ–ç›®æ ‡å‡½æ•°""" # å®šä¹‰æœç´¢ç©ºé—´ params = { 'n_estimators': trial.suggest_int('n_estimators', 50, 500), 'max_depth': trial.suggest_int('max_depth', 3, 20), 'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True), 'subsample': trial.suggest_float('subsample', 0.5, 1.0), 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0), 'min_child_weight': trial.suggest_int('min_child_weight', 1, 10), } # è®­ç»ƒæ¨¡å‹ model = train_model(X_train, y_train, params) # è¯„ä¼° predictions = model.predict(X_val) score = calculate_metric(y_val, predictions) return score def optimize(self, X_train, y_train, X_val, y_val): """æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–""" # åˆ›å»ºç ”ç©¶å¯¹è±¡ self.study = optuna.create_study( direction="maximize", study_name="hyperparameter-optimization" ) # æ·»åŠ MLflowå›è°ƒ mlflc = MLflowCallback( tracking_uri="http://mlflow-server:5000", metric_name="validation_score" ) # æ‰§è¡Œä¼˜åŒ– self.study.optimize( lambda trial: self.objective(trial, X_train, y_train, X_val, y_val), n_trials=self.n_trials, timeout=self.timeout, callbacks=[mlflc] ) return self.study.best_params, self.study.best_value def get_importance(self): """è·å–è¶…å‚æ•°é‡è¦æ€§""" return optuna.importance.get_param_importances(self.study) äºŒã€ç‰¹å¾å·¥ç¨‹ä¸ç®¡ç† 2.1 ç‰¹å¾å­˜å‚¨æ¶æ„ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 # ========== ç‰¹å¾å­˜å‚¨ç³»ç»Ÿ ========== from abc import ABC, abstractmethod from typing import List, Dict, Any import pandas as pd from datetime import datetime, timedelta class FeatureStore(ABC): """ç‰¹å¾å­˜å‚¨æŠ½è±¡ç±»""" @abstractmethod def get_features(self, entity_ids: List[str], feature_names: List[str]) -> pd.DataFrame: """è·å–ç‰¹å¾""" pass @abstractmethod def write_features(self, entity_id: str, features: Dict[str, Any]): """å†™å…¥ç‰¹å¾""" pass class OfflineFeatureStore(FeatureStore): """ç¦»çº¿ç‰¹å¾å­˜å‚¨ - ç”¨äºè®­ç»ƒ""" def __init__(self, storage_path: str): self.storage_path = storage_path def get_features(self, entity_ids: List[str], feature_names: List[str]) -> pd.DataFrame: """ä»å­˜å‚¨è·å–ç‰¹å¾""" # ä»Parquetæ–‡ä»¶è¯»å– df = pd.read_parquet(f"{self.storage_path}/features.parquet") # è¿‡æ»¤å®ä½“ df = df[df['entity_id'].isin(entity_ids)] # é€‰æ‹©ç‰¹å¾åˆ— return df[['entity_id'] + feature_names] def write_features(self, entity_id: str, features: Dict[str, Any]): """å†™å…¥ç‰¹å¾åˆ°å­˜å‚¨""" # å®ç°å†™å…¥é€»è¾‘ pass def create_training_set( self, entity_ids: List[str], feature_names: List[str], label_name: str ) -> pd.DataFrame: """åˆ›å»ºè®­ç»ƒæ•°æ®é›†""" df = self.get_features(entity_ids, feature_names + [label_name]) return df class OnlineFeatureStore(FeatureStore): """åœ¨çº¿ç‰¹å¾å­˜å‚¨ - ç”¨äºæ¨ç†""" def __init__(self, redis_client): self.redis = redis_client def get_features(self, entity_ids: List[str], feature_names: List[str]) -> pd.DataFrame: """ä»Redisè·å–å®æ—¶ç‰¹å¾""" features = [] for entity_id in entity_ids: key = f"feature:{entity_id}" data = self.redis.hgetall(key) feature_dict = { 'entity_id': entity_id } for feature_name in feature_names: feature_dict[feature_name] = data.get(feature_name) features.append(feature_dict) return pd.DataFrame(features) def write_features(self, entity_id: str, features: Dict[str, Any]): """å†™å…¥ç‰¹å¾åˆ°Redis""" key = f"feature:{entity_id}" # æ·»åŠ æ—¶é—´æˆ³ features['updated_at'] = datetime.now().isoformat() self.redis.hset(key, mapping=features) # è®¾ç½®è¿‡æœŸæ—¶é—´ self.redis.expire(key, timedelta(days=7)) class FeatureEngineeringPipeline: """ç‰¹å¾å·¥ç¨‹ç®¡é“""" def __init__(self, config: Dict[str, Any]): self.config = config self.transformers = {} def fit(self, df: pd.DataFrame): """æ‹Ÿåˆå˜æ¢å™¨""" for feature_config in self.config['features']: feature_name = feature_config['name'] transform_type = feature_config['transform'] if transform_type == 'standard': from sklearn.preprocessing import StandardScaler transformer = StandardScaler() transformer.fit(df[[feature_name]]) self.transformers[feature_name] = transformer elif transform_type == 'minmax': from sklearn.preprocessing import MinMaxScaler transformer = MinMaxScaler() transformer.fit(df[[feature_name]]) self.transformers[feature_name] = transformer elif transform_type == 'label': from sklearn.preprocessing import LabelEncoder transformer = LabelEncoder() transformer.fit(df[feature_name]) self.transformers[feature_name] = transformer def transform(self, df: pd.DataFrame) -> pd.DataFrame: """å˜æ¢æ•°æ®""" result_df = df.copy() for feature_name, transformer in self.transformers.items(): if isinstance(transformer, (StandardScaler, MinMaxScaler)): result_df[feature_name] = transformer.transform(df[[feature_name]]).flatten() elif isinstance(transformer, LabelEncoder): result_df[feature_name] = transformer.transform(df[feature_name]) return result_df def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame: """æ‹Ÿåˆå¹¶å˜æ¢""" self.fit(df) return self.transform(df) # ä½¿ç”¨ç¤ºä¾‹ def create_training_features(): """åˆ›å»ºè®­ç»ƒç‰¹å¾""" # åˆå§‹åŒ–ç¦»çº¿ç‰¹å¾å­˜å‚¨ offline_store = OfflineFeatureStore('/data/features') # è·å–åŸå§‹æ•°æ® raw_data = load_raw_data() # ç‰¹å¾å·¥ç¨‹ pipeline = FeatureEngineeringPipeline({ 'features': [ {'name': 'age', 'transform': 'standard'}, {'name': 'income', 'transform': 'minmax'}, {'name': 'category', 'transform': 'label'} ] }) # æ‹Ÿåˆå¹¶å˜æ¢ features = pipeline.fit_transform(raw_data) # å†™å…¥ç‰¹å¾å­˜å‚¨ for _, row in features.iterrows(): offline_store.write_features( row['entity_id'], row.to_dict() ) return features def get_online_features(entity_id: str): """è·å–åœ¨çº¿ç‰¹å¾""" import redis r = redis.Redis(host='localhost', port=6379) online_store = OnlineFeatureStore(r) features = online_store.get_features( [entity_id], ['age', 'income', 'category'] ) return features.iloc[0].to_dict() 2.2 ç‰¹å¾ç‰ˆæœ¬ç®¡ç† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 # ========== ç‰¹å¾ç‰ˆæœ¬ç®¡ç† ========== class FeatureVersion: """ç‰¹å¾ç‰ˆæœ¬""" def __init__( self, feature_name: str, version: int, computation_logic: str, created_at: datetime ): self.feature_name = feature_name self.version = version self.computation_logic = computation_logic self.created_at = created_at class FeatureRegistry: """ç‰¹å¾æ³¨å†Œè¡¨""" def __init__(self): self.features = {} def register_feature( self, feature_name: str, computation_logic: str, description: str = "", owner: str = "" ): """æ³¨å†Œæ–°ç‰¹å¾""" if feature_name in self.features: # åˆ›å»ºæ–°ç‰ˆæœ¬ last_version = max(self.features[feature_name].keys()) new_version = last_version + 1 else: self.features[feature_name] = {} new_version = 1 feature_version = FeatureVersion( feature_name=feature_name, version=new_version, computation_logic=computation_logic, created_at=datetime.now() ) self.features[feature_name][new_version] = feature_version return new_version def get_feature(self, feature_name: str, version: Optional[int] = None): """è·å–ç‰¹å¾å®šä¹‰""" if feature_name not in self.features: raise ValueError(f"Feature {feature_name} not found") if version is None: # è·å–æœ€æ–°ç‰ˆæœ¬ version = max(self.features[feature_name].keys()) return self.features[feature_name][version] def list_features(self): """åˆ—å‡ºæ‰€æœ‰ç‰¹å¾""" return { name: max(versions.keys()) for name, versions in self.features.items() } # ä½¿ç”¨ç¤ºä¾‹ registry = FeatureRegistry() # æ³¨å†Œç‰¹å¾ registry.register_feature( feature_name="user_avg_transaction_amount", computation_logic=""" SELECT user_id, AVG(amount) as user_avg_transaction_amount FROM transactions WHERE transaction_date >= DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY) GROUP BY user_id """, description="ç”¨æˆ·è¿‡å»30å¤©å¹³å‡äº¤æ˜“é‡‘é¢", owner="data-team" ) # æ›´æ–°ç‰¹å¾é€»è¾‘ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰ registry.register_feature( feature_name="user_avg_transaction_amount", computation_logic=""" SELECT user_id, AVG(amount) as user_avg_transaction_amount FROM transactions WHERE transaction_date >= DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY) AND status = 'completed' GROUP BY user_id """, description="ç”¨æˆ·è¿‡å»30å¤©å·²å®Œæˆäº¤æ˜“å¹³å‡é‡‘é¢", owner="data-team" ) ä¸‰ã€æ¨¡å‹éƒ¨ç½²ä¸æœåŠ¡åŒ– 3.1 æ¨¡å‹æœåŠ¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 # ========== æ¨¡å‹æœåŠ¡ ========== from fastapi import FastAPI, HTTPException from pydantic import BaseModel from typing import List import joblib import numpy as np app = FastAPI(title="ML Model Service") class PredictionRequest(BaseModel): features: List[float] class PredictionResponse(BaseModel): prediction: float probability: float model_version: str timestamp: str class ModelService: """æ¨¡å‹æœåŠ¡""" def __init__(self, model_path: str): self.model = self.load_model(model_path) self.model_version = self.get_model_version(model_path) def load_model(self, model_path: str): """åŠ è½½æ¨¡å‹""" return joblib.load(model_path) def get_model_version(self, model_path: str) -> str: """è·å–æ¨¡å‹ç‰ˆæœ¬""" # ä»è·¯å¾„æˆ–å…ƒæ•°æ®ä¸­æå–ç‰ˆæœ¬ return model_path.split('/')[-1].replace('.pkl', '') def predict(self, features: List[float]) -> dict: """é¢„æµ‹""" X = np.array(features).reshape(1, -1) prediction = self.model.predict(X)[0] probability = self.model.predict_proba(X)[0].max() return { 'prediction': float(prediction), 'probability': float(probability) } # å…¨å±€æ¨¡å‹æœåŠ¡å®ä¾‹ model_service = ModelService("/models/fraud_detection_v1.pkl") @app.post("/predict", response_model=PredictionResponse) async def predict(request: PredictionRequest): """é¢„æµ‹æ¥å£""" try: result = model_service.predict(request.features) return PredictionResponse( prediction=result['prediction'], probability=result['probability'], model_version=model_service.model_version, timestamp=datetime.now().isoformat() ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get("/model/info") async def model_info(): """æ¨¡å‹ä¿¡æ¯æ¥å£""" return { "model_version": model_service.model_version, "model_type": type(model_service.model).__name__, "loaded_at": datetime.now().isoformat() } @app.get("/health") async def health_check(): """å¥åº·æ£€æŸ¥""" return {"status": "healthy"} # ========== æ‰¹é‡é¢„æµ‹æœåŠ¡ ========== class BatchPredictionService: """æ‰¹é‡é¢„æµ‹æœåŠ¡""" def __init__(self, model_path: str): self.model = joblib.load(model_path) self.batch_size = 1000 def predict_batch(self, features: List[List[float]]) -> List[dict]: """æ‰¹é‡é¢„æµ‹""" results = [] for i in range(0, len(features), self.batch_size): batch = features[i:i + self.batch_size] X = np.array(batch) predictions = self.model.predict(X) probabilities = self.model.predict_proba(X).max(axis=1) for pred, prob in zip(predictions, probabilities): results.append({ 'prediction': int(pred), 'probability': float(prob) }) return results @app.post("/predict/batch") async def predict_batch(request: PredictionRequest): """æ‰¹é‡é¢„æµ‹æ¥å£""" batch_service = BatchPredictionService("/models/fraud_detection_v1.pkl") results = batch_service.predict_batch([request.features]) return {"predictions": results} 3.2 æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ä¸å›æ»š 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 # ========== æ¨¡å‹ç‰ˆæœ¬ç®¡ç† ========== class ModelVersion: """æ¨¡å‹ç‰ˆæœ¬""" def __init__( self, version: str, model_path: str, metrics: Dict[str, float], created_at: datetime ): self.version = version self.model_path = model_path self.metrics = metrics self.created_at = created_at class ModelRegistry: """æ¨¡å‹æ³¨å†Œè¡¨""" def __init__(self, storage_path: str): self.storage_path = storage_path self.models = {} self.current_version = None def register_model( self, version: str, model_path: str, metrics: Dict[str, float] ): """æ³¨å†Œæ¨¡å‹""" model_version = ModelVersion( version=version, model_path=model_path, metrics=metrics, created_at=datetime.now() ) self.models[version] = model_version return model_version def set_current_version(self, version: str): """è®¾ç½®å½“å‰ç‰ˆæœ¬""" if version not in self.models: raise ValueError(f"Version {version} not found") self.current_version = version def get_current_model(self): """è·å–å½“å‰æ¨¡å‹""" if self.current_version is None: raise ValueError("No current version set") return self.models[self.current_version] def rollback(self, target_version: str): """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬""" if target_version not in self.models: raise ValueError(f"Version {target_version} not found") old_version = self.current_version self.current_version = target_version print(f"Rollback from {old_version} to {target_version}") def list_versions(self): """åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬""" return sorted( self.models.keys(), key=lambda v: self.models[v].created_at, reverse=True ) def compare_versions(self, version1: str, version2: str) -> dict: """æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬""" if version1 not in self.models or version2 not in self.models: raise ValueError("One or both versions not found") return { 'version1': { 'version': version1, 'metrics': self.models[version1].metrics }, 'version2': { 'version': version2, 'metrics': self.models[version2].metrics }, 'improvement': { metric: self.models[version2].metrics[metric] - self.models[version1].metrics[metric] for metric in self.models[version1].metrics } } # ========== ç°åº¦å‘å¸ƒ ========== class CanaryDeployment: """ç°åº¦éƒ¨ç½²ç®¡ç†""" def __init__(self, registry: ModelRegistry): self.registry = registry self.traffic_split = {} def set_traffic_split(self, version_percentages: Dict[str, float]): """è®¾ç½®æµé‡åˆ†é…""" total = sum(version_percentages.values()) if abs(total - 1.0) > 0.01: raise ValueError("Percentages must sum to 1.0") for version in version_percentages.keys(): if version not in self.registry.models: raise ValueError(f"Version {version} not found") self.traffic_split = version_percentages def route_request(self) -> str: """è·¯ç”±è¯·æ±‚åˆ°æŒ‡å®šç‰ˆæœ¬""" import random rand = random.random() cumulative = 0.0 for version, percentage in self.traffic_split.items(): cumulative += percentage if rand &lt;= cumulative: return version return self.registry.current_version def gradual_rollout( self, new_version: str, steps: int = 10, duration_hours: int = 24 ): """æ¸è¿›å¼ç°åº¦å‘å¸ƒ""" import asyncio step_duration = duration_hours * 3600 / steps async def rollout_step(step: int): percentage = (step + 1) / steps self.set_traffic_split({ new_version: percentage, self.registry.current_version: 1 - percentage }) print(f"Step {step + 1}/{steps}: {new_version} at {percentage:.1%}") await asyncio.sleep(step_duration) # æ‰§è¡Œæ¸è¿›å¼å‘å¸ƒ for step in range(steps): asyncio.run(rollout_step(step)) # å®Œå…¨åˆ‡æ¢åˆ°æ–°ç‰ˆæœ¬ self.registry.set_current_version(new_version) self.traffic_split = {new_version: 1.0} å››ã€æ¨¡å‹ç›‘æ§ä¸A/Bæµ‹è¯• 4.1 æ¨¡å‹æ€§èƒ½ç›‘æ§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 # ========== æ¨¡å‹ç›‘æ§ç³»ç»Ÿ ========== from prometheus_client import Counter, Histogram, Gauge import numpy as np # å®šä¹‰ç›‘æ§æŒ‡æ ‡ prediction_count = Counter( 'ml_predictions_total', 'Total predictions made', ['model_version', 'prediction'] ) prediction_latency = Histogram( 'ml_prediction_duration_seconds', 'Prediction latency', ['model_version'] ) prediction_drift = Gauge( 'ml_prediction_distribution', 'Prediction distribution', ['model_version', 'prediction_class'] ) class ModelMonitor: """æ¨¡å‹ç›‘æ§å™¨""" def __init__(self, model_version: str, expected_distribution: dict): self.model_version = model_version self.expected_distribution = expected_distribution self.actual_predictions = [] def log_prediction( self, prediction: int, probability: float, latency: float ): """è®°å½•é¢„æµ‹""" prediction_count.labels( model_version=self.model_version, prediction=str(prediction) ).inc() prediction_latency.labels( model_version=self.model_version ).observe(latency) self.actual_predictions.append(prediction) def check_drift(self, threshold: float = 0.1) -> bool: """æ£€æŸ¥æ¼‚ç§»""" if len(self.actual_predictions) &lt; 100: return False # è®¡ç®—å®é™…åˆ†å¸ƒ actual_dist = {} for pred in self.actual_predictions: actual_dist[pred] = actual_dist.get(pred, 0) + 1 for key in actual_dist: actual_dist[key] /= len(self.actual_predictions) # è®¡ç®—åˆ†å¸ƒå·®å¼‚ drift_score = 0.0 for key in self.expected_distribution: expected = self.expected_distribution.get(key, 0) actual = actual_dist.get(key, 0) drift_score += abs(expected - actual) return drift_score > threshold def update_distribution(self): """æ›´æ–°æœŸæœ›åˆ†å¸ƒ""" if len(self.actual_predictions) &lt; 100: return new_dist = {} for pred in self.actual_predictions: new_dist[pred] = new_dist.get(pred, 0) + 1 for key in new_dist: new_dist[key] /= len(self.actual_predictions) self.expected_distribution = new_dist self.actual_predictions = [] class DataDriftDetector: """æ•°æ®æ¼‚ç§»æ£€æµ‹å™¨""" def __init__(self, reference_data: np.ndarray): self.reference_data = reference_data self.reference_mean = np.mean(reference_data, axis=0) self.reference_std = np.std(reference_data, axis=0) def detect_drift( self, current_data: np.ndarray, threshold: float = 3.0 ) -> dict: """æ£€æµ‹æ•°æ®æ¼‚ç§»""" current_mean = np.mean(current_data, axis=0) current_std = np.std(current_data, axis=0) # Z-scoreæ£€æµ‹ z_scores = np.abs( (current_mean - self.reference_mean) / self.reference_std ) drifted_features = np.where(z_scores > threshold)[0] return { 'drift_detected': len(drifted_features) > 0, 'drifted_features': drifted_features.tolist(), 'z_scores': z_scores.tolist() } # ä½¿ç”¨ç¤ºä¾‹ def create_model_monitor(): """åˆ›å»ºæ¨¡å‹ç›‘æ§å™¨""" # æœŸæœ›åˆ†å¸ƒï¼ˆä»è®­ç»ƒæ•°æ®è·å–ï¼‰ expected_dist = { 0: 0.95, # 95% æ­£å¸¸ 1: 0.05 # 5% æ¬ºè¯ˆ } monitor = ModelMonitor( model_version="v1.0", expected_distribution=expected_dist ) return monitor async def monitor_predictions(): """ç›‘æ§é¢„æµ‹""" monitor = create_model_monitor() while True: # è·å–é¢„æµ‹ç»“æœ predictions = await get_recent_predictions() for pred in predictions: monitor.log_prediction( prediction=pred['label'], probability=pred['probability'], latency=pred['latency'] ) # æ£€æŸ¥æ¼‚ç§» if monitor.check_drift(): send_alert("Prediction drift detected!") await asyncio.sleep(60) # æ¯åˆ†é’Ÿæ£€æŸ¥ 4.2 A/Bæµ‹è¯•æ¡†æ¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 # ========== A/Bæµ‹è¯•æ¡†æ¶ ========== class ABTest: """A/Bæµ‹è¯•""" def __init__( self, name: str, variants: List[str], traffic_split: Dict[str, float], metrics: List[str] ): self.name = name self.variants = variants self.traffic_split = traffic_split self.metrics = metrics self.results = {variant: {metric: [] for metric in metrics} for variant in variants} def assign_variant(self, user_id: str) -> str: """åˆ†é…ç”¨æˆ·åˆ°å˜ä½“""" import hashlib # ä½¿ç”¨ç”¨æˆ·IDçš„å“ˆå¸Œå€¼ä¿è¯ä¸€è‡´æ€§ hash_value = int(hashlib.md5(f"{self.name}:{user_id}".encode()).hexdigest(), 16) normalized = hash_value / (2 ** 32 - 1) cumulative = 0.0 for variant, percentage in self.traffic_split.items(): cumulative += percentage if normalized &lt;= cumulative: return variant return self.variants[-1] def record_metric(self, variant: str, metric: str, value: float): """è®°å½•æŒ‡æ ‡""" if variant not in self.results: raise ValueError(f"Unknown variant: {variant}") if metric not in self.metrics: raise ValueError(f"Unknown metric: {metric}") self.results[variant][metric].append(value) def analyze(self) -> dict: """åˆ†æA/Bæµ‹è¯•ç»“æœ""" from scipy import stats analysis = {} for metric in self.metrics: metric_analysis = {} # è®¡ç®—æ¯ä¸ªå˜ä½“çš„ç»Ÿè®¡ä¿¡æ¯ for variant in self.variants: values = self.results[variant][metric] if len(values) == 0: continue metric_analysis[variant] = { 'mean': np.mean(values), 'std': np.std(values), 'count': len(values) } # æ¯”è¾ƒå˜ä½“ if len(self.variants) >= 2: variant_a, variant_b = self.variants[0], self.variants[1] values_a = self.results[variant_a][metric] values_b = self.results[variant_b][metric] if len(values_a) > 0 and len(values_b) > 0: # tæ£€éªŒ t_stat, p_value = stats.ttest_ind(values_a, values_b) metric_analysis['comparison'] = { 't_statistic': t_stat, 'p_value': p_value, 'significant': p_value &lt; 0.05, 'lift': ( metric_analysis[variant_b]['mean'] - metric_analysis[variant_a]['mean'] ) / metric_analysis[variant_a]['mean'] } analysis[metric] = metric_analysis return analysis def get_winner(self) -> str: """ç¡®å®šè·èƒœå˜ä½“""" analysis = self.analyze() # ç®€å•ç­–ç•¥ï¼šé€‰æ‹©ä¸»è¦æŒ‡æ ‡æœ€é«˜çš„å˜ä½“ primary_metric = self.metrics[0] best_variant = None best_value = float('-inf') for variant in self.variants: if primary_metric in analysis: value = analysis[primary_metric].get(variant, {}).get('mean', float('-inf')) if value > best_value: best_value = value best_variant = variant return best_variant # ä½¿ç”¨ç¤ºä¾‹ def run_ab_test(): """è¿è¡ŒA/Bæµ‹è¯•""" # åˆ›å»ºA/Bæµ‹è¯• ab_test = ABTest( name="fraud_detection_v2", variants=["control", "treatment"], traffic_split={"control": 0.5, "treatment": 0.5}, metrics=["accuracy", "precision", "recall", "f1_score"] ) # åˆ†é…ç”¨æˆ·å¹¶è®°å½•æŒ‡æ ‡ async def process_prediction(user_id: str, prediction: dict, actual: int): """å¤„ç†é¢„æµ‹å¹¶è®°å½•æŒ‡æ ‡""" variant = ab_test.assign_variant(user_id) # ä½¿ç”¨å¯¹åº”å˜ä½“çš„æ¨¡å‹ if variant == "control": result = control_model.predict(prediction['features']) else: result = treatment_model.predict(prediction['features']) # è®¡ç®—æŒ‡æ ‡ accuracy = 1 if result['prediction'] == actual else 0 precision = calculate_precision(result, actual) recall = calculate_recall(result, actual) f1_score = 2 * (precision * recall) / (precision + recall) # è®°å½•æŒ‡æ ‡ ab_test.record_metric(variant, "accuracy", accuracy) ab_test.record_metric(variant, "precision", precision) ab_test.record_metric(variant, "recall", recall) ab_test.record_metric(variant, "f1_score", f1_score) # åˆ†æç»“æœ analysis = ab_test.analyze() print("A/B Test Analysis:") print(analysis) # è·å–è·èƒœå˜ä½“ winner = ab_test.get_winner() print(f"Winner: {winner}") return analysis, winner äº”ã€ç«¯åˆ°ç«¯MLOpsæµæ°´çº¿ 5.1 CI/CDé›†æˆ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 # .github/workflows/mlops-pipeline.yml name: MLOps Pipeline on: push: branches: [main] paths: - 'models/**' - 'data/**' - 'training/**' pull_request: branches: [main] jobs: data-validation: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python uses: actions/setup-python@v4 with: python-version: '3.9' - name: Install dependencies run: | pip install -r requirements.txt - name: Validate data run: | python scripts/validate_data.py - name: Check data drift run: | python scripts/check_drift.py train-model: needs: data-validation runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python uses: actions/setup-python@v4 with: python-version: '3.9' - name: Install dependencies run: | pip install -r requirements.txt - name: Train model env: MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }} run: | python scripts/train_model.py - name: Run tests run: | pytest tests/ evaluate-model: needs: train-model runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Evaluate model env: MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }} run: | python scripts/evaluate_model.py - name: Check thresholds run: | python scripts/check_thresholds.py deploy-model: needs: evaluate-model if: github.ref == 'refs/heads/main' runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Deploy to staging run: | kubectl apply -f k8s/staging/ - name: Run smoke tests run: | python scripts/smoke_test.py - name: Promote to production run: | kubectl apply -f k8s/production/ 5.2 å®Œæ•´MLOpsé¡¹ç›®ç»“æ„ mlops-project/ â”œâ”€â”€ data/ â”‚ â”œâ”€â”€ raw/ # åŸå§‹æ•°æ® â”‚ â”œâ”€â”€ processed/ # å¤„ç†åæ•°æ® â”‚ â””â”€â”€ features/ # ç‰¹å¾æ•°æ® â”œâ”€â”€ models/ â”‚ â”œâ”€â”€ training/ # è®­ç»ƒè„šæœ¬ â”‚ â”‚ â”œâ”€â”€ train.py â”‚ â”‚ â”œâ”€â”€ evaluate.py â”‚ â”‚ â””â”€â”€ tune.py â”‚ â”œâ”€â”€ inference/ # æ¨ç†ä»£ç  â”‚ â”‚ â”œâ”€â”€ predict.py â”‚ â”‚ â””â”€â”€ batch_predict.py â”‚ â””â”€â”€ monitoring/ # ç›‘æ§è„šæœ¬ â”‚ â”œâ”€â”€ drift_detector.py â”‚ â””â”€â”€ performance_monitor.py â”œâ”€â”€ features/ â”‚ â”œâ”€â”€ feature_store.py # ç‰¹å¾å­˜å‚¨ â”‚ â””â”€â”€ feature_registry.py # ç‰¹å¾æ³¨å†Œè¡¨ â”œâ”€â”€ experiments/ â”‚ â””â”€â”€ notebooks/ # å®éªŒç¬”è®°æœ¬ â”œâ”€â”€ tests/ â”‚ â”œâ”€â”€ unit/ â”‚ â”œâ”€â”€ integration/ â”‚ â””â”€â”€ performance/ â”œâ”€â”€ deployment/ â”‚ â”œâ”€â”€ k8s/ # Kubernetesé…ç½® â”‚ â”œâ”€â”€ docker/ # Dockerfile â”‚ â””â”€â”€ terraform/ # åŸºç¡€è®¾æ–½ä»£ç  â”œâ”€â”€ mlflow/ # MLflowé…ç½® â”œâ”€â”€ dvc/ # DVCé…ç½® â”œâ”€â”€ requirements.txt â””â”€â”€ README.md æ€»ç»“ AI/MLç³»ç»Ÿçš„å·¥ç¨‹åŒ–å®è·µéœ€è¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/ai%E5%BC%80%E5%8F%91/ class=category-link>AIå¼€å‘</a><a href=/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ class=category-link>æœºå™¨å­¦ä¹ </a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to AIä¸æœºå™¨å­¦ä¹ å·¥ç¨‹åŒ–å®è·µï¼šä»æ¨¡å‹åˆ°ç”Ÿäº§ç³»ç»Ÿçš„å®Œæ•´æŒ‡å—" href=/blog/articles/ai%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%8C%96%E5%AE%9E%E8%B7%B5%E4%BB%8E%E6%A8%A1%E5%9E%8B%E5%88%B0%E7%94%9F%E4%BA%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>åç«¯ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼šä»å•ä½“åˆ°å¾®æœåŠ¡çš„æ¼”è¿›ä¹‹è·¯</h2></header><div class=entry-content><p>å¼•è¨€ éšç€ä¸šåŠ¡è§„æ¨¡çš„ä¸æ–­æ‰©å¤§ï¼Œåç«¯ç³»ç»Ÿæ¶æ„éœ€è¦ä¸æ–­æ¼”è¿›ä»¥åº”å¯¹æ—¥ç›Šå¢é•¿çš„æŒ‘æˆ˜ã€‚ä»å•ä½“åº”ç”¨åˆ°å¾®æœåŠ¡æ¶æ„ï¼Œä»å•æœºéƒ¨ç½²åˆ°åˆ†å¸ƒå¼é›†ç¾¤ï¼Œæ¯ä¸€æ¬¡æ¶æ„æ¼”è¿›éƒ½æ˜¯ä¸ºäº†è§£å†³ç‰¹å®šçš„ç—›ç‚¹ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨åç«¯ç³»ç»Ÿæ¶æ„è®¾è®¡çš„æ ¸å¿ƒåŸåˆ™ã€æ¨¡å¼ä¸å®è·µã€‚
ä¸€ã€æ¶æ„æ¼”è¿›å†ç¨‹ 1.1 æ¶æ„æ¼”è¿›è·¯å¾„ å•ä½“åº”ç”¨ â†’ åˆ†å±‚æ¶æ„ â†’ SOA â†’ å¾®æœåŠ¡ â†’ Serverless æ¼”è¿›é˜¶æ®µå¯¹æ¯”
æ¶æ„ç±»å‹ ç‰¹ç‚¹ ä¼˜åŠ¿ æŒ‘æˆ˜ é€‚ç”¨åœºæ™¯ å•ä½“åº”ç”¨ å•ä¸€ä»£ç åº“ã€å•ä¸€éƒ¨ç½² å¼€å‘ç®€å•ã€éƒ¨ç½²å®¹æ˜“ æ‰©å±•æ€§å·®ã€æŠ€æœ¯æ ˆå›ºå®š å°å‹é¡¹ç›®ã€åˆåˆ›æœŸ åˆ†å±‚æ¶æ„ MVC/MVPåˆ†å±‚ èŒè´£æ¸…æ™°ã€æ˜“äºç»´æŠ¤ å±‚é—´è€¦åˆå¼º ä¸­å°å‹é¡¹ç›® SOA æœåŠ¡åŒ–ã€ESBæ€»çº¿ æœåŠ¡å¤ç”¨ã€æ¾è€¦åˆ ESBå•ç‚¹ã€å¤æ‚åº¦é«˜ ä¼ä¸šçº§åº”ç”¨ å¾®æœåŠ¡ ç‹¬ç«‹æœåŠ¡ã€è‡ªæ²»éƒ¨ç½² ç‹¬ç«‹æ‰©å±•ã€æŠ€æœ¯è‡ªç”± è¿ç»´å¤æ‚ã€åˆ†å¸ƒå¼äº‹åŠ¡ å¤§å‹å¤æ‚ç³»ç»Ÿ Serverless å‡½æ•°çº§ã€æŒ‰éœ€ä»˜è´¹ æè‡´å¼¹æ€§ã€æˆæœ¬ä¼˜åŒ– å‚å•†é”å®šã€å†·å¯åŠ¨ äº‹ä»¶é©±åŠ¨ã€æ³¢å³°æ˜æ˜¾ 1.2 å•ä½“æ¶æ„çš„å±€é™æ€§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # å•ä½“åº”ç”¨çš„å…¸å‹é—®é¢˜ # é—®é¢˜1: ä»£ç è€¦åˆä¸¥é‡ # ä¸€ä¸ªè¯·æ±‚çš„å¤„ç†æµç¨‹æ¶‰åŠå¤šä¸ªæ¨¡å— class OrderService: def create_order(self, user_id, items): # ç›´æ¥ä¾èµ–å¤šä¸ªæ¨¡å— user = UserService().get_user(user_id) inventory = InventoryService().check_stock(items) payment = PaymentService().process_payment(items) shipping = ShippingService().calculate_shipping(user.address) notification = NotificationService().send_confirmation(user.email) # å¦‚æœä»»ä½•ä¸€ä¸ªæ¨¡å—å‡ºé”™ï¼Œæ•´ä¸ªè®¢å•åˆ›å»ºå¤±è´¥ return Order(user=user, items=items, payment=payment) # é—®é¢˜2: éš¾ä»¥ç‹¬ç«‹æ‰©å±• # å½“è®¢å•æœåŠ¡å‹åŠ›å¤§æ—¶ï¼Œå¿…é¡»æ•´ä½“æ‰©å±• # æ— æ³•é’ˆå¯¹ç‰¹å®šç“¶é¢ˆæœåŠ¡å•ç‹¬æ‰©å®¹ # é—®é¢˜3: æŠ€æœ¯æ ˆé”å®š # æ•´ä¸ªåº”ç”¨å¿…é¡»ä½¿ç”¨ç›¸åŒçš„è¯­è¨€å’Œæ¡†æ¶ # æ— æ³•ä¸ºæ–°æœåŠ¡é€‰æ‹©æ›´é€‚åˆçš„æŠ€æœ¯ # é—®é¢˜4: éƒ¨ç½²é£é™©é«˜ # ä»»ä½•å°çš„ä¿®æ”¹éƒ½éœ€è¦é‡æ–°éƒ¨ç½²æ•´ä¸ªåº”ç”¨ # ä¸€å¤„bugå¯èƒ½å½±å“æ•´ä¸ªç³»ç»Ÿ äºŒã€å¾®æœåŠ¡æ¶æ„è®¾è®¡ 2.1 æ ¸å¿ƒè®¾è®¡åŸåˆ™ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 # ========== æœåŠ¡æ‹†åˆ†åŸåˆ™ ========== # 1. å•ä¸€èŒè´£åŸåˆ™ # æ¯ä¸ªæœåŠ¡ä¸“æ³¨äºä¸€ä¸ªä¸šåŠ¡é¢†åŸŸ class UserService: """ç”¨æˆ·æœåŠ¡ - åªè´Ÿè´£ç”¨æˆ·ç›¸å…³çš„ä¸šåŠ¡""" def create_user(self, data): pass def get_user(self, user_id): pass def update_user(self, user_id, data): pass class OrderService: """è®¢å•æœåŠ¡ - åªè´Ÿè´£è®¢å•ç›¸å…³çš„ä¸šåŠ¡""" def create_order(self, data): pass def get_order(self, order_id): pass def cancel_order(self, order_id): pass # 2. é™ç•Œä¸Šä¸‹æ–‡åŸåˆ™ # æŒ‰ç…§ä¸šåŠ¡é¢†åŸŸè¾¹ç•Œæ‹†åˆ†æœåŠ¡ # DDD (Domain-Driven Design) æˆ˜æœ¯æ¨¡å¼ # 3. æ•°æ®ç‹¬ç«‹æ€§åŸåˆ™ # æ¯ä¸ªæœåŠ¡æ‹¥æœ‰ç‹¬ç«‹çš„æ•°æ®åº“ class UserDatabase: """ç”¨æˆ·æœåŠ¡çš„æ•°æ®åº“""" def __init__(self): self.db = PostgreSQL('users_db') class OrderDatabase: """è®¢å•æœåŠ¡çš„æ•°æ®åº“""" def __init__(self): self.db = MongoDB('orders_db') # 4. APIç½‘å…³åŸåˆ™ # ç»Ÿä¸€å…¥å£ï¼Œè·¯ç”±è½¬å‘ class APIGateway: """APIç½‘å…³ - æœåŠ¡ç»Ÿä¸€å…¥å£""" def __init__(self): self.routes = { '/api/users/*': UserService(), '/api/orders/*': OrderService(), '/api/products/*': ProductService(), '/api/payments/*': PaymentService() } def route(self, request): # è·¯ç”±åŒ¹é… for pattern, service in self.routes.items(): if request.path.match(pattern): return service.handle(request) # èšåˆå¤šä¸ªæœåŠ¡çš„å“åº” if request.path == '/api/dashboard': return self.aggregate_dashboard(request) def aggregate_dashboard(self, request): """èšåˆå¤šä¸ªæœåŠ¡çš„æ•°æ®""" user_data = self.call_service('/api/users/me', request) order_data = self.call_service('/api/orders/recent', request) notification_data = self.call_service('/api/notifications', request) return { 'user': user_data, 'orders': order_data, 'notifications': notification_data } 2.2 æœåŠ¡é€šä¿¡æ¨¡å¼ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 # ========== åŒæ­¥é€šä¿¡: REST/gRPC ========== import requests from typing import Protocol # REST APIè°ƒç”¨ class OrderClient: """è®¢å•æœåŠ¡å®¢æˆ·ç«¯""" BASE_URL = "http://order-service:8080" def create_order(self, order_data: dict) -> dict: response = requests.post( f"{self.BASE_URL}/api/orders", json=order_data, timeout=5 # è¶…æ—¶æ§åˆ¶ ) response.raise_for_status() return response.json() def get_order(self, order_id: str) -> dict: response = requests.get( f"{self.BASE_URL}/api/orders/{order_id}", timeout=3 ) response.raise_for_status() return response.json() # gRPCè°ƒç”¨ (æ€§èƒ½æ›´é«˜) import grpc from generated import order_pb2, order_pb2_grpc class OrderGRPCClient: """è®¢å•æœåŠ¡gRPCå®¢æˆ·ç«¯""" def __init__(self): self.channel = grpc.insecure_channel('order-service:9090') self.stub = order_pb2_grpc.OrderServiceStub(self.channel) def create_order(self, order_data: dict) -> order_pb2.OrderResponse: request = order_pb2.CreateOrderRequest( user_id=order_data['user_id'], items=[ order_pb2.OrderItem( product_id=item['product_id'], quantity=item['quantity'] ) for item in order_data['items'] ] ) return self.stub.CreateOrder(request, timeout=5) # ========== å¼‚æ­¥é€šä¿¡: æ¶ˆæ¯é˜Ÿåˆ— ========== import asyncio from aio_pika import connect, Message class EventBus: """äº‹ä»¶æ€»çº¿ - å¼‚æ­¥æ¶ˆæ¯ä¼ é€’""" def __init__(self, amqp_url: str): self.connection = None self.channel = None self.amqp_url = amqp_url async def connect(self): """å»ºç«‹è¿æ¥""" self.connection = await connect(self.amqp_url) self.channel = await self.connection.channel() # å£°æ˜äº¤æ¢æœº await self.channel.declare_exchange( 'domain-events', 'topic', durable=True ) async def publish(self, event_type: str, event_data: dict): """å‘å¸ƒäº‹ä»¶""" exchange = await self.get_exchange() message = Message( json.dumps(event_data).encode(), content_type='application/json', delivery_mode=2 # æŒä¹…åŒ– ) await exchange.publish( message, routing_key=event_type ) async def subscribe(self, event_pattern: str, handler): """è®¢é˜…äº‹ä»¶""" exchange = await self.get_exchange() # å£°æ˜é˜Ÿåˆ— queue = await self.channel.declare_queue( f'{event_pattern}-queue', durable=True ) # ç»‘å®šäº¤æ¢æœº await queue.bind(exchange, routing_key=event_pattern) async with queue.iterator() as queue_iter: async for message in queue_iter: try: event_data = json.loads(message.body.decode()) await handler(event_data) await message.ack() except Exception as e: await message.nack() # äº‹ä»¶é©±åŠ¨æ¶æ„ç¤ºä¾‹ class OrderCreatedEvent: """è®¢å•åˆ›å»ºäº‹ä»¶""" def __init__(self, order_id, user_id, items): self.event_type = 'order.created' self.data = { 'order_id': order_id, 'user_id': user_id, 'items': items, 'timestamp': datetime.now().isoformat() } # è®¢å•æœåŠ¡å‘å¸ƒäº‹ä»¶ async def create_order_with_event(order_data): # åˆ›å»ºè®¢å• order = await order_repository.create(order_data) # å‘å¸ƒäº‹ä»¶ event_bus = EventBus() await event_bus.publish( 'order.created', OrderCreatedEvent( order.id, order.user_id, order.items ).data ) return order # åº“å­˜æœåŠ¡ç›‘å¬äº‹ä»¶ async def handle_order_created(event_data): """å¤„ç†è®¢å•åˆ›å»ºäº‹ä»¶ - æ‰£å‡åº“å­˜""" order_id = event_data['order_id'] items = event_data['items'] for item in items: await inventory_service.deduct_stock( item['product_id'], item['quantity'] ) await event_bus.publish( 'inventory.deducted', {'order_id': order_id, 'status': 'completed'} ) # é€šçŸ¥æœåŠ¡ç›‘å¬äº‹ä»¶ async def handle_inventory_deducted(event_data): """å¤„ç†åº“å­˜æ‰£å‡å®Œæˆäº‹ä»¶ - å‘é€é€šçŸ¥""" order_id = event_data['order_id'] order = await order_repository.get(order_id) await notification_service.send_order_confirmation( order.user_email, order_id ) 2.3 æœåŠ¡å‘ç°ä¸æ³¨å†Œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 # ========== æœåŠ¡æ³¨å†Œä¸­å¿ƒ ========== import asyncio from typing import Dict, List, Optional from datetime import datetime, timedelta class ServiceInstance: """æœåŠ¡å®ä¾‹""" def __init__(self, service_id: str, address: str, port: int): self.service_id = service_id self.address = address self.port = port self.last_heartbeat = datetime.now() @property def url(self) -> str: return f"http://{self.address}:{self.port}" def is_alive(self, timeout: int = 10) -> bool: """æ£€æŸ¥å®ä¾‹æ˜¯å¦å­˜æ´»""" return (datetime.now() - self.last_heartbeat).seconds &lt; timeout class ServiceRegistry: """æœåŠ¡æ³¨å†Œä¸­å¿ƒ""" def __init__(self): self.services: Dict[str, List[ServiceInstance]] = {} def register(self, service_name: str, instance: ServiceInstance): """æ³¨å†ŒæœåŠ¡å®ä¾‹""" if service_name not in self.services: self.services[service_name] = [] # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ existing = next( (i for i in self.services[service_name] if i.service_id == instance.service_id), None ) if existing: # æ›´æ–°å¿ƒè·³æ—¶é—´ existing.last_heartbeat = datetime.now() else: # æ–°æ³¨å†Œ self.services[service_name].append(instance) print(f"Registered: {service_name} - {instance.url}") def deregister(self, service_name: str, service_id: str): """æ³¨é”€æœåŠ¡å®ä¾‹""" if service_name in self.services: self.services[service_name] = [ i for i in self.services[service_name] if i.service_id != service_id ] def discover(self, service_name: str) -> Optional[ServiceInstance]: """æœåŠ¡å‘ç° - è´Ÿè½½å‡è¡¡""" if service_name not in self.services: return None # è¿‡æ»¤æ‰å¤±æ•ˆçš„å®ä¾‹ alive_instances = [ i for i in self.services[service_name] if i.is_alive() ] if not alive_instances: return None # è½®è¯¢è´Ÿè½½å‡è¡¡ return alive_instances[hash(service_name) % len(alive_instances)] # æˆ–è€…ä½¿ç”¨éšæœºé€‰æ‹© # return random.choice(alive_instances) def heartbeat(self, service_name: str, service_id: str): """æ¥æ”¶å¿ƒè·³""" if service_name in self.services: for instance in self.services[service_name]: if instance.service_id == service_id: instance.last_heartbeat = datetime.now() # ========== æœåŠ¡å®¢æˆ·ç«¯ ========== class ServiceClient: """æœåŠ¡å®¢æˆ·ç«¯ - å¸¦æœåŠ¡å‘ç°""" def __init__(self, registry: ServiceRegistry): self.registry = registry self.cache = {} # ç¼“å­˜æœåŠ¡åœ°å€ async def call(self, service_name: str, endpoint: str, **kwargs): """è°ƒç”¨æœåŠ¡""" # ä»ç¼“å­˜æˆ–æ³¨å†Œä¸­å¿ƒè·å–æœåŠ¡åœ°å€ instance = self.cache.get(service_name) if not instance or not instance.is_alive(): instance = self.registry.discover(service_name) if not instance: raise ServiceUnavailableException(f"Service {service_name} not found") self.cache[service_name] = instance # æ„å»ºè¯·æ±‚URL url = f"{instance.url}{endpoint}" try: response = requests.post(url, json=kwargs, timeout=5) response.raise_for_status() return response.json() except requests.RequestException as e: # è°ƒç”¨å¤±è´¥ï¼Œæ¸…é™¤ç¼“å­˜ self.cache.pop(service_name, None) raise e # ========== ä½¿ç”¨ç¤ºä¾‹ ========== # æœåŠ¡å¯åŠ¨æ—¶æ³¨å†Œ registry = ServiceRegistry() async def start_service(): service_instance = ServiceInstance( service_id=f"order-service-{os.getenv('INSTANCE_ID')}", address=os.getenv('SERVICE_ADDRESS'), port=int(os.getenv('SERVICE_PORT')) ) registry.register('order-service', service_instance) # å®šæœŸå‘é€å¿ƒè·³ while True: await asyncio.sleep(5) registry.heartbeat('order-service', service_instance.service_id) 2.4 åˆ†å¸ƒå¼é…ç½®ç®¡ç† 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 # ========== é…ç½®ä¸­å¿ƒ ========== import asyncio import json from typing import Any, Callable from watchfiles import awatch class ConfigCenter: """åˆ†å¸ƒå¼é…ç½®ä¸­å¿ƒ""" def __init__(self, config_dir: str = './config'): self.config_dir = config_dir self.configs = {} self.watchers = {} # config_key -> [callbacks] def load_config(self, service_name: str) -> dict: """åŠ è½½æœåŠ¡é…ç½®""" config_file = f"{self.config_dir}/{service_name}.json" try: with open(config_file) as f: config = json.load(f) self.configs[service_name] = config return config except FileNotFoundError: return {} def get_config(self, service_name: str, key: str = None) -> Any: """è·å–é…ç½®""" config = self.configs.get(service_name, {}) if key: return config.get(key) return config def watch_config(self, service_name: str, callback: Callable): """ç›‘å¬é…ç½®å˜åŒ–""" if service_name not in self.watchers: self.watchers[service_name] = [] self.watchers[service_name].append(callback) async def watch_changes(self): """ç›‘å¬é…ç½®æ–‡ä»¶å˜åŒ–""" async for changes in awatch(self.config_dir): for change_type, config_path in changes: service_name = config_path.stem if change_type == Change.modified: # é‡æ–°åŠ è½½é…ç½® old_config = self.configs.get(service_name, {}) new_config = self.load_config(service_name) # è§¦å‘å›è°ƒ if service_name in self.watchers: for callback in self.watchers[service_name]: await callback(old_config, new_config) # ========== ä½¿ç”¨ç¤ºä¾‹ ========== config_center = ConfigCenter() # åŠ è½½é…ç½® app_config = config_center.load_config('order-service') # ç›‘å¬é…ç½®å˜åŒ– async def on_config_changed(old_config, new_config): """é…ç½®å˜åŒ–å¤„ç†""" if old_config.get('log_level') != new_config.get('log_level'): # é‡æ–°é…ç½®æ—¥å¿—çº§åˆ« logging.getLogger().setLevel(new_config['log_level']) if old_config.get('database') != new_config.get('database'): # é‡æ–°å»ºç«‹æ•°æ®åº“è¿æ¥ await reconnect_database(new_config['database']) config_center.watch_config('order-service', on_config_changed) ä¸‰ã€æ•°æ®ä¸€è‡´æ€§è®¾è®¡ 3.1 åˆ†å¸ƒå¼äº‹åŠ¡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 # ========== ä¸¤é˜¶æ®µæäº¤ (2PC) ========== class TwoPhaseCommit: """ä¸¤é˜¶æ®µæäº¤åè°ƒè€…""" def __init__(self): self.participants = [] def register_participant(self, participant): """æ³¨å†Œå‚ä¸è€…""" self.participants.append(participant) async def execute(self, transaction_data): """æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡""" transaction_id = generate_transaction_id() # é˜¶æ®µ1: å‡†å¤‡é˜¶æ®µ prepared = [] for participant in self.participants: try: result = await participant.prepare(transaction_id, transaction_data) if result == 'PREPARED': prepared.append(participant) else: # ä»»ä½•å‚ä¸è€…æ‹’ç»ï¼Œå›æ»šæ‰€æœ‰ await self._rollback_all(transaction_id, prepared) return False except Exception as e: await self._rollback_all(transaction_id, prepared) raise e # é˜¶æ®µ2: æäº¤é˜¶æ®µ committed = [] for participant in prepared: try: await participant.commit(transaction_id) committed.append(participant) except Exception as e: # æäº¤å¤±è´¥ï¼Œéœ€è¦äººå·¥ä»‹å…¥ await self._rollback_all(transaction_id, committed) raise Exception(f"Commit failed: {e}") return True async def _rollback_all(self, transaction_id, participants): """å›æ»šæ‰€æœ‰å‚ä¸è€…""" for participant in participants: try: await participant.rollback(transaction_id) except Exception as e: logging.error(f"Rollback failed: {e}") # ========== Sagaæ¨¡å¼ ========== # é•¿äº‹åŠ¡çš„æ›¿ä»£æ–¹æ¡ˆ class SagaOrchestrator: """Sagaç¼–æ’å™¨""" def __init__(self): self.steps = [] self.compensations = [] def add_step(self, action, compensation): """æ·»åŠ æ­¥éª¤""" self.steps.append(action) self.compensations.append(compensation) async def execute(self, initial_data): """æ‰§è¡ŒSaga""" context = initial_data executed_steps = [] # æ‰§è¡Œæ¯ä¸ªæ­¥éª¤ for i, step in enumerate(self.steps): try: context = await step(context) executed_steps.append(i) except Exception as e: # å¤±è´¥ï¼Œæ‰§è¡Œè¡¥å¿ await self._compensate(executed_steps, context) raise e return context async def _compensate(self, executed_steps, context): """æ‰§è¡Œè¡¥å¿äº‹åŠ¡""" # é€†åºæ‰§è¡Œè¡¥å¿ for i in reversed(executed_steps): try: await self.compensations[i](context) except Exception as e: logging.error(f"Compensation failed: {e}") # è®¢å•Sagaç¤ºä¾‹ class OrderSaga: """è®¢å•å¤„ç†Saga""" def __init__(self): self.saga = SagaOrchestrator() self._setup_steps() def _setup_steps(self): """è®¾ç½®Sagaæ­¥éª¤""" # æ­¥éª¤1: åˆ›å»ºè®¢å• async def create_order(context): order = await order_repository.create(context['order_data']) context['order'] = order return context async def cancel_order(context): await order_repository.update_status( context['order'].id, 'CANCELLED' ) # æ­¥éª¤2: æ‰£å‡åº“å­˜ async def deduct_inventory(context): for item in context['order'].items: await inventory_service.deduct_stock( item.product_id, item.quantity ) return context async def restore_inventory(context): for item in context['order'].items: await inventory_service.restore_stock( item.product_id, item.quantity ) # æ­¥éª¤3: å¤„ç†æ”¯ä»˜ async def process_payment(context): payment = await payment_service.charge( context['order'].user_id, context['order'].total_amount ) context['payment'] = payment return context async def refund_payment(context): await payment_service.refund( context['payment'].transaction_id ) # æ­¥éª¤4: å‘é€é€šçŸ¥ async def send_notification(context): await notification_service.send( context['order'].user_email, 'Order Created', f'Your order {context["order"].id} has been created' ) return context async def cancel_notification(context): # é€šçŸ¥å¯èƒ½ä¸éœ€è¦è¡¥å¿ pass # æ·»åŠ æ­¥éª¤å’Œè¡¥å¿ self.saga.add_step(create_order, cancel_order) self.saga.add_step(deduct_inventory, restore_inventory) self.saga.add_step(process_payment, refund_payment) self.saga.add_step(send_notification, cancel_notification) async def execute(self, order_data): """æ‰§è¡Œè®¢å•Saga""" return await self.saga.execute({'order_data': order_data}) 3.2 æœ€ç»ˆä¸€è‡´æ€§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 # ========== äº‹ä»¶æº¯æº ========== # é€šè¿‡äº‹ä»¶æµé‡å»ºçŠ¶æ€ class EventStore: """äº‹ä»¶å­˜å‚¨""" def __init__(self): self.events = [] async def append_event(self, aggregate_id: str, event: dict): """è¿½åŠ äº‹ä»¶""" event['aggregate_id'] = aggregate_id event['timestamp'] = datetime.now().isoformat() event['version'] = len(self.events) + 1 self.events.append(event) async def get_events(self, aggregate_id: str) -> List[dict]: """è·å–èšåˆçš„æ‰€æœ‰äº‹ä»¶""" return [ e for e in self.events if e['aggregate_id'] == aggregate_id ] class OrderAggregate: """è®¢å•èšåˆ - é€šè¿‡äº‹ä»¶é‡å»ºçŠ¶æ€""" def __init__(self, event_store: EventStore): self.event_store = event_store self.state = None async def rebuild(self, order_id: str): """ä»äº‹ä»¶æµé‡å»ºçŠ¶æ€""" events = await self.event_store.get_events(order_id) state = None for event in events: state = self._apply_event(state, event) self.state = state return state def _apply_event(self, state, event): """åº”ç”¨äº‹ä»¶åˆ°çŠ¶æ€""" event_type = event['type'] if event_type == 'OrderCreated': return { 'id': event['order_id'], 'user_id': event['user_id'], 'items': event['items'], 'status': 'CREATED' } elif event_type == 'PaymentCompleted': state['status'] = 'PAID' state['payment_id'] = event['payment_id'] return state elif event_type == 'OrderShipped': state['status'] = 'SHIPPED' state['shipping_id'] = event['shipping_id'] return state elif event_type == 'OrderCancelled': state['status'] = 'CANCELLED' return state return state async def create_order(self, user_id, items): """åˆ›å»ºè®¢å•""" event = { 'type': 'OrderCreated', 'order_id': generate_id(), 'user_id': user_id, 'items': items } await self.event_store.append_event(event['order_id'], event) return await self.rebuild(event['order_id']) # ========== CQRS ========== # å‘½ä»¤æŸ¥è¯¢èŒè´£åˆ†ç¦» class CommandBus: """å‘½ä»¤æ€»çº¿""" def __init__(self): self.handlers = {} def register(self, command_type: str, handler): """æ³¨å†Œå‘½ä»¤å¤„ç†å™¨""" self.handlers[command_type] = handler async def execute(self, command: dict): """æ‰§è¡Œå‘½ä»¤""" command_type = command['type'] if command_type not in self.handlers: raise ValueError(f"Unknown command: {command_type}") return await self.handlers[command_type](command) class QueryBus: """æŸ¥è¯¢æ€»çº¿""" def __init__(self): self.handlers = {} def register(self, query_type: str, handler): """æ³¨å†ŒæŸ¥è¯¢å¤„ç†å™¨""" self.handlers[query_type] = handler async def execute(self, query: dict): """æ‰§è¡ŒæŸ¥è¯¢""" query_type = query['type'] if query_type not in self.handlers: raise ValueError(f"Unknown query: {query_type}") return await self.handlers[query_type](query) # CQRSç¤ºä¾‹ class OrderService: """è®¢å•æœåŠ¡ - CQRS""" def __init__(self): self.command_bus = CommandBus() self.query_bus = QueryBus() self.event_store = EventStore() self.read_db = {} # è¯»æ¨¡å‹ self._register_handlers() def _register_handlers(self): """æ³¨å†Œå¤„ç†å™¨""" # å‘½ä»¤å¤„ç†å™¨ self.command_bus.register('CreateOrder', self._handle_create_order) self.command_bus.register('CancelOrder', self._handle_cancel_order) # æŸ¥è¯¢å¤„ç†å™¨ self.query_bus.register('GetOrder', self._handle_get_order) self.query_bus.register('ListOrders', self._handle_list_orders) async def _handle_create_order(self, command): """å¤„ç†åˆ›å»ºè®¢å•å‘½ä»¤""" event = { 'type': 'OrderCreated', 'order_id': command['order_id'], 'user_id': command['user_id'], 'items': command['items'] } await self.event_store.append_event(command['order_id'], event) # æ›´æ–°è¯»æ¨¡å‹ self._update_read_model(event) return event['order_id'] async def _handle_cancel_order(self, command): """å¤„ç†å–æ¶ˆè®¢å•å‘½ä»¤""" event = { 'type': 'OrderCancelled', 'order_id': command['order_id'] } await self.event_store.append_event(command['order_id'], event) # æ›´æ–°è¯»æ¨¡å‹ self._update_read_model(event) async def _handle_get_order(self, query): """å¤„ç†è·å–è®¢å•æŸ¥è¯¢""" return self.read_db.get(query['order_id']) async def _handle_list_orders(self, query): """å¤„ç†è®¢å•åˆ—è¡¨æŸ¥è¯¢""" user_id = query.get('user_id') orders = [ order for order in self.read_db.values() if not user_id or order['user_id'] == user_id ] return orders def _update_read_model(self, event): """æ›´æ–°è¯»æ¨¡å‹""" order_id = event['order_id'] if event['type'] == 'OrderCreated': self.read_db[order_id] = { 'id': order_id, 'user_id': event['user_id'], 'items': event['items'], 'status': 'CREATED' } elif event['type'] == 'OrderCancelled': if order_id in self.read_db: self.read_db[order_id]['status'] = 'CANCELLED' å››ã€å®¹é”™ä¸é«˜å¯ç”¨è®¾è®¡ 4.1 ç†”æ–­å™¨æ¨¡å¼ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 import asyncio from enum import Enum from datetime import datetime, timedelta class CircuitState(Enum): CLOSED = 'CLOSED' # æ­£å¸¸çŠ¶æ€ OPEN = 'OPEN' # ç†”æ–­çŠ¶æ€ HALF_OPEN = 'HALF_OPEN' # åŠå¼€çŠ¶æ€ class CircuitBreaker: """ç†”æ–­å™¨""" def __init__( self, failure_threshold: int = 5, timeout: int = 60, half_open_attempts: int = 3 ): self.failure_threshold = failure_threshold self.timeout = timeout self.half_open_attempts = half_open_attempts self.state = CircuitState.CLOSED self.failure_count = 0 self.success_count = 0 self.last_failure_time = None async def call(self, func, *args, **kwargs): """é€šè¿‡ç†”æ–­å™¨è°ƒç”¨å‡½æ•°""" if self.state == CircuitState.OPEN: # ç†”æ–­çŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›å…¥åŠå¼€ if self._should_attempt_reset(): self.state = CircuitState.HALF_OPEN self.success_count = 0 else: raise CircuitBreakerOpenException( f"Circuit breaker is OPEN. Try again later." ) try: result = await func(*args, **kwargs) # æˆåŠŸï¼Œé‡ç½®è®¡æ•° self._on_success() return result except Exception as e: # å¤±è´¥ï¼Œå¢åŠ è®¡æ•° self._on_failure() raise e def _should_attempt_reset(self) -> bool: """æ£€æŸ¥æ˜¯å¦åº”è¯¥å°è¯•é‡ç½®""" if self.last_failure_time is None: return False elapsed = (datetime.now() - self.last_failure_time).seconds return elapsed >= self.timeout def _on_success(self): """å¤„ç†æˆåŠŸ""" if self.state == CircuitState.HALF_OPEN: self.success_count += 1 # åŠå¼€çŠ¶æ€ä¸‹è¿ç»­æˆåŠŸï¼Œæ¢å¤å…³é—­çŠ¶æ€ if self.success_count >= self.half_open_attempts: self.state = CircuitState.CLOSED self.failure_count = 0 elif self.state == CircuitState.CLOSED: self.failure_count = 0 def _on_failure(self): """å¤„ç†å¤±è´¥""" self.failure_count += 1 self.last_failure_time = datetime.now() # è¾¾åˆ°é˜ˆå€¼ï¼Œæ‰“å¼€ç†”æ–­å™¨ if self.failure_count >= self.failure_threshold: self.state = CircuitState.OPEN # ä½¿ç”¨ç¤ºä¾‹ async def call_external_service(url): """è°ƒç”¨å¤–éƒ¨æœåŠ¡""" response = await aiohttp.get(url) return await response.json() # åˆ›å»ºç†”æ–­å™¨ circuit_breaker = CircuitBreaker( failure_threshold=5, timeout=60, half_open_attempts=3 ) # é€šè¿‡ç†”æ–­å™¨è°ƒç”¨ try: result = await circuit_breaker.call( call_external_service, 'http://external-service/api/data' ) except CircuitBreakerOpenException: # ç†”æ–­å™¨æ‰“å¼€ï¼Œä½¿ç”¨é™çº§é€»è¾‘ result = get_cached_data() except Exception as e: # å…¶ä»–é”™è¯¯å¤„ç† logger.error(f"Service call failed: {e}") 4.2 é‡è¯•ä¸è¶…æ—¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 import asyncio from functools import wraps from typing import Callable, Type class RetryConfig: """é‡è¯•é…ç½®""" def __init__( self, max_attempts: int = 3, base_delay: float = 1.0, max_delay: float = 10.0, exponential_base: float = 2, jitter: bool = True, retry_exceptions: list = None ): self.max_attempts = max_attempts self.base_delay = base_delay self.max_delay = max_delay self.exponential_base = exponential_base self.jitter = jitter self.retry_exceptions = retry_exceptions or [Exception] def retry(config: RetryConfig = None): """é‡è¯•è£…é¥°å™¨""" if config is None: config = RetryConfig() def decorator(func: Callable): @wraps(func) async def wrapper(*args, **kwargs): last_exception = None for attempt in range(1, config.max_attempts + 1): try: return await func(*args, **kwargs) except tuple(config.retry_exceptions) as e: last_exception = e if attempt &lt; config.max_attempts: # è®¡ç®—å»¶è¿Ÿæ—¶é—´ delay = min( config.base_delay * (config.exponential_base ** (attempt - 1)), config.max_delay ) # æ·»åŠ æŠ–åŠ¨ if config.jitter: delay = delay * (0.5 + random.random() * 0.5) logger.warning( f"Attempt {attempt} failed: {e}. " f"Retrying in {delay:.2f}s..." ) await asyncio.sleep(delay) # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ raise last_exception return wrapper return decorator # è¶…æ—¶è£…é¥°å™¨ def timeout(seconds: float): """è¶…æ—¶è£…é¥°å™¨""" def decorator(func: Callable): @wraps(func) async def wrapper(*args, **kwargs): try: return await asyncio.wait_for( func(*args, **kwargs), timeout=seconds ) except asyncio.TimeoutError: raise TimeoutException( f"Function {func.__name__} timed out after {seconds}s" ) return wrapper return decorator # ä½¿ç”¨ç¤ºä¾‹ @retry(RetryConfig( max_attempts=3, base_delay=1.0, exponential_base=2, retry_exceptions=[ConnectionError, TimeoutError] )) @timeout(seconds=5) async def call_external_api(url): """è°ƒç”¨å¤–éƒ¨APIï¼Œå¸¦é‡è¯•å’Œè¶…æ—¶""" async with aiohttp.ClientSession() as session: async with session.get(url) as response: response.raise_for_status() return await response.json() 4.3 é™æµä¸é™çº§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 import time from collections import deque from typing import Callable, Any class RateLimiter: """é€Ÿç‡é™åˆ¶å™¨""" def __init__(self, rate: int, per: float): """ rate: å…è®¸çš„è¯·æ±‚æ•° per: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ """ self.rate = rate self.per = per self.allowance = rate self.last_check = time.time() def acquire(self, tokens: int = 1) -> bool: """è·å–ä»¤ç‰Œ""" current = time.time() elapsed = current - self.last_check # è¡¥å……ä»¤ç‰Œ self.allowance += elapsed * (self.rate / self.per) if self.allowance > self.rate: self.allowance = self.rate self.last_check = current # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ä»¤ç‰Œ if self.allowance &lt; tokens: return False self.allowance -= tokens return True class TokenBucket: """ä»¤ç‰Œæ¡¶ç®—æ³•""" def __init__(self, capacity: int, refill_rate: float): """ capacity: æ¡¶å®¹é‡ refill_rate: å¡«å……é€Ÿç‡ï¼ˆæ¯ç§’ï¼‰ """ self.capacity = capacity self.refill_rate = refill_rate self.tokens = capacity self.last_refill = time.time() def consume(self, tokens: int = 1) -> bool: """æ¶ˆè´¹ä»¤ç‰Œ""" self._refill() if self.tokens >= tokens: self.tokens -= tokens return True return False def _refill(self): """è¡¥å……ä»¤ç‰Œ""" now = time.time() elapsed = now - self.last_refill refill_amount = elapsed * self.refill_rate self.tokens = min(self.capacity, self.tokens + refill_amount) self.last_refill = now class SlidingWindow: """æ»‘åŠ¨çª—å£é™æµ""" def __init__(self, limit: int, window: float): """ limit: çª—å£å†…æœ€å¤§è¯·æ±‚æ•° window: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰ """ self.limit = limit self.window = window self.requests = deque() def is_allowed(self) -> bool: """æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚""" now = time.time() # ç§»é™¤çª—å£å¤–çš„è¯·æ±‚ while self.requests and self.requests[0] &lt; now - self.window: self.requests.popleft() # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶ if len(self.requests) >= self.limit: return False self.requests.append(now) return True # é™çº§è£…é¥°å™¨ class FallbackExecutor: """é™çº§æ‰§è¡Œå™¨""" def __init__(self): self.fallbacks = {} def register_fallback(self, func_name: str, fallback: Callable): """æ³¨å†Œé™çº§å‡½æ•°""" self.fallbacks[func_name] = fallback async def execute_with_fallback( self, func: Callable, *args, fallback_result: Any = None, **kwargs ): """æ‰§è¡Œå‡½æ•°ï¼Œå¤±è´¥æ—¶é™çº§""" try: return await func(*args, **kwargs) except Exception as e: func_name = func.__name__ # æŸ¥æ‰¾æ³¨å†Œçš„é™çº§å‡½æ•° if func_name in self.fallbacks: logger.warning(f"Function {func_name} failed, using fallback") return await self.fallbacks[func_name](*args, **kwargs) # ä½¿ç”¨é»˜è®¤é™çº§ç»“æœ if fallback_result is not None: logger.warning(f"Function {func_name} failed, using fallback result") return fallback_result # æ²¡æœ‰é™çº§æ–¹æ¡ˆï¼ŒæŠ›å‡ºå¼‚å¸¸ raise e # ä½¿ç”¨ç¤ºä¾‹ # åˆ›å»ºé™æµå™¨ rate_limiter = RateLimiter(rate=100, per=1) # 100è¯·æ±‚/ç§’ token_bucket = TokenBucket(capacity=10, refill_rate=1) # 10ä»¤ç‰Œå®¹é‡ï¼Œæ¯ç§’è¡¥å……1ä¸ª sliding_window = SlidingWindow(limit=100, window=60) # 60ç§’å†…æœ€å¤š100è¯·æ±‚ # åˆ›å»ºé™çº§æ‰§è¡Œå™¨ fallback_executor = FallbackExecutor() async def get_user_data(user_id): """è·å–ç”¨æˆ·æ•°æ®""" # æ£€æŸ¥é™æµ if not rate_limiter.acquire(): raise RateLimitException("Too many requests") # è°ƒç”¨æœåŠ¡ return await user_service.get_user(user_id) # æ³¨å†Œé™çº§å‡½æ•° async def get_user_data_fallback(user_id): """é™çº§ï¼šè¿”å›ç¼“å­˜çš„ç”¨æˆ·æ•°æ®""" return await cache.get(f"user:{user_id}") fallback_executor.register_fallback('get_user_data', get_user_data_fallback) # ä½¿ç”¨ try: result = await fallback_executor.execute_with_fallback( get_user_data, user_id='123' ) except Exception as e: logger.error(f"All attempts failed: {e}") äº”ã€å¯è§‚æµ‹æ€§è®¾è®¡ 5.1 æ—¥å¿—ç³»ç»Ÿ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 import structlog from typing import Any class LogContext: """æ—¥å¿—ä¸Šä¸‹æ–‡""" def __init__(self): self.context = {} def set(self, key: str, value: Any): """è®¾ç½®ä¸Šä¸‹æ–‡""" self.context[key] = value def get(self, key: str, default=None): """è·å–ä¸Šä¸‹æ–‡""" return self.context.get(key, default) def clear(self): """æ¸…ç©ºä¸Šä¸‹æ–‡""" self.context.clear() # å…¨å±€æ—¥å¿—ä¸Šä¸‹æ–‡ log_context = LogContext() # é…ç½®structlog structlog.configure( processors=[ structlog.stdlib.filter_by_level, structlog.stdlib.add_logger_name, structlog.stdlib.add_log_level, structlog.stdlib.PositionalArgumentsFormatter(), structlog.processors.TimeStamper(fmt="iso"), structlog.processors.StackInfoRenderer(), structlog.processors.format_exc_info, structlog.processors.UnicodeDecoder(), # æ·»åŠ ä¸Šä¸‹æ–‡ lambda logger, method_name, event_dict: { **event_dict, **log_context.context }, # æ ¼å¼åŒ–è¾“å‡º structlog.processors.JSONRenderer() ], context_class=dict, logger_factory=structlog.stdlib.LoggerFactory(), cache_logger_on_first_use=True, ) class ServiceLogger: """æœåŠ¡æ—¥å¿—è®°å½•å™¨""" def __init__(self, service_name: str): self.service_name = service_name self.logger = structlog.get_logger() def log_request(self, request_id: str, method: str, path: str, **kwargs): """è®°å½•è¯·æ±‚""" self.logger.info( "incoming_request", request_id=request_id, service=self.service_name, method=method, path=path, **kwargs ) def log_response( self, request_id: str, status_code: int, duration_ms: float, **kwargs ): """è®°å½•å“åº”""" self.logger.info( "outgoing_response", request_id=request_id, service=self.service_name, status_code=status_code, duration_ms=duration_ms, **kwargs ) def log_error(self, error: Exception, **kwargs): """è®°å½•é”™è¯¯""" self.logger.error( "error_occurred", service=self.service_name, error_type=type(error).__name__, error_message=str(error), **kwargs ) def log_service_call( self, service_name: str, method: str, duration_ms: float, success: bool, **kwargs ): """è®°å½•æœåŠ¡è°ƒç”¨""" self.logger.info( "service_call", caller=self.service_name, service=service_name, method=method, duration_ms=duration_ms, success=success, **kwargs ) # ä¸­é—´ä»¶ç¤ºä¾‹ class LoggingMiddleware: """æ—¥å¿—ä¸­é—´ä»¶""" def __init__(self, logger: ServiceLogger): self.logger = logger async def process_request(self, request, call_next): """å¤„ç†è¯·æ±‚""" request_id = generate_request_id() start_time = time.time() # è®¾ç½®æ—¥å¿—ä¸Šä¸‹æ–‡ log_context.set('request_id', request_id) log_context.set('user_id', request.user_id) # è®°å½•è¯·æ±‚ self.logger.log_request( request_id=request_id, method=request.method, path=request.path ) try: # å¤„ç†è¯·æ±‚ response = await call_next(request) # è®°å½•å“åº” duration_ms = (time.time() - start_time) * 1000 self.logger.log_response( request_id=request_id, status_code=response.status_code, duration_ms=duration_ms ) return response except Exception as e: duration_ms = (time.time() - start_time) * 1000 self.logger.log_error( error=e, request_id=request_id, duration_ms=duration_ms ) raise finally: log_context.clear() 5.2 é“¾è·¯è¿½è¸ª 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 from opentelemetry import trace from opentelemetry.sdk.trace import TracerProvider from opentelemetry.sdk.trace.export import BatchSpanProcessor from opentelemetry.exporter.jaeger.thrift import JaegerExporter # é…ç½®Tracer trace.set_tracer_provider(TracerProvider()) tracer_provider = trace.get_tracer_provider() # é…ç½®Jaegerå¯¼å‡ºå™¨ jaeger_exporter = JaegerExporter( agent_host_name="localhost", agent_port=6831, ) tracer_provider.add_span_processor( BatchSpanProcessor(jaeger_exporter) ) class TracingClient: """å¸¦è¿½è¸ªçš„å®¢æˆ·ç«¯""" def __init__(self, service_name: str): self.service_name = service_name self.tracer = trace.get_tracer(__name__) async def call_service( self, service_name: str, method: str, **kwargs ): """è°ƒç”¨æœåŠ¡å¹¶è¿½è¸ª""" with self.tracer.start_as_current_span( f"{service_name}.{method}", kind=trace.SpanKind.CLIENT ) as span: # æ·»åŠ å±æ€§ span.set_attribute("service", self.service_name) span.set_attribute("target_service", service_name) span.set_attribute("method", method) try: # æ³¨å…¥è¿½è¸ªä¸Šä¸‹æ–‡ headers = {} trace.inject(headers) # è°ƒç”¨æœåŠ¡ result = await self._make_request( service_name, method, headers=headers, **kwargs ) span.set_attribute("success", True) return result except Exception as e: span.record_exception(e) span.set_attribute("success", False) raise async def _make_request(self, service_name, method, headers, **kwargs): """å®é™…è¯·æ±‚é€»è¾‘""" # å®ç°æœåŠ¡è°ƒç”¨ pass # ä½¿ç”¨ç¤ºä¾‹ client = TracingClient("order-service") async def create_order(user_id, items): """åˆ›å»ºè®¢å• - å¸¦è¿½è¸ª""" with client.tracer.start_as_current_span("create_order") as span: span.set_attribute("user_id", user_id) span.set_attribute("item_count", len(items)) # è°ƒç”¨åº“å­˜æœåŠ¡ inventory_result = await client.call_service( "inventory-service", "check_stock", items=items ) # è°ƒç”¨æ”¯ä»˜æœåŠ¡ payment_result = await client.call_service( "payment-service", "process_payment", user_id=user_id, amount=calculate_amount(items) ) return { "inventory": inventory_result, "payment": payment_result } 5.3 æŒ‡æ ‡ç›‘æ§ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 from prometheus_client import Counter, Histogram, Gauge, start_http_server # å®šä¹‰æŒ‡æ ‡ request_count = Counter( 'http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'] ) request_duration = Histogram( 'http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'] ) active_connections = Gauge( 'active_connections', 'Number of active connections' ) business_metric = Counter( 'business_operations_total', 'Total business operations', ['operation', 'status'] ) class MetricsMiddleware: """æŒ‡æ ‡æ”¶é›†ä¸­é—´ä»¶""" def __init__(self): self.active_connections = active_connections async def process_request(self, request, call_next): """å¤„ç†è¯·æ±‚å¹¶æ”¶é›†æŒ‡æ ‡""" # å¢åŠ æ´»è·ƒè¿æ¥æ•° self.active_connections.inc() start_time = time.time() try: response = await call_next(request) # è®°å½•è¯·æ±‚è®¡æ•° request_count.labels( method=request.method, endpoint=request.path, status=response.status_code ).inc() # è®°å½•è¯·æ±‚è€—æ—¶ duration = time.time() - start_time request_duration.labels( method=request.method, endpoint=request.path ).observe(duration) return response finally: # å‡å°‘æ´»è·ƒè¿æ¥æ•° self.active_connections.dec() class BusinessMetrics: """ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†""" @staticmethod def record_operation(operation: str, success: bool): """è®°å½•ä¸šåŠ¡æ“ä½œ""" status = "success" if success else "failure" business_metric.labels( operation=operation, status=status ).inc() @staticmethod def record_order_created(order_value: float): """è®°å½•è®¢å•åˆ›å»º""" business_metric.labels( operation="order_created", status="success" ).inc() @staticmethod def record_payment_failed(amount: float, reason: str): """è®°å½•æ”¯ä»˜å¤±è´¥""" business_metric.labels( operation=f"payment_failed_{reason}", status="failure" ).inc() # ä½¿ç”¨ç¤ºä¾‹ async def create_order_logic(user_id, items): """åˆ›å»ºè®¢å•é€»è¾‘""" try: order = await order_service.create(user_id, items) BusinessMetrics.record_operation("order_created", True) return order except InventoryError as e: BusinessMetrics.record_operation("order_created", False) BusinessMetrics.record_operation("inventory_check_failed", False) raise except PaymentError as e: BusinessMetrics.record_operation("order_created", False) BusinessMetrics.record_payment_failed( order.total, e.reason ) raise # å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨ start_http_server(8000) æ€»ç»“ åç«¯ç³»ç»Ÿæ¶æ„è®¾è®¡æ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿå·¥ç¨‹ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªç»´åº¦ï¼š
...</p></div><footer class=entry-footer><div class=post-meta-content><div class=post-categories-inline><a href=/blog/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/ class=category-link>åç«¯å¼€å‘</a><a href=/blog/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/ class=category-link>æ¶æ„è®¾è®¡</a></div><span class=post-date>2025-12-30</span><span class=post-author>æœ‰æ¡å·¥å…·å›¢é˜Ÿ</span></div><style>.post-meta-content{display:flex;align-items:center;flex-wrap:wrap;gap:.75rem;font-family:sf mono,monaco,courier new,monospace;font-size:.875rem;color:#9ca3af !important}.post-categories-inline{display:inline-flex;align-items:center;gap:.5rem}.category-link{display:inline-flex;align-items:center;gap:.25rem;padding:.25rem .75rem;background:rgba(255,255,255,.1);color:#e5e7eb !important;text-decoration:none;font-size:.75rem;font-weight:600;text-transform:uppercase;letter-spacing:.05em;border:1px solid rgba(255,255,255,.2);border-radius:0;transition:all .3s ease;white-space:nowrap}.category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3);transform:translateY(-1px)}.category-link::before{content:'ğŸ“';font-size:.7rem;opacity:.8}.post-date,.post-reading-time,.post-word-count,.post-author{color:#9ca3af !important}[data-theme=dark] .post-meta-content{color:#9ca3af !important}[data-theme=dark] .category-link{background:rgba(255,255,255,.1);color:#e5e7eb !important;border-color:rgba(255,255,255,.2)}[data-theme=dark] .category-link:hover{background:rgba(255,255,255,.2);color:#fff !important;border-color:rgba(255,255,255,.3)}[data-theme=dark] .post-date,[data-theme=dark] .post-reading-time,[data-theme=dark] .post-word-count,[data-theme=dark] .post-author{color:#9ca3af !important}[data-theme=light] .post-meta-content{color:#6c757d !important}[data-theme=light] .category-link{background:rgba(0,0,0,5%);color:#495057 !important;border-color:rgba(0,0,0,.15)}[data-theme=light] .category-link:hover{background:rgba(0,102,204,.1);color:#212529 !important;border-color:rgba(0,102,204,.3)}[data-theme=light] .post-date,[data-theme=light] .post-reading-time,[data-theme=light] .post-word-count,[data-theme=light] .post-author{color:#6c757d !important}@media(max-width:768px){.post-meta-content{gap:.5rem;font-size:.8rem}.category-link{padding:.2rem .6rem;font-size:.7rem}}</style></footer><a class=entry-link aria-label="post link to åç«¯ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼šä»å•ä½“åˆ°å¾®æœåŠ¡çš„æ¼”è¿›ä¹‹è·¯" href=/blog/articles/%E5%90%8E%E7%AB%AF%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%BB%8E%E5%8D%95%E4%BD%93%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B9%8B%E8%B7%AF/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=/blog/posts/page/4/>Â«&nbsp;&nbsp;
</a><a class=next href=/blog/posts/page/6/>&nbsp;&nbsp;Â»</a></nav></footer></main><footer class=footer><span>Â© 2024-2025 æœ‰æ¡å·¥å…·æŠ€æœ¯åšå®¢</span> Â·</footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>